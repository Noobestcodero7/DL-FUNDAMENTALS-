{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0120cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L2Regularization,Dropout layer and Early stopping  with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984c5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "872d650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08865ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98b6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d66d2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url,sep=r\"\\s+\",skiprows=22, header=None )\n",
    "data = np.hstack([raw_df.values[::2,:],raw_df.values[1::2,:2]])\n",
    "target = raw_df.values[1::2,2].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a0b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and y\n",
    "X = pd.DataFrame(data)\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ac7ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdee9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the features\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(X_train)\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab50756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library for L1 regularization\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def88b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define ANN with L1 regularization\n",
    "model_l2=Sequential()\n",
    "model_l2.add(Dense(128,activation='relu',input_shape=(13,),\n",
    "                   kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "model_l2.add(Dense(64,activation='relu',kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "model_l2.add(Dense(64,activation='relu',kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "model_l2.add(Dense(32,activation='relu',kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "model_l2.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ce82848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model_l2.compile(loss='mse',\n",
    "                 optimizer=Adam(learning_rate=0.01),\n",
    "                 metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4706ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_l1=model_l2.fit(X_train,y_train,\n",
    "                        batch_size=64,\n",
    "                        epochs=1000,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aca19c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8494 - mae: 0.4699 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 17.1010 - mae: 2.2003 \n",
      "Train loss: 3.378\n",
      "Test loss : 15.274\n",
      "Train mae : 0.765\n",
      "Test mae  : 2.179\n"
     ]
    }
   ],
   "source": [
    "train_loss_l2, train_mae_l2 = model_l2.evaluate(X_train, y_train)\n",
    "test_loss_l2, test_mae_l2 = model_l2.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Train loss: {train_loss_l2:.3f}\")\n",
    "print(f\"Test loss : {test_loss_l2:.3f}\")\n",
    "print(f\"Train mae : {train_mae_l2:.3f}\")\n",
    "print(f\"Test mae  : {test_mae_l2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9567fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library for Dropout\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define ANN with Dropout(Dropout rate=0.5)\n",
    "model_d=Sequential()\n",
    "model_d.add(Dense(128,activation='relu',input_shape=(13,)))\n",
    "model_d.add(Dropout(0.5))\n",
    "model_d.add(Dense(64,activation='relu'))\n",
    "model_d.add(Dropout(0.5))\n",
    "model_d.add(Dense(64,activation='relu'))\n",
    "model_d.add(Dropout(0.5))\n",
    "model_d.add(Dense(64,activation='relu'))\n",
    "model_d.add(Dropout(0.5))\n",
    "model_d.add(Dense(32,activation='relu'))\n",
    "model_d.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2a5ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model_d.compile(loss='mse',optimizer=Adam(learning_rate=0.01),metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecc31c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library for earlystopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ad6cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define ANN with Dropout(Dropout rate=0.5)\n",
    "model_e=Sequential()\n",
    "model_e.add(Dense(128,activation='relu',input_shape=(13,)))\n",
    "model_e.add(Dense(64,activation='relu'))\n",
    "model_e.add(Dense(64,activation='relu'))\n",
    "model_e.add(Dense(64,activation='relu'))\n",
    "model_e.add(Dense(32,activation='relu'))\n",
    "model_e.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c31c39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model_e.compile(loss='mse',optimizer=Adam(learning_rate=0.01),metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "543d5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d553da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 560.7420 - mae: 20.6981 - val_loss: 86.2040 - val_mae: 7.4204\n",
      "Epoch 2/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 95.7733 - mae: 7.5970 - val_loss: 46.3336 - val_mae: 5.4496\n",
      "Epoch 3/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 54.9328 - mae: 5.6143 - val_loss: 42.1110 - val_mae: 5.4008\n",
      "Epoch 4/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 54.8914 - mae: 5.5037 - val_loss: 30.6745 - val_mae: 4.4915\n",
      "Epoch 5/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 32.4359 - mae: 4.5546 - val_loss: 18.2490 - val_mae: 3.3975\n",
      "Epoch 6/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 23.5183 - mae: 3.7728 - val_loss: 16.1199 - val_mae: 3.0941\n",
      "Epoch 7/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 17.7824 - mae: 3.1665 - val_loss: 14.0977 - val_mae: 2.8461\n",
      "Epoch 8/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 14.5052 - mae: 2.8683 - val_loss: 15.5632 - val_mae: 3.0210\n",
      "Epoch 9/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 12.8920 - mae: 2.7513 - val_loss: 14.0826 - val_mae: 2.7506\n",
      "Epoch 10/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.8265 - mae: 2.4339 - val_loss: 14.3543 - val_mae: 2.8501\n",
      "Epoch 11/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10.8563 - mae: 2.4839 - val_loss: 11.1136 - val_mae: 2.6101\n",
      "Epoch 12/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.7914 - mae: 2.4970 - val_loss: 21.5533 - val_mae: 3.5635\n",
      "Epoch 13/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10.7454 - mae: 2.5351 - val_loss: 10.8871 - val_mae: 2.5264\n",
      "Epoch 14/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.1535 - mae: 2.2391 - val_loss: 21.0125 - val_mae: 3.4837\n",
      "Epoch 15/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 11.4341 - mae: 2.6270 - val_loss: 10.3968 - val_mae: 2.4354\n",
      "Epoch 16/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.8833 - mae: 2.2019 - val_loss: 9.2328 - val_mae: 2.3225\n",
      "Epoch 17/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.7675 - mae: 2.1809 - val_loss: 17.9106 - val_mae: 3.2227\n",
      "Epoch 18/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.0864 - mae: 2.1396 - val_loss: 10.1448 - val_mae: 2.3431\n",
      "Epoch 19/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.3925 - mae: 1.9833 - val_loss: 10.1152 - val_mae: 2.3857\n",
      "Epoch 20/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.6783 - mae: 2.1032 - val_loss: 17.0681 - val_mae: 3.1546\n",
      "Epoch 21/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.8771 - mae: 2.1625 - val_loss: 8.8313 - val_mae: 2.2114\n",
      "Epoch 22/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.7300 - mae: 1.9023 - val_loss: 10.3674 - val_mae: 2.3220\n",
      "Epoch 23/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.9515 - mae: 1.9166 - val_loss: 13.6726 - val_mae: 2.6809\n",
      "Epoch 24/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.7073 - mae: 1.8592 - val_loss: 11.4613 - val_mae: 2.4546\n",
      "Epoch 25/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.6856 - mae: 1.7995 - val_loss: 8.7951 - val_mae: 2.1424\n",
      "Epoch 26/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.8076 - mae: 1.7584 - val_loss: 13.8342 - val_mae: 2.6931\n",
      "Epoch 27/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.6667 - mae: 1.8210 - val_loss: 11.7742 - val_mae: 2.4449\n",
      "Epoch 28/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.6795 - mae: 1.6598 - val_loss: 11.7163 - val_mae: 2.4264\n",
      "Epoch 29/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.8662 - mae: 1.7122 - val_loss: 10.6530 - val_mae: 2.2970\n",
      "Epoch 30/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.1549 - mae: 1.6514 - val_loss: 9.5365 - val_mae: 2.2492\n",
      "Epoch 31/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.9128 - mae: 1.7705 - val_loss: 11.3823 - val_mae: 2.4086\n",
      "Epoch 32/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5960 - mae: 1.5724 - val_loss: 14.1244 - val_mae: 2.6227\n",
      "Epoch 33/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.7020 - mae: 1.6210 - val_loss: 14.4376 - val_mae: 2.7328\n",
      "Epoch 34/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1152 - mae: 1.8048 - val_loss: 11.1505 - val_mae: 2.3700\n",
      "Epoch 35/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.0669 - mae: 1.7044 - val_loss: 10.0968 - val_mae: 2.2414\n",
      "Epoch 36/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2636 - mae: 1.6704 - val_loss: 10.9539 - val_mae: 2.2565\n",
      "Epoch 37/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.6429 - mae: 1.4372 - val_loss: 12.5067 - val_mae: 2.5232\n",
      "Epoch 38/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.2544 - mae: 1.5604 - val_loss: 11.9256 - val_mae: 2.4437\n",
      "Epoch 39/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.2574 - mae: 1.3153 - val_loss: 13.8403 - val_mae: 2.6043\n",
      "Epoch 40/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.5503 - mae: 1.4057 - val_loss: 12.7381 - val_mae: 2.5004\n",
      "Epoch 41/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.8214 - mae: 1.4340 - val_loss: 13.6990 - val_mae: 2.6145\n",
      "Epoch 42/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.7757 - mae: 1.4402 - val_loss: 11.7565 - val_mae: 2.4098\n",
      "Epoch 43/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.2766 - mae: 1.3658 - val_loss: 12.0049 - val_mae: 2.4053\n",
      "Epoch 44/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.4570 - mae: 1.3200 - val_loss: 11.5419 - val_mae: 2.3706\n",
      "Epoch 45/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.0177 - mae: 1.2614 - val_loss: 15.1370 - val_mae: 2.7199\n",
      "Epoch 46/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5277 - mae: 1.6466 - val_loss: 19.9072 - val_mae: 3.2870\n",
      "Epoch 47/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3088 - mae: 1.7485 - val_loss: 19.5066 - val_mae: 3.2337\n",
      "Epoch 48/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.9822 - mae: 1.7041 - val_loss: 16.3434 - val_mae: 2.9129\n",
      "Epoch 49/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.8982 - mae: 1.7517 - val_loss: 13.7170 - val_mae: 2.5992\n",
      "Epoch 50/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.8020 - mae: 1.5100 - val_loss: 13.2892 - val_mae: 2.5170\n",
      "Epoch 51/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3230 - mae: 1.3840 - val_loss: 10.0304 - val_mae: 2.1936\n",
      "Epoch 52/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.1816 - mae: 1.3587 - val_loss: 10.5849 - val_mae: 2.3300\n",
      "Epoch 53/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.4338 - mae: 1.5542 - val_loss: 9.4890 - val_mae: 2.1427\n",
      "Epoch 54/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.7481 - mae: 1.4412 - val_loss: 11.9500 - val_mae: 2.4093\n",
      "Epoch 55/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.1356 - mae: 1.3578 - val_loss: 15.6266 - val_mae: 2.8198\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "history_e=model_e.fit(X_train,y_train,\n",
    "                      batch_size=64,\n",
    "                      epochs=1000,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[early_stop],\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e77ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
