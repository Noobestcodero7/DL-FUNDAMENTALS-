{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79dbb1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer and Batch normalization with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc65e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a75bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06d0904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD,Adagrad,RMSprop,Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c15e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe04b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url,sep=r\"\\s+\",skiprows=22, header=None )\n",
    "data = np.hstack([raw_df.values[::2,:],raw_df.values[1::2,:2]])\n",
    "target = raw_df.values[1::2,2].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a465fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and y\n",
    "X = pd.DataFrame(data)\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15aea0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a613316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the features\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(X_train)\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf161999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define ANN \n",
    "def ann():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(128,activation='relu',input_shape=(13,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ae6ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44762182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Optimizer\n",
    "\n",
    "#Momentum\n",
    "optimizer=SGD(learning_rate=0.001,momentum=0.9)\n",
    "#Adagrad\n",
    "optimizer=Adagrad(learning_rate=0.001,epsilon=10**-10)\n",
    "#RMSprop\n",
    "optimizer=RMSprop(learning_rate=0.001,rho=0.9)\n",
    "#Adam\n",
    "optimizer=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b024640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ann()\n",
    "model.compile(\n",
    "    loss=MeanSquaredError(),\n",
    "    optimizer=optimizer,\n",
    "    metrics=['mae']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e8b4c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 596.9387 - mae: 22.9434 - val_loss: 557.9008 - val_mae: 21.3992\n",
      "Epoch 2/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 562.2905 - mae: 22.6273 - val_loss: 549.6035 - val_mae: 21.2664\n",
      "Epoch 3/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 563.9278 - mae: 22.8294 - val_loss: 543.0520 - val_mae: 21.1706\n",
      "Epoch 4/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 552.2882 - mae: 22.6274 - val_loss: 537.7689 - val_mae: 21.1016\n",
      "Epoch 5/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 540.1792 - mae: 22.5133 - val_loss: 533.0369 - val_mae: 21.0486\n",
      "Epoch 6/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 531.5953 - mae: 22.4038 - val_loss: 528.1639 - val_mae: 20.9912\n",
      "Epoch 7/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 531.8776 - mae: 22.5235 - val_loss: 523.5905 - val_mae: 20.9419\n",
      "Epoch 8/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 508.2935 - mae: 22.0914 - val_loss: 519.1394 - val_mae: 20.8981\n",
      "Epoch 9/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 528.1375 - mae: 22.4774 - val_loss: 514.3952 - val_mae: 20.8581\n",
      "Epoch 10/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 504.4331 - mae: 22.1038 - val_loss: 510.1319 - val_mae: 20.8394\n",
      "Epoch 11/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 526.8761 - mae: 22.5759 - val_loss: 507.9247 - val_mae: 20.8433\n",
      "Epoch 12/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 505.5435 - mae: 22.1433 - val_loss: 507.1783 - val_mae: 20.8853\n",
      "Epoch 13/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 513.5477 - mae: 22.4051 - val_loss: 507.2802 - val_mae: 20.9484\n",
      "Epoch 14/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 495.7631 - mae: 22.0104 - val_loss: 507.9644 - val_mae: 21.0191\n",
      "Epoch 15/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 510.0602 - mae: 22.3263 - val_loss: 509.1658 - val_mae: 21.0728\n",
      "Epoch 16/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 490.8742 - mae: 21.9053 - val_loss: 507.9622 - val_mae: 21.1236\n",
      "Epoch 17/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 507.4601 - mae: 22.2908 - val_loss: 508.6320 - val_mae: 21.1896\n",
      "Epoch 18/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 490.0961 - mae: 21.8868 - val_loss: 510.6516 - val_mae: 21.2711\n",
      "Epoch 19/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 470.5970 - mae: 21.5473 - val_loss: 511.1013 - val_mae: 21.3157\n",
      "Epoch 20/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 487.4966 - mae: 21.9491 - val_loss: 513.6082 - val_mae: 21.3933\n",
      "Epoch 21/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 448.5563 - mae: 21.0254 - val_loss: 514.6119 - val_mae: 21.4579\n",
      "Epoch 22/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 466.1455 - mae: 21.4827 - val_loss: 515.3679 - val_mae: 21.5015\n",
      "Epoch 23/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 467.2861 - mae: 21.4833 - val_loss: 512.0974 - val_mae: 21.4734\n",
      "Epoch 24/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 455.1523 - mae: 21.1824 - val_loss: 507.7175 - val_mae: 21.4229\n",
      "Epoch 25/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 445.2570 - mae: 20.9265 - val_loss: 505.5349 - val_mae: 21.3646\n",
      "Epoch 26/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 482.2719 - mae: 21.8169 - val_loss: 500.0226 - val_mae: 21.2958\n",
      "Epoch 27/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 464.9527 - mae: 21.4897 - val_loss: 493.4451 - val_mae: 21.1669\n",
      "Epoch 28/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 432.4375 - mae: 20.6526 - val_loss: 493.2447 - val_mae: 21.1621\n",
      "Epoch 29/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 458.6209 - mae: 21.3000 - val_loss: 488.7069 - val_mae: 21.0735\n",
      "Epoch 30/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 458.5536 - mae: 21.3163 - val_loss: 481.5756 - val_mae: 20.9770\n",
      "Epoch 31/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 444.0665 - mae: 20.9772 - val_loss: 474.3713 - val_mae: 20.8548\n",
      "Epoch 32/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 435.9309 - mae: 20.7916 - val_loss: 469.3635 - val_mae: 20.7197\n",
      "Epoch 33/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 424.8880 - mae: 20.5541 - val_loss: 462.1852 - val_mae: 20.5505\n",
      "Epoch 34/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 432.4324 - mae: 20.6939 - val_loss: 451.8772 - val_mae: 20.3777\n",
      "Epoch 35/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 448.0649 - mae: 21.0600 - val_loss: 444.2647 - val_mae: 20.1904\n",
      "Epoch 36/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 405.5219 - mae: 20.0061 - val_loss: 436.4370 - val_mae: 19.9969\n",
      "Epoch 37/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 423.6565 - mae: 20.5189 - val_loss: 429.4324 - val_mae: 19.8695\n",
      "Epoch 38/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 390.1521 - mae: 19.6363 - val_loss: 424.0256 - val_mae: 19.7631\n",
      "Epoch 39/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 402.2663 - mae: 19.9956 - val_loss: 415.7436 - val_mae: 19.6281\n",
      "Epoch 40/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 400.1074 - mae: 19.9370 - val_loss: 412.0356 - val_mae: 19.5548\n",
      "Epoch 41/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 406.1147 - mae: 20.0844 - val_loss: 408.4226 - val_mae: 19.4316\n",
      "Epoch 42/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 395.7339 - mae: 19.8385 - val_loss: 399.3775 - val_mae: 19.2278\n",
      "Epoch 43/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 392.0970 - mae: 19.7174 - val_loss: 390.4591 - val_mae: 19.0383\n",
      "Epoch 44/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 383.9130 - mae: 19.5078 - val_loss: 383.3723 - val_mae: 18.7824\n",
      "Epoch 45/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 379.6337 - mae: 19.3871 - val_loss: 379.4302 - val_mae: 18.7698\n",
      "Epoch 46/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 368.2617 - mae: 19.0815 - val_loss: 370.2719 - val_mae: 18.5545\n",
      "Epoch 47/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 364.7369 - mae: 19.0184 - val_loss: 364.0293 - val_mae: 18.4131\n",
      "Epoch 48/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 374.2928 - mae: 19.2852 - val_loss: 363.5758 - val_mae: 18.3615\n",
      "Epoch 49/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 366.9283 - mae: 19.1045 - val_loss: 361.7012 - val_mae: 18.3829\n",
      "Epoch 50/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 355.7284 - mae: 18.7645 - val_loss: 355.5360 - val_mae: 18.1692\n",
      "Epoch 51/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 357.2627 - mae: 18.8155 - val_loss: 348.7014 - val_mae: 18.0713\n",
      "Epoch 52/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 348.2161 - mae: 18.6101 - val_loss: 344.2812 - val_mae: 17.9942\n",
      "Epoch 53/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 349.2718 - mae: 18.6105 - val_loss: 335.5989 - val_mae: 17.7173\n",
      "Epoch 54/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 340.8981 - mae: 18.3792 - val_loss: 325.0099 - val_mae: 17.4208\n",
      "Epoch 55/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 346.0490 - mae: 18.5378 - val_loss: 319.4607 - val_mae: 17.3055\n",
      "Epoch 56/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 339.1074 - mae: 18.3619 - val_loss: 315.1825 - val_mae: 17.1705\n",
      "Epoch 57/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 329.4023 - mae: 18.0948 - val_loss: 307.1292 - val_mae: 16.9701\n",
      "Epoch 58/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 329.0093 - mae: 18.0626 - val_loss: 300.2781 - val_mae: 16.8324\n",
      "Epoch 59/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 329.5253 - mae: 18.0305 - val_loss: 300.0590 - val_mae: 16.7295\n",
      "Epoch 60/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 303.4047 - mae: 17.2741 - val_loss: 297.0125 - val_mae: 16.6096\n",
      "Epoch 61/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 308.1525 - mae: 17.4976 - val_loss: 290.2418 - val_mae: 16.5755\n",
      "Epoch 62/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 331.0533 - mae: 18.1040 - val_loss: 285.7472 - val_mae: 16.3613\n",
      "Epoch 63/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 308.3131 - mae: 17.4901 - val_loss: 279.3606 - val_mae: 16.1550\n",
      "Epoch 64/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 304.1892 - mae: 17.3695 - val_loss: 271.8623 - val_mae: 16.0231\n",
      "Epoch 65/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 288.6852 - mae: 16.8962 - val_loss: 269.1019 - val_mae: 15.9066\n",
      "Epoch 66/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 275.9001 - mae: 16.5367 - val_loss: 268.2751 - val_mae: 15.9500\n",
      "Epoch 67/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 270.9346 - mae: 16.3849 - val_loss: 266.1489 - val_mae: 15.8429\n",
      "Epoch 68/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 270.3299 - mae: 16.3496 - val_loss: 256.7178 - val_mae: 15.4854\n",
      "Epoch 69/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 279.1660 - mae: 16.6379 - val_loss: 247.8024 - val_mae: 15.2512\n",
      "Epoch 70/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 259.3181 - mae: 16.0200 - val_loss: 242.3932 - val_mae: 15.0672\n",
      "Epoch 71/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 264.0886 - mae: 16.1455 - val_loss: 237.9435 - val_mae: 14.9199\n",
      "Epoch 72/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 266.7284 - mae: 16.2659 - val_loss: 232.8679 - val_mae: 14.8051\n",
      "Epoch 73/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 263.1366 - mae: 16.0991 - val_loss: 230.2673 - val_mae: 14.7573\n",
      "Epoch 74/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 259.9900 - mae: 16.0267 - val_loss: 228.7675 - val_mae: 14.5725\n",
      "Epoch 75/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 245.5721 - mae: 15.6004 - val_loss: 225.9061 - val_mae: 14.5800\n",
      "Epoch 76/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 230.5066 - mae: 15.0844 - val_loss: 222.1022 - val_mae: 14.4652\n",
      "Epoch 77/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 235.9838 - mae: 15.2722 - val_loss: 213.7302 - val_mae: 14.1928\n",
      "Epoch 78/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 242.8932 - mae: 15.4964 - val_loss: 209.1750 - val_mae: 13.9665\n",
      "Epoch 79/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 232.6173 - mae: 15.1844 - val_loss: 200.2853 - val_mae: 13.7258\n",
      "Epoch 80/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 220.8945 - mae: 14.7837 - val_loss: 194.5617 - val_mae: 13.5104\n",
      "Epoch 81/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 200.5878 - mae: 14.0461 - val_loss: 189.9184 - val_mae: 13.2929\n",
      "Epoch 82/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 222.1225 - mae: 14.8286 - val_loss: 183.8568 - val_mae: 13.1350\n",
      "Epoch 83/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 196.1414 - mae: 13.8784 - val_loss: 176.5219 - val_mae: 12.8319\n",
      "Epoch 84/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 197.0334 - mae: 13.9414 - val_loss: 170.7408 - val_mae: 12.6477\n",
      "Epoch 85/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 200.6337 - mae: 14.0889 - val_loss: 168.8287 - val_mae: 12.5783\n",
      "Epoch 86/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 189.6620 - mae: 13.6725 - val_loss: 166.4255 - val_mae: 12.4577\n",
      "Epoch 87/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 189.9809 - mae: 13.6939 - val_loss: 162.8082 - val_mae: 12.3541\n",
      "Epoch 88/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 176.9021 - mae: 13.2243 - val_loss: 161.3935 - val_mae: 12.2506\n",
      "Epoch 89/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 185.7933 - mae: 13.5428 - val_loss: 161.0979 - val_mae: 12.2460\n",
      "Epoch 90/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 178.4429 - mae: 13.2838 - val_loss: 153.4926 - val_mae: 11.9867\n",
      "Epoch 91/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 166.0038 - mae: 12.7964 - val_loss: 151.3480 - val_mae: 11.8799\n",
      "Epoch 92/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 177.0972 - mae: 13.2183 - val_loss: 147.2765 - val_mae: 11.6536\n",
      "Epoch 93/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 165.6386 - mae: 12.7635 - val_loss: 141.6192 - val_mae: 11.4283\n",
      "Epoch 94/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 148.5591 - mae: 12.0901 - val_loss: 141.6245 - val_mae: 11.4618\n",
      "Epoch 95/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 146.5488 - mae: 12.0158 - val_loss: 139.7443 - val_mae: 11.4031\n",
      "Epoch 96/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 160.9600 - mae: 12.5724 - val_loss: 134.0344 - val_mae: 11.1704\n",
      "Epoch 97/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 125.9154 - mae: 11.0834 - val_loss: 127.6660 - val_mae: 10.8488\n",
      "Epoch 98/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 127.1088 - mae: 11.0909 - val_loss: 123.4616 - val_mae: 10.6195\n",
      "Epoch 99/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 128.8455 - mae: 11.2659 - val_loss: 117.5845 - val_mae: 10.4241\n",
      "Epoch 100/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 128.3181 - mae: 11.1842 - val_loss: 113.6318 - val_mae: 10.2096\n",
      "Epoch 101/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 128.6169 - mae: 11.2378 - val_loss: 110.1233 - val_mae: 10.0273\n",
      "Epoch 102/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 113.9525 - mae: 10.6021 - val_loss: 107.8886 - val_mae: 9.9010\n",
      "Epoch 103/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 129.6696 - mae: 11.1976 - val_loss: 104.3314 - val_mae: 9.7288\n",
      "Epoch 104/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 110.9678 - mae: 10.3380 - val_loss: 101.7145 - val_mae: 9.5395\n",
      "Epoch 105/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 109.0051 - mae: 10.2502 - val_loss: 99.6250 - val_mae: 9.4783\n",
      "Epoch 106/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 108.8725 - mae: 10.2794 - val_loss: 95.9865 - val_mae: 9.2825\n",
      "Epoch 107/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 105.3056 - mae: 10.1445 - val_loss: 94.4628 - val_mae: 9.2125\n",
      "Epoch 108/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 87.3385 - mae: 9.1666 - val_loss: 91.3574 - val_mae: 9.0809\n",
      "Epoch 109/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 87.9712 - mae: 9.2466 - val_loss: 85.9432 - val_mae: 8.7863\n",
      "Epoch 110/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 90.6239 - mae: 9.4491 - val_loss: 81.5302 - val_mae: 8.5541\n",
      "Epoch 111/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 76.4266 - mae: 8.5631 - val_loss: 77.9363 - val_mae: 8.2797\n",
      "Epoch 112/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 79.2427 - mae: 8.6870 - val_loss: 73.7398 - val_mae: 8.0200\n",
      "Epoch 113/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 72.1684 - mae: 8.3964 - val_loss: 73.1421 - val_mae: 7.9119\n",
      "Epoch 114/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 77.4260 - mae: 8.6566 - val_loss: 68.5913 - val_mae: 7.7278\n",
      "Epoch 115/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 63.7208 - mae: 7.8753 - val_loss: 65.4871 - val_mae: 7.5485\n",
      "Epoch 116/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 58.5602 - mae: 7.4249 - val_loss: 62.9106 - val_mae: 7.3250\n",
      "Epoch 117/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 76.1645 - mae: 8.4179 - val_loss: 59.4272 - val_mae: 7.1261\n",
      "Epoch 118/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 59.6462 - mae: 7.5945 - val_loss: 57.3770 - val_mae: 6.9817\n",
      "Epoch 119/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 56.7696 - mae: 7.4045 - val_loss: 50.7967 - val_mae: 6.5597\n",
      "Epoch 120/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 44.6484 - mae: 6.4903 - val_loss: 46.3682 - val_mae: 6.1373\n",
      "Epoch 121/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 48.6236 - mae: 6.7665 - val_loss: 47.3960 - val_mae: 6.2264\n",
      "Epoch 122/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 48.1339 - mae: 6.8314 - val_loss: 46.3673 - val_mae: 6.1206\n",
      "Epoch 123/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 42.1376 - mae: 6.3349 - val_loss: 41.6480 - val_mae: 5.7457\n",
      "Epoch 124/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 42.4134 - mae: 6.3392 - val_loss: 40.6593 - val_mae: 5.6073\n",
      "Epoch 125/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 36.3778 - mae: 5.8665 - val_loss: 41.8637 - val_mae: 5.7412\n",
      "Epoch 126/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 34.2223 - mae: 5.6743 - val_loss: 38.6695 - val_mae: 5.4884\n",
      "Epoch 127/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 33.6749 - mae: 5.6698 - val_loss: 36.1326 - val_mae: 5.2233\n",
      "Epoch 128/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 27.4975 - mae: 5.1203 - val_loss: 32.3413 - val_mae: 4.9540\n",
      "Epoch 129/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 26.2572 - mae: 4.9426 - val_loss: 28.5392 - val_mae: 4.6085\n",
      "Epoch 130/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 23.5349 - mae: 4.7042 - val_loss: 27.5395 - val_mae: 4.4684\n",
      "Epoch 131/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 20.7266 - mae: 4.3923 - val_loss: 26.3684 - val_mae: 4.3239\n",
      "Epoch 132/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 24.3124 - mae: 4.7212 - val_loss: 26.1594 - val_mae: 4.3223\n",
      "Epoch 133/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 14.2200 - mae: 3.6038 - val_loss: 22.7011 - val_mae: 3.9775\n",
      "Epoch 134/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 12.9951 - mae: 3.3990 - val_loss: 20.5169 - val_mae: 3.6681\n",
      "Epoch 135/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 14.1306 - mae: 3.4705 - val_loss: 19.3909 - val_mae: 3.5899\n",
      "Epoch 136/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 13.0727 - mae: 3.4180 - val_loss: 18.9124 - val_mae: 3.4345\n",
      "Epoch 137/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 12.4879 - mae: 3.2964 - val_loss: 17.7883 - val_mae: 3.3253\n",
      "Epoch 138/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 11.0007 - mae: 3.0114 - val_loss: 17.5456 - val_mae: 3.2319\n",
      "Epoch 139/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 9.3213 - mae: 2.6444 - val_loss: 16.1227 - val_mae: 2.9698\n",
      "Epoch 140/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 9.1110 - mae: 2.7033 - val_loss: 14.2190 - val_mae: 2.7653\n",
      "Epoch 141/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 6.1095 - mae: 2.1163 - val_loss: 13.8972 - val_mae: 2.6897\n",
      "Epoch 142/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 7.5591 - mae: 2.4053 - val_loss: 15.0386 - val_mae: 2.8164\n",
      "Epoch 143/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 4.2363 - mae: 1.7481 - val_loss: 13.3115 - val_mae: 2.6527\n",
      "Epoch 144/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.6941 - mae: 1.3569 - val_loss: 12.6068 - val_mae: 2.5652\n",
      "Epoch 145/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 3.6045 - mae: 1.5870 - val_loss: 12.6419 - val_mae: 2.5416\n",
      "Epoch 146/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.9256 - mae: 1.0842 - val_loss: 13.4859 - val_mae: 2.6285\n",
      "Epoch 147/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.7656 - mae: 1.0145 - val_loss: 13.6906 - val_mae: 2.6895\n",
      "Epoch 148/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 2.0940 - mae: 1.1616 - val_loss: 16.1439 - val_mae: 2.7092\n",
      "Epoch 149/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 4.0687 - mae: 1.5789 - val_loss: 13.2352 - val_mae: 2.6519\n",
      "Epoch 150/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.0241 - mae: 1.5868 - val_loss: 12.1301 - val_mae: 2.5344\n",
      "Epoch 151/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.5821 - mae: 1.2953 - val_loss: 11.8652 - val_mae: 2.5023\n",
      "Epoch 152/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.1953 - mae: 1.1659 - val_loss: 11.7854 - val_mae: 2.5444\n",
      "Epoch 153/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 2.1639 - mae: 1.2002 - val_loss: 12.5162 - val_mae: 2.5858\n",
      "Epoch 154/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2.4787 - mae: 1.1637 - val_loss: 13.2145 - val_mae: 2.6153\n",
      "Epoch 155/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.5834 - mae: 1.2426 - val_loss: 12.1201 - val_mae: 2.5819\n",
      "Epoch 156/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.3490 - mae: 0.8778 - val_loss: 12.7130 - val_mae: 2.6482\n",
      "Epoch 157/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.3076 - mae: 0.8446 - val_loss: 12.7525 - val_mae: 2.5920\n",
      "Epoch 158/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.7330 - mae: 1.0555 - val_loss: 12.4250 - val_mae: 2.6308\n",
      "Epoch 159/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.7182 - mae: 1.2922 - val_loss: 12.1289 - val_mae: 2.5510\n",
      "Epoch 160/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.3953 - mae: 0.8805 - val_loss: 12.3225 - val_mae: 2.5192\n",
      "Epoch 161/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.9290 - mae: 1.0500 - val_loss: 13.0865 - val_mae: 2.5206\n",
      "Epoch 162/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.7327 - mae: 1.3293 - val_loss: 13.6235 - val_mae: 2.5166\n",
      "Epoch 163/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 1.2517 - mae: 0.8401 - val_loss: 11.8621 - val_mae: 2.4210\n",
      "Epoch 164/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.5554 - mae: 1.2155 - val_loss: 11.4420 - val_mae: 2.4052\n",
      "Epoch 165/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 2.6542 - mae: 1.3176 - val_loss: 12.2365 - val_mae: 2.4772\n",
      "Epoch 166/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 2.5148 - mae: 1.2069 - val_loss: 12.3967 - val_mae: 2.4987\n",
      "Epoch 167/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.8384 - mae: 1.0921 - val_loss: 13.2806 - val_mae: 2.5664\n",
      "Epoch 168/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.8996 - mae: 1.3533 - val_loss: 12.8804 - val_mae: 2.5448\n",
      "Epoch 169/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.8167 - mae: 1.1120 - val_loss: 13.0849 - val_mae: 2.5571\n",
      "Epoch 170/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 5.5205 - mae: 1.8073 - val_loss: 13.0462 - val_mae: 2.5386\n",
      "Epoch 171/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 3.1398 - mae: 1.4525 - val_loss: 13.1833 - val_mae: 2.5262\n",
      "Epoch 172/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 3.6581 - mae: 1.5035 - val_loss: 11.8311 - val_mae: 2.5263\n",
      "Epoch 173/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.9728 - mae: 1.1233 - val_loss: 13.9475 - val_mae: 2.5259\n",
      "Epoch 174/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.0464 - mae: 1.1253 - val_loss: 13.7711 - val_mae: 2.4760\n",
      "Epoch 175/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2.6190 - mae: 1.3055 - val_loss: 13.0171 - val_mae: 2.5854\n",
      "Epoch 176/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.4797 - mae: 0.8841 - val_loss: 14.5172 - val_mae: 2.6635\n",
      "Epoch 177/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.1569 - mae: 0.8136 - val_loss: 13.0004 - val_mae: 2.5424\n",
      "Epoch 178/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2.3764 - mae: 1.2410 - val_loss: 12.9837 - val_mae: 2.5411\n",
      "Epoch 179/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.2158 - mae: 0.8689 - val_loss: 13.9722 - val_mae: 2.5511\n",
      "Epoch 180/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4737 - mae: 0.9437 - val_loss: 11.9751 - val_mae: 2.3487\n",
      "Epoch 181/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 1.7058 - mae: 0.9953 - val_loss: 12.2205 - val_mae: 2.4189\n",
      "Epoch 182/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.5992 - mae: 0.9609 - val_loss: 14.0741 - val_mae: 2.5523\n",
      "Epoch 183/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 2.7152 - mae: 1.3129 - val_loss: 12.2699 - val_mae: 2.4313\n",
      "Epoch 184/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2.6046 - mae: 1.2434 - val_loss: 13.0499 - val_mae: 2.3691\n",
      "Epoch 185/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.5261 - mae: 1.3360 - val_loss: 13.7681 - val_mae: 2.5278\n",
      "Epoch 186/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.4925 - mae: 0.9660 - val_loss: 12.6371 - val_mae: 2.5043\n",
      "Epoch 187/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.5210 - mae: 0.9756 - val_loss: 11.9752 - val_mae: 2.5349\n",
      "Epoch 188/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.5369 - mae: 0.9838 - val_loss: 11.9031 - val_mae: 2.4291\n",
      "Epoch 189/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.2997 - mae: 0.9232 - val_loss: 10.4587 - val_mae: 2.3407\n",
      "Epoch 190/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.0760 - mae: 0.8278 - val_loss: 12.0748 - val_mae: 2.4801\n",
      "Epoch 191/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.8662 - mae: 1.1380 - val_loss: 13.0115 - val_mae: 2.5069\n",
      "Epoch 192/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 2.3008 - mae: 1.2264 - val_loss: 11.4721 - val_mae: 2.4079\n",
      "Epoch 193/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.1797 - mae: 0.8120 - val_loss: 13.2540 - val_mae: 2.5417\n",
      "Epoch 194/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 3.8746 - mae: 1.6879 - val_loss: 12.5762 - val_mae: 2.4775\n",
      "Epoch 195/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 3.3106 - mae: 1.5930 - val_loss: 10.9488 - val_mae: 2.3585\n",
      "Epoch 196/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 1.1262 - mae: 0.8234 - val_loss: 12.9765 - val_mae: 2.5522\n",
      "Epoch 197/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.1179 - mae: 1.1612 - val_loss: 11.0903 - val_mae: 2.3814\n",
      "Epoch 198/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 5.0361 - mae: 1.9126 - val_loss: 12.6841 - val_mae: 2.4578\n",
      "Epoch 199/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.8996 - mae: 1.1028 - val_loss: 14.9639 - val_mae: 2.6800\n",
      "Epoch 200/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 3.5847 - mae: 1.5769 - val_loss: 12.3960 - val_mae: 2.4666\n",
      "Epoch 201/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.8630 - mae: 0.6899 - val_loss: 13.6573 - val_mae: 2.5206\n",
      "Epoch 202/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.8413 - mae: 1.0383 - val_loss: 13.4522 - val_mae: 2.5370\n",
      "Epoch 203/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.8772 - mae: 1.1218 - val_loss: 14.2568 - val_mae: 2.6265\n",
      "Epoch 204/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.1419 - mae: 1.0947 - val_loss: 13.8907 - val_mae: 2.4758\n",
      "Epoch 205/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 4.7793 - mae: 1.8805 - val_loss: 10.8794 - val_mae: 2.3167\n",
      "Epoch 206/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 2.7317 - mae: 1.2774 - val_loss: 12.2403 - val_mae: 2.4679\n",
      "Epoch 207/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 3.1113 - mae: 1.4359 - val_loss: 12.4681 - val_mae: 2.4461\n",
      "Epoch 208/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.3554 - mae: 0.9176 - val_loss: 12.2974 - val_mae: 2.4292\n",
      "Epoch 209/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.9162 - mae: 1.1722 - val_loss: 12.6095 - val_mae: 2.5177\n",
      "Epoch 210/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.2793 - mae: 0.8639 - val_loss: 12.2450 - val_mae: 2.4858\n",
      "Epoch 211/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.3891 - mae: 0.9470 - val_loss: 11.6660 - val_mae: 2.4992\n",
      "Epoch 212/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.4607 - mae: 1.7330 - val_loss: 12.5840 - val_mae: 2.5573\n",
      "Epoch 213/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.9590 - mae: 1.0643 - val_loss: 10.3695 - val_mae: 2.3728\n",
      "Epoch 214/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.9775 - mae: 0.8017 - val_loss: 9.8798 - val_mae: 2.2830\n",
      "Epoch 215/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.2263 - mae: 0.8937 - val_loss: 10.4224 - val_mae: 2.2828\n",
      "Epoch 216/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.1704 - mae: 1.1814 - val_loss: 9.8166 - val_mae: 2.2287\n",
      "Epoch 217/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.1729 - mae: 1.1655 - val_loss: 11.5518 - val_mae: 2.4173\n",
      "Epoch 218/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.1027 - mae: 0.8076 - val_loss: 11.5599 - val_mae: 2.4442\n",
      "Epoch 219/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 3.4926 - mae: 1.5557 - val_loss: 11.1423 - val_mae: 2.3852\n",
      "Epoch 220/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.8801 - mae: 0.9966 - val_loss: 12.8544 - val_mae: 2.4417\n",
      "Epoch 221/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.9524 - mae: 0.7317 - val_loss: 12.9118 - val_mae: 2.4497\n",
      "Epoch 222/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.8992 - mae: 1.3812 - val_loss: 12.4928 - val_mae: 2.4268\n",
      "Epoch 223/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 2.6082 - mae: 1.3277 - val_loss: 12.3952 - val_mae: 2.5422\n",
      "Epoch 224/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.0643 - mae: 1.7184 - val_loss: 11.1037 - val_mae: 2.4016\n",
      "Epoch 225/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.7230 - mae: 1.0011 - val_loss: 12.3295 - val_mae: 2.4274\n",
      "Epoch 226/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2163 - mae: 0.8394 - val_loss: 11.0501 - val_mae: 2.3611\n",
      "Epoch 227/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.7383 - mae: 1.0871 - val_loss: 10.2368 - val_mae: 2.3198\n",
      "Epoch 228/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.0011 - mae: 0.7727 - val_loss: 10.0170 - val_mae: 2.2523\n",
      "Epoch 229/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.1126 - mae: 1.1888 - val_loss: 10.3342 - val_mae: 2.3628\n",
      "Epoch 230/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.1433 - mae: 0.8246 - val_loss: 11.5003 - val_mae: 2.4269\n",
      "Epoch 231/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.3343 - mae: 0.9491 - val_loss: 11.5054 - val_mae: 2.3601\n",
      "Epoch 232/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2910 - mae: 0.8957 - val_loss: 10.6808 - val_mae: 2.3839\n",
      "Epoch 233/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 3.2762 - mae: 1.5287 - val_loss: 11.0536 - val_mae: 2.4384\n",
      "Epoch 234/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.3349 - mae: 0.9685 - val_loss: 12.1031 - val_mae: 2.4583\n",
      "Epoch 235/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.0640 - mae: 0.7875 - val_loss: 12.1164 - val_mae: 2.4586\n",
      "Epoch 236/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.0657 - mae: 0.8109 - val_loss: 12.8529 - val_mae: 2.5047\n",
      "Epoch 237/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.5812 - mae: 0.9599 - val_loss: 12.4275 - val_mae: 2.5747\n",
      "Epoch 238/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.6669 - mae: 1.3181 - val_loss: 13.2105 - val_mae: 2.5757\n",
      "Epoch 239/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2069 - mae: 0.8750 - val_loss: 13.7765 - val_mae: 2.6065\n",
      "Epoch 240/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.9926 - mae: 0.7751 - val_loss: 13.2846 - val_mae: 2.6020\n",
      "Epoch 241/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.7805 - mae: 0.6798 - val_loss: 11.0755 - val_mae: 2.3828\n",
      "Epoch 242/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.9148 - mae: 0.7195 - val_loss: 11.4882 - val_mae: 2.3915\n",
      "Epoch 243/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 5.3364 - mae: 2.0167 - val_loss: 12.5056 - val_mae: 2.4872\n",
      "Epoch 244/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.3907 - mae: 0.8765 - val_loss: 11.6167 - val_mae: 2.4693\n",
      "Epoch 245/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.4381 - mae: 0.9069 - val_loss: 11.9852 - val_mae: 2.5283\n",
      "Epoch 246/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7350 - mae: 0.6512 - val_loss: 11.9789 - val_mae: 2.5147\n",
      "Epoch 247/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.2200 - mae: 1.7141 - val_loss: 11.5676 - val_mae: 2.4491\n",
      "Epoch 248/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.1998 - mae: 0.9022 - val_loss: 11.8806 - val_mae: 2.4378\n",
      "Epoch 249/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9599 - mae: 0.7589 - val_loss: 12.5097 - val_mae: 2.4936\n",
      "Epoch 250/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.7031 - mae: 1.0479 - val_loss: 12.9499 - val_mae: 2.4714\n",
      "Epoch 251/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 2.5256 - mae: 1.2277 - val_loss: 11.4563 - val_mae: 2.4169\n",
      "Epoch 252/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.3449 - mae: 1.1421 - val_loss: 11.8811 - val_mae: 2.4446\n",
      "Epoch 253/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.1005 - mae: 0.8159 - val_loss: 12.9671 - val_mae: 2.4866\n",
      "Epoch 254/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.0866 - mae: 1.4153 - val_loss: 13.6098 - val_mae: 2.5275\n",
      "Epoch 255/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 3.7920 - mae: 1.5960 - val_loss: 14.9232 - val_mae: 2.5929\n",
      "Epoch 256/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9509 - mae: 0.7402 - val_loss: 13.6564 - val_mae: 2.5735\n",
      "Epoch 257/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.9298 - mae: 1.0672 - val_loss: 11.6729 - val_mae: 2.4682\n",
      "Epoch 258/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.3256 - mae: 1.2025 - val_loss: 12.4739 - val_mae: 2.4907\n",
      "Epoch 259/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.2067 - mae: 1.1804 - val_loss: 11.5994 - val_mae: 2.4469\n",
      "Epoch 260/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 1.2293 - mae: 0.9188 - val_loss: 11.4852 - val_mae: 2.3643\n",
      "Epoch 261/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.0412 - mae: 1.6615 - val_loss: 10.8213 - val_mae: 2.3767\n",
      "Epoch 262/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.1472 - mae: 1.1605 - val_loss: 10.6478 - val_mae: 2.3741\n",
      "Epoch 263/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.6967 - mae: 0.9666 - val_loss: 11.3432 - val_mae: 2.4046\n",
      "Epoch 264/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.3979 - mae: 0.9475 - val_loss: 11.0425 - val_mae: 2.3928\n",
      "Epoch 265/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.0870 - mae: 0.8451 - val_loss: 10.5955 - val_mae: 2.3840\n",
      "Epoch 266/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.7606 - mae: 1.0386 - val_loss: 10.7232 - val_mae: 2.3702\n",
      "Epoch 267/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 3.9688 - mae: 1.6768 - val_loss: 10.1106 - val_mae: 2.3283\n",
      "Epoch 268/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 1.7767 - mae: 0.9963 - val_loss: 9.7883 - val_mae: 2.3190\n",
      "Epoch 269/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.3971 - mae: 0.9635 - val_loss: 10.9105 - val_mae: 2.3628\n",
      "Epoch 270/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.4893 - mae: 0.9655 - val_loss: 10.5447 - val_mae: 2.3933\n",
      "Epoch 271/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.9959 - mae: 0.7410 - val_loss: 10.8090 - val_mae: 2.3376\n",
      "Epoch 272/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9373 - mae: 0.7445 - val_loss: 10.7904 - val_mae: 2.3164\n",
      "Epoch 273/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.3800 - mae: 0.8980 - val_loss: 10.7596 - val_mae: 2.3646\n",
      "Epoch 274/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.7674 - mae: 1.0741 - val_loss: 11.2697 - val_mae: 2.3696\n",
      "Epoch 275/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.1787 - mae: 0.8409 - val_loss: 10.9040 - val_mae: 2.3942\n",
      "Epoch 276/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.4719 - mae: 0.9366 - val_loss: 11.1418 - val_mae: 2.3880\n",
      "Epoch 277/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.3253 - mae: 0.9347 - val_loss: 11.0555 - val_mae: 2.3820\n",
      "Epoch 278/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.2221 - mae: 1.7127 - val_loss: 10.9222 - val_mae: 2.3611\n",
      "Epoch 279/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.5824 - mae: 0.9527 - val_loss: 12.2183 - val_mae: 2.4204\n",
      "Epoch 280/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.8847 - mae: 1.0333 - val_loss: 11.1150 - val_mae: 2.3858\n",
      "Epoch 281/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.5973 - mae: 1.0294 - val_loss: 11.5036 - val_mae: 2.4124\n",
      "Epoch 282/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.0581 - mae: 0.7920 - val_loss: 11.4056 - val_mae: 2.3787\n",
      "Epoch 283/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.0478 - mae: 1.7080 - val_loss: 10.1349 - val_mae: 2.3326\n",
      "Epoch 284/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.9922 - mae: 1.1249 - val_loss: 12.0199 - val_mae: 2.4310\n",
      "Epoch 285/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.0379 - mae: 1.0964 - val_loss: 11.0720 - val_mae: 2.3966\n",
      "Epoch 286/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 2.5414 - mae: 1.3209 - val_loss: 11.1400 - val_mae: 2.3211\n",
      "Epoch 287/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.6787 - mae: 1.0219 - val_loss: 11.5534 - val_mae: 2.3831\n",
      "Epoch 288/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.7932 - mae: 1.0540 - val_loss: 10.6418 - val_mae: 2.3982\n",
      "Epoch 289/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.7669 - mae: 0.6894 - val_loss: 11.1386 - val_mae: 2.3515\n",
      "Epoch 290/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.0658 - mae: 0.8229 - val_loss: 10.8669 - val_mae: 2.3222\n",
      "Epoch 291/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.2421 - mae: 0.9098 - val_loss: 11.7173 - val_mae: 2.3956\n",
      "Epoch 292/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.9380 - mae: 0.7870 - val_loss: 12.1781 - val_mae: 2.4101\n",
      "Epoch 293/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7561 - mae: 0.6885 - val_loss: 11.0200 - val_mae: 2.3663\n",
      "Epoch 294/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.9825 - mae: 1.1900 - val_loss: 10.5206 - val_mae: 2.3418\n",
      "Epoch 295/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4042 - mae: 0.9822 - val_loss: 11.6061 - val_mae: 2.4501\n",
      "Epoch 296/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2514 - mae: 0.9111 - val_loss: 11.6445 - val_mae: 2.4762\n",
      "Epoch 297/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.2839 - mae: 1.5558 - val_loss: 11.2037 - val_mae: 2.3317\n",
      "Epoch 298/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7259 - mae: 0.6492 - val_loss: 11.1153 - val_mae: 2.3580\n",
      "Epoch 299/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4102 - mae: 0.9136 - val_loss: 12.0996 - val_mae: 2.4733\n",
      "Epoch 300/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.9901 - mae: 1.1854 - val_loss: 11.8041 - val_mae: 2.4515\n",
      "Epoch 301/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.2544 - mae: 0.8768 - val_loss: 13.6939 - val_mae: 2.5239\n",
      "Epoch 302/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.6686 - mae: 1.0444 - val_loss: 12.2936 - val_mae: 2.4151\n",
      "Epoch 303/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.1316 - mae: 0.7712 - val_loss: 12.9341 - val_mae: 2.4830\n",
      "Epoch 304/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7109 - mae: 0.6687 - val_loss: 13.4870 - val_mae: 2.5511\n",
      "Epoch 305/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.2597 - mae: 0.8445 - val_loss: 12.7090 - val_mae: 2.4695\n",
      "Epoch 306/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.3340 - mae: 1.2214 - val_loss: 14.7843 - val_mae: 2.6223\n",
      "Epoch 307/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 2.0858 - mae: 1.0776 - val_loss: 14.7854 - val_mae: 2.6251\n",
      "Epoch 308/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.4453 - mae: 0.9808 - val_loss: 13.1797 - val_mae: 2.4774\n",
      "Epoch 309/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.0185 - mae: 0.7843 - val_loss: 14.0689 - val_mae: 2.5210\n",
      "Epoch 310/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.3507 - mae: 1.2611 - val_loss: 12.6295 - val_mae: 2.4176\n",
      "Epoch 311/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.9232 - mae: 0.7868 - val_loss: 12.7752 - val_mae: 2.4383\n",
      "Epoch 312/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.9607 - mae: 1.1867 - val_loss: 14.9619 - val_mae: 2.6007\n",
      "Epoch 313/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.9340 - mae: 1.4456 - val_loss: 12.3689 - val_mae: 2.4047\n",
      "Epoch 314/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 1.7710 - mae: 1.0725 - val_loss: 11.6648 - val_mae: 2.3804\n",
      "Epoch 315/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 1.3147 - mae: 0.8552 - val_loss: 13.4076 - val_mae: 2.4999\n",
      "Epoch 316/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.2571 - mae: 0.8754 - val_loss: 12.5006 - val_mae: 2.4780\n",
      "Epoch 317/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.5363 - mae: 1.0364 - val_loss: 12.9784 - val_mae: 2.5472\n",
      "Epoch 318/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.8624 - mae: 1.1456 - val_loss: 13.7939 - val_mae: 2.5497\n",
      "Epoch 319/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.2880 - mae: 1.2114 - val_loss: 12.6007 - val_mae: 2.4334\n",
      "Epoch 320/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.5825 - mae: 0.9644 - val_loss: 12.2467 - val_mae: 2.4143\n",
      "Epoch 321/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 2.7952 - mae: 1.3903 - val_loss: 12.8515 - val_mae: 2.4568\n",
      "Epoch 322/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.2635 - mae: 1.1720 - val_loss: 13.8328 - val_mae: 2.4995\n",
      "Epoch 323/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.7334 - mae: 1.1074 - val_loss: 14.1242 - val_mae: 2.4487\n",
      "Epoch 324/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.9589 - mae: 1.5034 - val_loss: 15.0033 - val_mae: 2.4933\n",
      "Epoch 325/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.2315 - mae: 0.8893 - val_loss: 14.9650 - val_mae: 2.5127\n",
      "Epoch 326/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.7920 - mae: 1.3641 - val_loss: 14.6220 - val_mae: 2.5329\n",
      "Epoch 327/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.9535 - mae: 0.7388 - val_loss: 12.5599 - val_mae: 2.4003\n",
      "Epoch 328/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.9348 - mae: 1.3302 - val_loss: 12.6127 - val_mae: 2.3707\n",
      "Epoch 329/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.9721 - mae: 1.1156 - val_loss: 11.8963 - val_mae: 2.3212\n",
      "Epoch 330/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.8942 - mae: 1.0813 - val_loss: 12.8302 - val_mae: 2.3839\n",
      "Epoch 331/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.7276 - mae: 1.0420 - val_loss: 13.9938 - val_mae: 2.4507\n",
      "Epoch 332/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.5903 - mae: 1.3274 - val_loss: 12.9033 - val_mae: 2.4436\n",
      "Epoch 333/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.3531 - mae: 0.9368 - val_loss: 11.7490 - val_mae: 2.3523\n",
      "Epoch 334/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.6573 - mae: 1.2942 - val_loss: 11.6196 - val_mae: 2.3668\n",
      "Epoch 335/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 2.9135 - mae: 1.3105 - val_loss: 11.4189 - val_mae: 2.3485\n",
      "Epoch 336/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.7248 - mae: 1.0817 - val_loss: 10.9042 - val_mae: 2.3435\n",
      "Epoch 337/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.6534 - mae: 1.0418 - val_loss: 12.1726 - val_mae: 2.3848\n",
      "Epoch 338/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0529 - mae: 0.8229 - val_loss: 12.1608 - val_mae: 2.4439\n",
      "Epoch 339/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.0379 - mae: 0.7709 - val_loss: 11.9151 - val_mae: 2.4373\n",
      "Epoch 340/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.8763 - mae: 1.3258 - val_loss: 11.2305 - val_mae: 2.3516\n",
      "Epoch 341/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 3.1944 - mae: 1.4700 - val_loss: 11.6847 - val_mae: 2.4198\n",
      "Epoch 342/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.9169 - mae: 1.0077 - val_loss: 10.6650 - val_mae: 2.2627\n",
      "Epoch 343/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.4534 - mae: 0.9890 - val_loss: 9.7090 - val_mae: 2.2344\n",
      "Epoch 344/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.4051 - mae: 0.9044 - val_loss: 10.8575 - val_mae: 2.3769\n",
      "Epoch 345/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 3.2069 - mae: 1.5749 - val_loss: 10.9138 - val_mae: 2.3284\n",
      "Epoch 346/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.4217 - mae: 0.9960 - val_loss: 10.4401 - val_mae: 2.2401\n",
      "Epoch 347/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.0003 - mae: 1.1679 - val_loss: 10.9780 - val_mae: 2.3179\n",
      "Epoch 348/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 2.9433 - mae: 1.2769 - val_loss: 12.9267 - val_mae: 2.4842\n",
      "Epoch 349/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2.2977 - mae: 1.2923 - val_loss: 11.9596 - val_mae: 2.3483\n",
      "Epoch 350/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.5984 - mae: 0.9908 - val_loss: 10.8879 - val_mae: 2.2469\n",
      "Epoch 351/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 5.1372 - mae: 1.9477 - val_loss: 11.2837 - val_mae: 2.3253\n",
      "Epoch 352/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2.1639 - mae: 1.2602 - val_loss: 11.0255 - val_mae: 2.2581\n",
      "Epoch 353/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.6124 - mae: 1.3802 - val_loss: 11.5617 - val_mae: 2.3353\n",
      "Epoch 354/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1723 - mae: 0.8927 - val_loss: 11.5813 - val_mae: 2.3887\n",
      "Epoch 355/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1026 - mae: 0.7729 - val_loss: 12.1046 - val_mae: 2.4562\n",
      "Epoch 356/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.8303 - mae: 0.7118 - val_loss: 12.5570 - val_mae: 2.4698\n",
      "Epoch 357/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.0799 - mae: 0.8350 - val_loss: 12.1864 - val_mae: 2.3669\n",
      "Epoch 358/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.9510 - mae: 0.7583 - val_loss: 12.1662 - val_mae: 2.4082\n",
      "Epoch 359/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.1486 - mae: 0.8880 - val_loss: 11.1411 - val_mae: 2.4395\n",
      "Epoch 360/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 5.0767 - mae: 1.9847 - val_loss: 12.5658 - val_mae: 2.4877\n",
      "Epoch 361/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.5417 - mae: 0.9016 - val_loss: 11.8724 - val_mae: 2.4307\n",
      "Epoch 362/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.6517 - mae: 0.6446 - val_loss: 11.7373 - val_mae: 2.4424\n",
      "Epoch 363/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.0819 - mae: 1.2103 - val_loss: 11.6095 - val_mae: 2.4313\n",
      "Epoch 364/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.0916 - mae: 0.8160 - val_loss: 11.2374 - val_mae: 2.3160\n",
      "Epoch 365/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.9616 - mae: 1.4277 - val_loss: 11.3512 - val_mae: 2.2806\n",
      "Epoch 366/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.6451 - mae: 0.6280 - val_loss: 12.1062 - val_mae: 2.3852\n",
      "Epoch 367/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.9696 - mae: 0.7797 - val_loss: 11.7524 - val_mae: 2.3655\n",
      "Epoch 368/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.9942 - mae: 1.1814 - val_loss: 12.2568 - val_mae: 2.3951\n",
      "Epoch 369/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.6715 - mae: 0.6396 - val_loss: 10.9530 - val_mae: 2.2618\n",
      "Epoch 370/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.0379 - mae: 0.8357 - val_loss: 10.5577 - val_mae: 2.2390\n",
      "Epoch 371/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.3437 - mae: 1.2965 - val_loss: 12.3354 - val_mae: 2.3905\n",
      "Epoch 372/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.8910 - mae: 0.7071 - val_loss: 11.3521 - val_mae: 2.3285\n",
      "Epoch 373/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.0070 - mae: 1.1236 - val_loss: 11.0883 - val_mae: 2.2908\n",
      "Epoch 374/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.3328 - mae: 1.3365 - val_loss: 11.6869 - val_mae: 2.3731\n",
      "Epoch 375/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.4338 - mae: 0.5100 - val_loss: 11.2770 - val_mae: 2.3527\n",
      "Epoch 376/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.2919 - mae: 1.3144 - val_loss: 11.7240 - val_mae: 2.4241\n",
      "Epoch 377/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 2.4378 - mae: 1.3975 - val_loss: 13.2108 - val_mae: 2.5252\n",
      "Epoch 378/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 1.9314 - mae: 1.1853 - val_loss: 12.8114 - val_mae: 2.4927\n",
      "Epoch 379/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.3697 - mae: 0.9605 - val_loss: 12.0550 - val_mae: 2.4895\n",
      "Epoch 380/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.2643 - mae: 0.8314 - val_loss: 11.9554 - val_mae: 2.4444\n",
      "Epoch 381/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.4702 - mae: 1.0202 - val_loss: 12.1454 - val_mae: 2.4586\n",
      "Epoch 382/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.5300 - mae: 0.5778 - val_loss: 11.7744 - val_mae: 2.4096\n",
      "Epoch 383/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.2798 - mae: 0.9175 - val_loss: 12.2171 - val_mae: 2.4507\n",
      "Epoch 384/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.3317 - mae: 1.2236 - val_loss: 12.5257 - val_mae: 2.4988\n",
      "Epoch 385/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.5322 - mae: 0.9140 - val_loss: 12.2914 - val_mae: 2.4511\n",
      "Epoch 386/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.0354 - mae: 0.8491 - val_loss: 11.4750 - val_mae: 2.3494\n",
      "Epoch 387/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 4.4419 - mae: 1.7582 - val_loss: 11.4444 - val_mae: 2.3549\n",
      "Epoch 388/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0540 - mae: 0.8121 - val_loss: 13.2809 - val_mae: 2.5267\n",
      "Epoch 389/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7508 - mae: 0.6543 - val_loss: 13.4653 - val_mae: 2.6003\n",
      "Epoch 390/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.5847 - mae: 0.9708 - val_loss: 13.0622 - val_mae: 2.5493\n",
      "Epoch 391/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.5472 - mae: 1.0199 - val_loss: 14.0462 - val_mae: 2.5350\n",
      "Epoch 392/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.3690 - mae: 0.9537 - val_loss: 11.2909 - val_mae: 2.3220\n",
      "Epoch 393/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 1.5343 - mae: 1.0522 - val_loss: 10.7138 - val_mae: 2.3046\n",
      "Epoch 394/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 3.4005 - mae: 1.5102 - val_loss: 11.5718 - val_mae: 2.3604\n",
      "Epoch 395/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.4023 - mae: 0.9785 - val_loss: 11.7210 - val_mae: 2.3362\n",
      "Epoch 396/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.9826 - mae: 1.1850 - val_loss: 11.9534 - val_mae: 2.3854\n",
      "Epoch 397/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.9002 - mae: 0.7346 - val_loss: 10.5571 - val_mae: 2.2389\n",
      "Epoch 398/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0442 - mae: 0.8283 - val_loss: 10.9463 - val_mae: 2.2981\n",
      "Epoch 399/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.3430 - mae: 0.9510 - val_loss: 11.8318 - val_mae: 2.3680\n",
      "Epoch 400/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.9847 - mae: 0.7695 - val_loss: 10.9898 - val_mae: 2.3008\n",
      "Epoch 401/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.3950 - mae: 0.9707 - val_loss: 12.0084 - val_mae: 2.3831\n",
      "Epoch 402/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 3.6322 - mae: 1.6474 - val_loss: 11.6996 - val_mae: 2.4228\n",
      "Epoch 403/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.1380 - mae: 0.8803 - val_loss: 11.2974 - val_mae: 2.3393\n",
      "Epoch 404/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.8099 - mae: 0.7099 - val_loss: 11.8108 - val_mae: 2.3148\n",
      "Epoch 405/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.7595 - mae: 0.6960 - val_loss: 11.8285 - val_mae: 2.3754\n",
      "Epoch 406/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.7850 - mae: 0.6468 - val_loss: 12.3402 - val_mae: 2.4606\n",
      "Epoch 407/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.0070 - mae: 1.1141 - val_loss: 12.5004 - val_mae: 2.4274\n",
      "Epoch 408/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.7941 - mae: 0.7271 - val_loss: 11.8921 - val_mae: 2.4097\n",
      "Epoch 409/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 2.8035 - mae: 1.3924 - val_loss: 12.3516 - val_mae: 2.4380\n",
      "Epoch 410/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.8380 - mae: 1.1291 - val_loss: 12.7883 - val_mae: 2.4653\n",
      "Epoch 411/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9463 - mae: 0.7324 - val_loss: 12.7048 - val_mae: 2.4084\n",
      "Epoch 412/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1166 - mae: 0.7925 - val_loss: 11.9790 - val_mae: 2.3035\n",
      "Epoch 413/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 1.2016 - mae: 0.8863 - val_loss: 11.6492 - val_mae: 2.3188\n",
      "Epoch 414/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.7089 - mae: 1.0944 - val_loss: 11.5485 - val_mae: 2.3526\n",
      "Epoch 415/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.2937 - mae: 0.8752 - val_loss: 12.0913 - val_mae: 2.3550\n",
      "Epoch 416/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.5165 - mae: 0.5617 - val_loss: 10.4194 - val_mae: 2.2728\n",
      "Epoch 417/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 1.1198 - mae: 0.8412 - val_loss: 10.6891 - val_mae: 2.3500\n",
      "Epoch 418/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.0948 - mae: 1.2178 - val_loss: 11.5149 - val_mae: 2.3419\n",
      "Epoch 419/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.5710 - mae: 0.9998 - val_loss: 10.8983 - val_mae: 2.2659\n",
      "Epoch 420/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 3.4048 - mae: 1.5516 - val_loss: 11.0286 - val_mae: 2.3584\n",
      "Epoch 421/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.6283 - mae: 0.6300 - val_loss: 11.6927 - val_mae: 2.3548\n",
      "Epoch 422/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.0028 - mae: 0.7907 - val_loss: 11.5187 - val_mae: 2.3081\n",
      "Epoch 423/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 1.3342 - mae: 0.9292 - val_loss: 11.0143 - val_mae: 2.2849\n",
      "Epoch 424/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.2831 - mae: 0.9471 - val_loss: 12.7975 - val_mae: 2.3616\n",
      "Epoch 425/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 2.2948 - mae: 1.2400 - val_loss: 12.2641 - val_mae: 2.3280\n",
      "Epoch 426/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.6961 - mae: 0.6615 - val_loss: 13.5415 - val_mae: 2.4377\n",
      "Epoch 427/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.6774 - mae: 0.6329 - val_loss: 13.3686 - val_mae: 2.4474\n",
      "Epoch 428/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.1801 - mae: 0.9267 - val_loss: 12.2836 - val_mae: 2.3546\n",
      "Epoch 429/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.8412 - mae: 0.7092 - val_loss: 12.0674 - val_mae: 2.3557\n",
      "Epoch 430/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.6827 - mae: 1.0610 - val_loss: 11.8118 - val_mae: 2.3267\n",
      "Epoch 431/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.0668 - mae: 0.8231 - val_loss: 11.3445 - val_mae: 2.2652\n",
      "Epoch 432/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.7174 - mae: 0.9534 - val_loss: 12.7099 - val_mae: 2.3556\n",
      "Epoch 433/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.6748 - mae: 0.6161 - val_loss: 13.1088 - val_mae: 2.3663\n",
      "Epoch 434/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.8527 - mae: 1.1710 - val_loss: 11.7401 - val_mae: 2.2800\n",
      "Epoch 435/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.4261 - mae: 1.0078 - val_loss: 11.8787 - val_mae: 2.3041\n",
      "Epoch 436/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.3076 - mae: 0.9804 - val_loss: 12.5509 - val_mae: 2.3690\n",
      "Epoch 437/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2.0684 - mae: 1.1246 - val_loss: 11.9863 - val_mae: 2.3263\n",
      "Epoch 438/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.5240 - mae: 1.0192 - val_loss: 11.7473 - val_mae: 2.3167\n",
      "Epoch 439/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.5173 - mae: 1.0555 - val_loss: 12.8664 - val_mae: 2.3834\n",
      "Epoch 440/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.4561 - mae: 1.0124 - val_loss: 12.6402 - val_mae: 2.4265\n",
      "Epoch 441/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.2429 - mae: 0.9219 - val_loss: 11.7017 - val_mae: 2.3440\n",
      "Epoch 442/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.8695 - mae: 1.1644 - val_loss: 12.1429 - val_mae: 2.3448\n",
      "Epoch 443/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.8791 - mae: 1.0794 - val_loss: 12.7838 - val_mae: 2.3792\n",
      "Epoch 444/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 2.3823 - mae: 1.2785 - val_loss: 12.3623 - val_mae: 2.3202\n",
      "Epoch 445/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.3001 - mae: 0.9050 - val_loss: 12.1265 - val_mae: 2.3384\n",
      "Epoch 446/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.6943 - mae: 0.6566 - val_loss: 14.0513 - val_mae: 2.4244\n",
      "Epoch 447/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 1.1366 - mae: 0.8925 - val_loss: 12.2565 - val_mae: 2.3559\n",
      "Epoch 448/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.4538 - mae: 0.5137 - val_loss: 12.0293 - val_mae: 2.3484\n",
      "Epoch 449/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.7528 - mae: 0.6812 - val_loss: 12.0126 - val_mae: 2.3621\n",
      "Epoch 450/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.6771 - mae: 0.6726 - val_loss: 12.0493 - val_mae: 2.3447\n",
      "Epoch 451/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.6289 - mae: 0.6140 - val_loss: 12.9447 - val_mae: 2.4447\n",
      "Epoch 452/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.8691 - mae: 1.1679 - val_loss: 12.7915 - val_mae: 2.3527\n",
      "Epoch 453/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.1510 - mae: 0.8225 - val_loss: 12.7470 - val_mae: 2.4191\n",
      "Epoch 454/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 3.4166 - mae: 1.5702 - val_loss: 11.3677 - val_mae: 2.3545\n",
      "Epoch 455/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.7182 - mae: 0.6712 - val_loss: 11.5673 - val_mae: 2.3511\n",
      "Epoch 456/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.4333 - mae: 1.3073 - val_loss: 11.5265 - val_mae: 2.3346\n",
      "Epoch 457/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.9781 - mae: 0.7667 - val_loss: 10.1498 - val_mae: 2.2562\n",
      "Epoch 458/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.4376 - mae: 1.3520 - val_loss: 11.8783 - val_mae: 2.4084\n",
      "Epoch 459/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.6024 - mae: 1.0645 - val_loss: 12.4196 - val_mae: 2.4272\n",
      "Epoch 460/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.9379 - mae: 0.7687 - val_loss: 10.9025 - val_mae: 2.3088\n",
      "Epoch 461/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4773 - mae: 0.9137 - val_loss: 13.2402 - val_mae: 2.4820\n",
      "Epoch 462/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.6968 - mae: 1.0780 - val_loss: 12.7214 - val_mae: 2.4633\n",
      "Epoch 463/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.9439 - mae: 0.7364 - val_loss: 12.6841 - val_mae: 2.4453\n",
      "Epoch 464/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.7485 - mae: 1.0104 - val_loss: 12.8573 - val_mae: 2.3809\n",
      "Epoch 465/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.6591 - mae: 0.9738 - val_loss: 11.7058 - val_mae: 2.3328\n",
      "Epoch 466/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7266 - mae: 0.6637 - val_loss: 12.5356 - val_mae: 2.4153\n",
      "Epoch 467/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.4618 - mae: 0.9956 - val_loss: 13.1998 - val_mae: 2.4703\n",
      "Epoch 468/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.6539 - mae: 0.6087 - val_loss: 12.0538 - val_mae: 2.4183\n",
      "Epoch 469/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.3347 - mae: 0.9492 - val_loss: 11.5728 - val_mae: 2.3493\n",
      "Epoch 470/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.8965 - mae: 1.4087 - val_loss: 11.6951 - val_mae: 2.4060\n",
      "Epoch 471/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.2576 - mae: 0.9144 - val_loss: 10.7612 - val_mae: 2.2865\n",
      "Epoch 472/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.7436 - mae: 0.6638 - val_loss: 11.5323 - val_mae: 2.3511\n",
      "Epoch 473/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.5904 - mae: 1.1123 - val_loss: 12.4886 - val_mae: 2.4297\n",
      "Epoch 474/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.3318 - mae: 1.1489 - val_loss: 11.0860 - val_mae: 2.3350\n",
      "Epoch 475/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.1863 - mae: 1.1815 - val_loss: 11.1878 - val_mae: 2.2820\n",
      "Epoch 476/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.2780 - mae: 0.9625 - val_loss: 12.0080 - val_mae: 2.3285\n",
      "Epoch 477/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.5226 - mae: 0.5744 - val_loss: 11.0110 - val_mae: 2.2887\n",
      "Epoch 478/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.4577 - mae: 1.3837 - val_loss: 11.5127 - val_mae: 2.2829\n",
      "Epoch 479/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.8448 - mae: 0.7396 - val_loss: 11.4652 - val_mae: 2.2938\n",
      "Epoch 480/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.0690 - mae: 0.8376 - val_loss: 11.5563 - val_mae: 2.3713\n",
      "Epoch 481/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.4447 - mae: 0.9997 - val_loss: 11.3825 - val_mae: 2.3787\n",
      "Epoch 482/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.1413 - mae: 0.8089 - val_loss: 10.5464 - val_mae: 2.2737\n",
      "Epoch 483/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.0808 - mae: 1.1515 - val_loss: 11.3336 - val_mae: 2.3279\n",
      "Epoch 484/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.3073 - mae: 1.2269 - val_loss: 13.0806 - val_mae: 2.4275\n",
      "Epoch 485/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - loss: 0.7563 - mae: 0.7088 - val_loss: 12.1821 - val_mae: 2.3676\n",
      "Epoch 486/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 329ms/step - loss: 3.5688 - mae: 1.4538 - val_loss: 11.9690 - val_mae: 2.3436\n",
      "Epoch 487/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step - loss: 0.9852 - mae: 0.7981 - val_loss: 12.2287 - val_mae: 2.3413\n",
      "Epoch 488/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 341ms/step - loss: 1.6461 - mae: 1.0759 - val_loss: 10.8705 - val_mae: 2.2566\n",
      "Epoch 489/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - loss: 1.0284 - mae: 0.8018 - val_loss: 11.6388 - val_mae: 2.3216\n",
      "Epoch 490/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 323ms/step - loss: 1.2737 - mae: 0.8805 - val_loss: 11.1744 - val_mae: 2.3249\n",
      "Epoch 491/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 339ms/step - loss: 1.0141 - mae: 0.7900 - val_loss: 12.1198 - val_mae: 2.3040\n",
      "Epoch 492/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 330ms/step - loss: 2.2011 - mae: 1.1217 - val_loss: 11.8511 - val_mae: 2.3000\n",
      "Epoch 493/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325ms/step - loss: 0.5404 - mae: 0.6061 - val_loss: 11.6657 - val_mae: 2.3684\n",
      "Epoch 494/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 327ms/step - loss: 1.8639 - mae: 1.1721 - val_loss: 11.9121 - val_mae: 2.3525\n",
      "Epoch 495/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 356ms/step - loss: 1.6458 - mae: 1.0489 - val_loss: 11.0500 - val_mae: 2.2728\n",
      "Epoch 496/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 329ms/step - loss: 1.0135 - mae: 0.8207 - val_loss: 11.4735 - val_mae: 2.3604\n",
      "Epoch 497/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 329ms/step - loss: 1.1649 - mae: 0.8829 - val_loss: 11.6341 - val_mae: 2.3612\n",
      "Epoch 498/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 330ms/step - loss: 0.9352 - mae: 0.7605 - val_loss: 11.9901 - val_mae: 2.3381\n",
      "Epoch 499/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 330ms/step - loss: 1.1963 - mae: 0.9230 - val_loss: 11.5322 - val_mae: 2.2921\n",
      "Epoch 500/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 337ms/step - loss: 0.4972 - mae: 0.5616 - val_loss: 12.1887 - val_mae: 2.3331\n",
      "Epoch 501/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 334ms/step - loss: 0.9492 - mae: 0.7513 - val_loss: 12.7878 - val_mae: 2.3478\n",
      "Epoch 502/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 331ms/step - loss: 1.9598 - mae: 1.1369 - val_loss: 12.4049 - val_mae: 2.3817\n",
      "Epoch 503/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 321ms/step - loss: 1.3557 - mae: 0.9589 - val_loss: 11.6140 - val_mae: 2.3382\n",
      "Epoch 504/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325ms/step - loss: 0.8897 - mae: 0.7224 - val_loss: 12.0902 - val_mae: 2.3013\n",
      "Epoch 505/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 316ms/step - loss: 0.8734 - mae: 0.7443 - val_loss: 11.8324 - val_mae: 2.2770\n",
      "Epoch 506/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step - loss: 2.5728 - mae: 1.4215 - val_loss: 11.0438 - val_mae: 2.2660\n",
      "Epoch 507/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 340ms/step - loss: 1.2537 - mae: 0.9158 - val_loss: 10.7370 - val_mae: 2.2910\n",
      "Epoch 508/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - loss: 0.5646 - mae: 0.5840 - val_loss: 11.7629 - val_mae: 2.3884\n",
      "Epoch 509/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 347ms/step - loss: 0.6354 - mae: 0.6241 - val_loss: 13.3069 - val_mae: 2.4086\n",
      "Epoch 510/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362ms/step - loss: 2.1293 - mae: 1.2923 - val_loss: 11.4127 - val_mae: 2.2561\n",
      "Epoch 511/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 355ms/step - loss: 1.7778 - mae: 1.1256 - val_loss: 11.5876 - val_mae: 2.2760\n",
      "Epoch 512/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325ms/step - loss: 0.7847 - mae: 0.6981 - val_loss: 11.2165 - val_mae: 2.2632\n",
      "Epoch 513/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 319ms/step - loss: 0.4807 - mae: 0.5435 - val_loss: 10.9526 - val_mae: 2.2493\n",
      "Epoch 514/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 324ms/step - loss: 2.1303 - mae: 1.2487 - val_loss: 12.2780 - val_mae: 2.3439\n",
      "Epoch 515/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 329ms/step - loss: 2.1043 - mae: 1.1489 - val_loss: 13.3436 - val_mae: 2.4195\n",
      "Epoch 516/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - loss: 1.1865 - mae: 0.9216 - val_loss: 12.0175 - val_mae: 2.3387\n",
      "Epoch 517/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325ms/step - loss: 1.2762 - mae: 0.9130 - val_loss: 11.9640 - val_mae: 2.3624\n",
      "Epoch 518/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - loss: 0.7716 - mae: 0.6705 - val_loss: 12.6100 - val_mae: 2.3940\n",
      "Epoch 519/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 338ms/step - loss: 0.7456 - mae: 0.6852 - val_loss: 12.3026 - val_mae: 2.3691\n",
      "Epoch 520/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 323ms/step - loss: 0.6052 - mae: 0.5989 - val_loss: 12.1862 - val_mae: 2.3473\n",
      "Epoch 521/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 328ms/step - loss: 1.3956 - mae: 0.9693 - val_loss: 11.6643 - val_mae: 2.3374\n",
      "Epoch 522/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step - loss: 0.8726 - mae: 0.7291 - val_loss: 12.3182 - val_mae: 2.3599\n",
      "Epoch 523/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 337ms/step - loss: 0.7816 - mae: 0.6792 - val_loss: 11.9044 - val_mae: 2.3351\n",
      "Epoch 524/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325ms/step - loss: 1.1556 - mae: 0.8672 - val_loss: 11.2086 - val_mae: 2.2880\n",
      "Epoch 525/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325ms/step - loss: 1.1242 - mae: 0.8409 - val_loss: 11.9724 - val_mae: 2.3323\n",
      "Epoch 526/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - loss: 2.2270 - mae: 1.2204 - val_loss: 12.0849 - val_mae: 2.3708\n",
      "Epoch 527/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step - loss: 0.9106 - mae: 0.7542 - val_loss: 11.7276 - val_mae: 2.2935\n",
      "Epoch 528/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step - loss: 0.5180 - mae: 0.5566 - val_loss: 11.4401 - val_mae: 2.2778\n",
      "Epoch 529/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 337ms/step - loss: 3.4668 - mae: 1.7185 - val_loss: 12.6745 - val_mae: 2.3610\n",
      "Epoch 530/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 321ms/step - loss: 1.0765 - mae: 0.7773 - val_loss: 12.5929 - val_mae: 2.3593\n",
      "Epoch 531/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - loss: 3.8032 - mae: 1.6571 - val_loss: 12.3545 - val_mae: 2.3649\n",
      "Epoch 532/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 334ms/step - loss: 0.8783 - mae: 0.7695 - val_loss: 13.6425 - val_mae: 2.4293\n",
      "Epoch 533/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 336ms/step - loss: 1.3612 - mae: 0.9127 - val_loss: 13.2595 - val_mae: 2.3668\n",
      "Epoch 534/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - loss: 2.1839 - mae: 1.2164 - val_loss: 11.5492 - val_mae: 2.2765\n",
      "Epoch 535/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - loss: 3.7705 - mae: 1.6480 - val_loss: 11.5124 - val_mae: 2.3037\n",
      "Epoch 536/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 341ms/step - loss: 2.7420 - mae: 1.1677 - val_loss: 10.6625 - val_mae: 2.2532\n",
      "Epoch 537/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step - loss: 1.8302 - mae: 1.0489 - val_loss: 9.6921 - val_mae: 2.1024\n",
      "Epoch 538/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363ms/step - loss: 2.0960 - mae: 0.9786 - val_loss: 9.7896 - val_mae: 2.1444\n",
      "Epoch 539/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362ms/step - loss: 1.0665 - mae: 0.8508 - val_loss: 10.8354 - val_mae: 2.2561\n",
      "Epoch 540/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 334ms/step - loss: 1.0119 - mae: 0.8146 - val_loss: 10.1877 - val_mae: 2.2318\n",
      "Epoch 541/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325ms/step - loss: 0.9002 - mae: 0.7613 - val_loss: 10.6208 - val_mae: 2.2017\n",
      "Epoch 542/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 329ms/step - loss: 2.0347 - mae: 1.2507 - val_loss: 10.2022 - val_mae: 2.2279\n",
      "Epoch 543/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 327ms/step - loss: 1.7384 - mae: 1.1009 - val_loss: 10.7968 - val_mae: 2.2742\n",
      "Epoch 544/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 321ms/step - loss: 2.9094 - mae: 1.4732 - val_loss: 11.1854 - val_mae: 2.2285\n",
      "Epoch 545/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - loss: 1.5653 - mae: 1.0450 - val_loss: 11.2954 - val_mae: 2.2615\n",
      "Epoch 546/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 357ms/step - loss: 2.6251 - mae: 1.3944 - val_loss: 11.4586 - val_mae: 2.3061\n",
      "Epoch 547/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 336ms/step - loss: 1.5974 - mae: 1.0629 - val_loss: 11.5040 - val_mae: 2.2621\n",
      "Epoch 548/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - loss: 1.2083 - mae: 0.9167 - val_loss: 11.1325 - val_mae: 2.2405\n",
      "Epoch 549/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 344ms/step - loss: 0.8159 - mae: 0.7108 - val_loss: 11.2951 - val_mae: 2.2610\n",
      "Epoch 550/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242ms/step - loss: 1.4151 - mae: 1.0237 - val_loss: 11.5509 - val_mae: 2.3077\n",
      "Epoch 551/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.6971 - mae: 1.1350 - val_loss: 12.3477 - val_mae: 2.3348\n",
      "Epoch 552/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.8798 - mae: 0.7326 - val_loss: 11.6925 - val_mae: 2.2388\n",
      "Epoch 553/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 1.8167 - mae: 1.0926 - val_loss: 11.7974 - val_mae: 2.2499\n",
      "Epoch 554/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 1.4408 - mae: 1.0047 - val_loss: 10.6618 - val_mae: 2.1673\n",
      "Epoch 555/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.8088 - mae: 0.7035 - val_loss: 11.3422 - val_mae: 2.2046\n",
      "Epoch 556/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.8127 - mae: 0.7043 - val_loss: 12.6871 - val_mae: 2.2990\n",
      "Epoch 557/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 1.0532 - mae: 0.8303 - val_loss: 10.9343 - val_mae: 2.1603\n",
      "Epoch 558/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 1.0125 - mae: 0.8246 - val_loss: 11.0208 - val_mae: 2.1950\n",
      "Epoch 559/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.5754 - mae: 1.4297 - val_loss: 12.1606 - val_mae: 2.2538\n",
      "Epoch 560/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.9545 - mae: 0.8133 - val_loss: 12.5789 - val_mae: 2.2733\n",
      "Epoch 561/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.8891 - mae: 0.7470 - val_loss: 10.8620 - val_mae: 2.2076\n",
      "Epoch 562/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8361 - mae: 0.7320 - val_loss: 10.6740 - val_mae: 2.1722\n",
      "Epoch 563/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 1.5833 - mae: 0.9813 - val_loss: 11.3168 - val_mae: 2.2391\n",
      "Epoch 564/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 2.6319 - mae: 1.2863 - val_loss: 10.2212 - val_mae: 2.2336\n",
      "Epoch 565/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 1.2360 - mae: 0.9268 - val_loss: 10.9409 - val_mae: 2.2621\n",
      "Epoch 566/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 2.5615 - mae: 1.2680 - val_loss: 11.1000 - val_mae: 2.2623\n",
      "Epoch 567/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 1.2411 - mae: 0.8994 - val_loss: 11.6184 - val_mae: 2.3365\n",
      "Epoch 568/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.9544 - mae: 1.0759 - val_loss: 11.4439 - val_mae: 2.3371\n",
      "Epoch 569/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.8530 - mae: 0.7438 - val_loss: 10.0986 - val_mae: 2.1960\n",
      "Epoch 570/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.3515 - mae: 0.9908 - val_loss: 10.8894 - val_mae: 2.2759\n",
      "Epoch 571/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 3.5488 - mae: 1.5667 - val_loss: 10.8319 - val_mae: 2.2520\n",
      "Epoch 572/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 1.0629 - mae: 0.7777 - val_loss: 10.6289 - val_mae: 2.1895\n",
      "Epoch 573/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 1.1385 - mae: 0.8827 - val_loss: 10.8721 - val_mae: 2.2413\n",
      "Epoch 574/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.4219 - mae: 0.5249 - val_loss: 10.4651 - val_mae: 2.2358\n",
      "Epoch 575/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.9893 - mae: 0.8433 - val_loss: 10.5583 - val_mae: 2.2328\n",
      "Epoch 576/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.5977 - mae: 1.1957 - val_loss: 11.0765 - val_mae: 2.2560\n",
      "Epoch 577/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 2.6468 - mae: 1.2875 - val_loss: 11.1496 - val_mae: 2.2893\n",
      "Epoch 578/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 1.2309 - mae: 0.8796 - val_loss: 11.2227 - val_mae: 2.3259\n",
      "Epoch 579/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 3.4925 - mae: 1.5222 - val_loss: 10.5812 - val_mae: 2.2752\n",
      "Epoch 580/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 5.1974 - mae: 1.8539 - val_loss: 11.8982 - val_mae: 2.3623\n",
      "Epoch 581/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.0048 - mae: 0.8118 - val_loss: 11.4513 - val_mae: 2.3284\n",
      "Epoch 582/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.3580 - mae: 1.3589 - val_loss: 11.9382 - val_mae: 2.3648\n",
      "Epoch 583/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.2665 - mae: 0.9422 - val_loss: 11.2561 - val_mae: 2.3282\n",
      "Epoch 584/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 3.4864 - mae: 1.6770 - val_loss: 11.1890 - val_mae: 2.2474\n",
      "Epoch 585/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.7478 - mae: 0.6872 - val_loss: 12.6753 - val_mae: 2.3278\n",
      "Epoch 586/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.7596 - mae: 0.7003 - val_loss: 12.0692 - val_mae: 2.2670\n",
      "Epoch 587/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.2134 - mae: 0.8731 - val_loss: 11.4006 - val_mae: 2.2366\n",
      "Epoch 588/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 3.0712 - mae: 1.5277 - val_loss: 12.0955 - val_mae: 2.2727\n",
      "Epoch 589/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.0337 - mae: 0.7880 - val_loss: 10.6600 - val_mae: 2.2131\n",
      "Epoch 590/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.4736 - mae: 0.5424 - val_loss: 11.9679 - val_mae: 2.3882\n",
      "Epoch 591/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.4310 - mae: 1.3021 - val_loss: 11.9455 - val_mae: 2.3581\n",
      "Epoch 592/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.7823 - mae: 1.0870 - val_loss: 10.7962 - val_mae: 2.2858\n",
      "Epoch 593/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.5424 - mae: 0.5722 - val_loss: 12.1586 - val_mae: 2.3518\n",
      "Epoch 594/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.1571 - mae: 0.9022 - val_loss: 12.3111 - val_mae: 2.3479\n",
      "Epoch 595/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.8032 - mae: 0.6794 - val_loss: 12.7602 - val_mae: 2.3738\n",
      "Epoch 596/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.2388 - mae: 0.8331 - val_loss: 12.0169 - val_mae: 2.2840\n",
      "Epoch 597/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.1879 - mae: 0.8721 - val_loss: 11.1125 - val_mae: 2.2531\n",
      "Epoch 598/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.7894 - mae: 0.7003 - val_loss: 10.6857 - val_mae: 2.2322\n",
      "Epoch 599/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.0803 - mae: 1.2902 - val_loss: 11.5229 - val_mae: 2.2788\n",
      "Epoch 600/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2982 - mae: 0.8976 - val_loss: 12.1913 - val_mae: 2.3402\n",
      "Epoch 601/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.4452 - mae: 1.0322 - val_loss: 10.8184 - val_mae: 2.1882\n",
      "Epoch 602/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.0259 - mae: 0.7831 - val_loss: 11.4085 - val_mae: 2.1971\n",
      "Epoch 603/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 3.8403 - mae: 1.7898 - val_loss: 11.2682 - val_mae: 2.2394\n",
      "Epoch 604/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.8014 - mae: 0.7007 - val_loss: 10.4794 - val_mae: 2.2051\n",
      "Epoch 605/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.6705 - mae: 0.6748 - val_loss: 11.7643 - val_mae: 2.3260\n",
      "Epoch 606/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.8781 - mae: 0.9599 - val_loss: 11.8732 - val_mae: 2.3858\n",
      "Epoch 607/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.3212 - mae: 0.9664 - val_loss: 10.7956 - val_mae: 2.2806\n",
      "Epoch 608/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 4.1937 - mae: 1.7756 - val_loss: 11.7685 - val_mae: 2.3604\n",
      "Epoch 609/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.7965 - mae: 0.6912 - val_loss: 11.6973 - val_mae: 2.3235\n",
      "Epoch 610/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1823 - mae: 0.8978 - val_loss: 10.5854 - val_mae: 2.2592\n",
      "Epoch 611/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.0027 - mae: 1.1697 - val_loss: 10.4024 - val_mae: 2.2620\n",
      "Epoch 612/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1804 - mae: 0.9091 - val_loss: 10.7842 - val_mae: 2.2082\n",
      "Epoch 613/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.8970 - mae: 0.7437 - val_loss: 10.7693 - val_mae: 2.2070\n",
      "Epoch 614/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.1710 - mae: 0.9160 - val_loss: 10.1252 - val_mae: 2.2031\n",
      "Epoch 615/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2.2587 - mae: 1.2114 - val_loss: 10.2719 - val_mae: 2.2162\n",
      "Epoch 616/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 6.5872 - mae: 2.1720 - val_loss: 11.5718 - val_mae: 2.2810\n",
      "Epoch 617/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.6696 - mae: 1.1325 - val_loss: 11.4574 - val_mae: 2.3194\n",
      "Epoch 618/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.1008 - mae: 1.2903 - val_loss: 10.6250 - val_mae: 2.2574\n",
      "Epoch 619/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 1.8000 - mae: 1.1106 - val_loss: 10.5969 - val_mae: 2.2044\n",
      "Epoch 620/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.0446 - mae: 0.8168 - val_loss: 10.8855 - val_mae: 2.2325\n",
      "Epoch 621/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.8336 - mae: 1.1656 - val_loss: 11.0747 - val_mae: 2.2895\n",
      "Epoch 622/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 2.6894 - mae: 1.5177 - val_loss: 11.0986 - val_mae: 2.2823\n",
      "Epoch 623/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 2.1301 - mae: 1.2983 - val_loss: 11.9855 - val_mae: 2.3501\n",
      "Epoch 624/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.5818 - mae: 1.4056 - val_loss: 11.4243 - val_mae: 2.2603\n",
      "Epoch 625/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.5895 - mae: 0.5991 - val_loss: 10.7390 - val_mae: 2.1635\n",
      "Epoch 626/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.2231 - mae: 0.7731 - val_loss: 11.7111 - val_mae: 2.2763\n",
      "Epoch 627/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.6955 - mae: 1.0672 - val_loss: 10.9067 - val_mae: 2.1896\n",
      "Epoch 628/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.4741 - mae: 0.5377 - val_loss: 10.5805 - val_mae: 2.1617\n",
      "Epoch 629/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.5324 - mae: 1.0555 - val_loss: 10.1657 - val_mae: 2.1707\n",
      "Epoch 630/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.4750 - mae: 0.5324 - val_loss: 10.1116 - val_mae: 2.1379\n",
      "Epoch 631/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.6616 - mae: 0.6369 - val_loss: 10.7241 - val_mae: 2.1878\n",
      "Epoch 632/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.7488 - mae: 0.6787 - val_loss: 9.7582 - val_mae: 2.1442\n",
      "Epoch 633/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.5210 - mae: 0.5426 - val_loss: 9.6132 - val_mae: 2.1433\n",
      "Epoch 634/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.5974 - mae: 0.5686 - val_loss: 10.4372 - val_mae: 2.2317\n",
      "Epoch 635/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.5105 - mae: 1.0579 - val_loss: 10.5356 - val_mae: 2.2046\n",
      "Epoch 636/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.1769 - mae: 0.9079 - val_loss: 10.6330 - val_mae: 2.1703\n",
      "Epoch 637/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 2.3819 - mae: 1.2248 - val_loss: 11.0455 - val_mae: 2.2277\n",
      "Epoch 638/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.8852 - mae: 1.5038 - val_loss: 11.7963 - val_mae: 2.2658\n",
      "Epoch 639/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.5958 - mae: 1.0469 - val_loss: 11.9481 - val_mae: 2.2874\n",
      "Epoch 640/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.8724 - mae: 1.2174 - val_loss: 11.9625 - val_mae: 2.3172\n",
      "Epoch 641/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.9407 - mae: 1.0975 - val_loss: 11.9706 - val_mae: 2.2885\n",
      "Epoch 642/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.9354 - mae: 0.7633 - val_loss: 11.3600 - val_mae: 2.2751\n",
      "Epoch 643/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.9045 - mae: 1.2030 - val_loss: 10.8052 - val_mae: 2.2700\n",
      "Epoch 644/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.7882 - mae: 1.1567 - val_loss: 11.2236 - val_mae: 2.2768\n",
      "Epoch 645/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.5884 - mae: 0.5959 - val_loss: 10.3698 - val_mae: 2.2357\n",
      "Epoch 646/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.5443 - mae: 0.5832 - val_loss: 10.6831 - val_mae: 2.2164\n",
      "Epoch 647/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.7523 - mae: 1.4865 - val_loss: 11.4248 - val_mae: 2.2620\n",
      "Epoch 648/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8365 - mae: 0.7868 - val_loss: 11.1956 - val_mae: 2.2452\n",
      "Epoch 649/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.5249 - mae: 0.6085 - val_loss: 11.6264 - val_mae: 2.2867\n",
      "Epoch 650/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 3.0654 - mae: 1.6199 - val_loss: 11.8481 - val_mae: 2.2994\n",
      "Epoch 651/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.5312 - mae: 0.5822 - val_loss: 12.2585 - val_mae: 2.2651\n",
      "Epoch 652/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.5419 - mae: 0.5975 - val_loss: 11.9026 - val_mae: 2.2722\n",
      "Epoch 653/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.6483 - mae: 1.1110 - val_loss: 11.2875 - val_mae: 2.2684\n",
      "Epoch 654/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.6594 - mae: 1.0837 - val_loss: 11.7028 - val_mae: 2.2843\n",
      "Epoch 655/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.1490 - mae: 1.2850 - val_loss: 11.7811 - val_mae: 2.2929\n",
      "Epoch 656/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 4.9301 - mae: 1.9533 - val_loss: 12.0570 - val_mae: 2.2536\n",
      "Epoch 657/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.0649 - mae: 0.8711 - val_loss: 11.0166 - val_mae: 2.2217\n",
      "Epoch 658/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.3941 - mae: 0.9574 - val_loss: 11.8386 - val_mae: 2.2456\n",
      "Epoch 659/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 2.3824 - mae: 1.2830 - val_loss: 13.0946 - val_mae: 2.3472\n",
      "Epoch 660/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.1287 - mae: 0.8769 - val_loss: 12.6117 - val_mae: 2.2694\n",
      "Epoch 661/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.1305 - mae: 0.7840 - val_loss: 12.9478 - val_mae: 2.3130\n",
      "Epoch 662/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.2014 - mae: 0.9326 - val_loss: 12.0368 - val_mae: 2.2790\n",
      "Epoch 663/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.5556 - mae: 1.0472 - val_loss: 11.1423 - val_mae: 2.2773\n",
      "Epoch 664/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.2130 - mae: 0.9433 - val_loss: 11.6391 - val_mae: 2.3427\n",
      "Epoch 665/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.8840 - mae: 1.1325 - val_loss: 11.3246 - val_mae: 2.2944\n",
      "Epoch 666/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.3337 - mae: 0.8775 - val_loss: 11.8026 - val_mae: 2.3016\n",
      "Epoch 667/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.6673 - mae: 0.9961 - val_loss: 11.2464 - val_mae: 2.2743\n",
      "Epoch 668/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.4790 - mae: 1.0903 - val_loss: 11.5189 - val_mae: 2.2942\n",
      "Epoch 669/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.5498 - mae: 0.6015 - val_loss: 11.8545 - val_mae: 2.3184\n",
      "Epoch 670/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.2510 - mae: 0.9158 - val_loss: 11.4412 - val_mae: 2.2747\n",
      "Epoch 671/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.6008 - mae: 0.5785 - val_loss: 11.0865 - val_mae: 2.1884\n",
      "Epoch 672/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.1309 - mae: 0.8777 - val_loss: 10.8485 - val_mae: 2.2066\n",
      "Epoch 673/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.8568 - mae: 0.7427 - val_loss: 11.0005 - val_mae: 2.2287\n",
      "Epoch 674/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.5418 - mae: 0.5671 - val_loss: 10.9554 - val_mae: 2.2143\n",
      "Epoch 675/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.4780 - mae: 0.5577 - val_loss: 9.9580 - val_mae: 2.1656\n",
      "Epoch 676/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.7910 - mae: 1.4189 - val_loss: 10.4826 - val_mae: 2.1802\n",
      "Epoch 677/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.8955 - mae: 0.7323 - val_loss: 10.7354 - val_mae: 2.2099\n",
      "Epoch 678/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.4173 - mae: 1.0034 - val_loss: 11.1295 - val_mae: 2.2164\n",
      "Epoch 679/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.6949 - mae: 0.6381 - val_loss: 10.4162 - val_mae: 2.2374\n",
      "Epoch 680/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 4.3933 - mae: 1.8474 - val_loss: 10.3642 - val_mae: 2.2237\n",
      "Epoch 681/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 1.5132 - mae: 1.0348 - val_loss: 10.2704 - val_mae: 2.2260\n",
      "Epoch 682/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.6700 - mae: 0.6293 - val_loss: 10.6300 - val_mae: 2.2483\n",
      "Epoch 683/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.5747 - mae: 0.5900 - val_loss: 10.5534 - val_mae: 2.2456\n",
      "Epoch 684/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 1.6755 - mae: 1.0928 - val_loss: 11.3159 - val_mae: 2.2618\n",
      "Epoch 685/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.9065 - mae: 0.7464 - val_loss: 11.5406 - val_mae: 2.2685\n",
      "Epoch 686/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.5330 - mae: 0.9949 - val_loss: 12.0835 - val_mae: 2.2543\n",
      "Epoch 687/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.3491 - mae: 1.1012 - val_loss: 13.1912 - val_mae: 2.3381\n",
      "Epoch 688/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.0514 - mae: 0.7808 - val_loss: 11.6236 - val_mae: 2.2700\n",
      "Epoch 689/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.9618 - mae: 0.8067 - val_loss: 10.3958 - val_mae: 2.1568\n",
      "Epoch 690/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.5278 - mae: 0.5723 - val_loss: 11.3270 - val_mae: 2.2385\n",
      "Epoch 691/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.3286 - mae: 1.2924 - val_loss: 11.8982 - val_mae: 2.3456\n",
      "Epoch 692/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 2.9972 - mae: 1.4926 - val_loss: 11.7350 - val_mae: 2.2872\n",
      "Epoch 693/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2.4601 - mae: 1.3796 - val_loss: 10.9160 - val_mae: 2.2216\n",
      "Epoch 694/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 3.4008 - mae: 1.6366 - val_loss: 12.0242 - val_mae: 2.3136\n",
      "Epoch 695/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.9110 - mae: 0.7369 - val_loss: 11.2123 - val_mae: 2.2691\n",
      "Epoch 696/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.0819 - mae: 0.8421 - val_loss: 11.8544 - val_mae: 2.2397\n",
      "Epoch 697/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.5068 - mae: 1.0621 - val_loss: 11.4154 - val_mae: 2.2765\n",
      "Epoch 698/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.8337 - mae: 0.7361 - val_loss: 10.4701 - val_mae: 2.1934\n",
      "Epoch 699/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.7397 - mae: 0.6818 - val_loss: 12.3298 - val_mae: 2.2980\n",
      "Epoch 700/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9921 - mae: 0.8231 - val_loss: 11.3206 - val_mae: 2.2770\n",
      "Epoch 701/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.6957 - mae: 0.6956 - val_loss: 10.8361 - val_mae: 2.2300\n",
      "Epoch 702/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 1.3981 - mae: 1.0221 - val_loss: 10.9900 - val_mae: 2.2253\n",
      "Epoch 703/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.5653 - mae: 0.5903 - val_loss: 11.6086 - val_mae: 2.2619\n",
      "Epoch 704/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 1.6040 - mae: 1.0507 - val_loss: 12.5565 - val_mae: 2.2621\n",
      "Epoch 705/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.9238 - mae: 0.7511 - val_loss: 11.3229 - val_mae: 2.1707\n",
      "Epoch 706/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.7871 - mae: 1.1241 - val_loss: 12.0529 - val_mae: 2.2207\n",
      "Epoch 707/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 1.1713 - mae: 0.9278 - val_loss: 12.7977 - val_mae: 2.3311\n",
      "Epoch 708/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.4864 - mae: 0.5646 - val_loss: 11.1249 - val_mae: 2.2361\n",
      "Epoch 709/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.9092 - mae: 0.7746 - val_loss: 11.0390 - val_mae: 2.2214\n",
      "Epoch 710/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9893 - mae: 0.7609 - val_loss: 11.8908 - val_mae: 2.3167\n",
      "Epoch 711/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.7804 - mae: 0.7202 - val_loss: 12.6944 - val_mae: 2.3482\n",
      "Epoch 712/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.9730 - mae: 1.2348 - val_loss: 12.3072 - val_mae: 2.3055\n",
      "Epoch 713/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.8417 - mae: 0.7507 - val_loss: 12.7532 - val_mae: 2.3190\n",
      "Epoch 714/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.8244 - mae: 0.7680 - val_loss: 10.9401 - val_mae: 2.1650\n",
      "Epoch 715/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.7589 - mae: 1.0966 - val_loss: 11.3793 - val_mae: 2.2634\n",
      "Epoch 716/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.4909 - mae: 0.5661 - val_loss: 12.5029 - val_mae: 2.3329\n",
      "Epoch 717/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.9291 - mae: 1.1967 - val_loss: 11.5253 - val_mae: 2.2446\n",
      "Epoch 718/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.7015 - mae: 1.0558 - val_loss: 11.8520 - val_mae: 2.2614\n",
      "Epoch 719/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.9270 - mae: 0.7643 - val_loss: 11.1974 - val_mae: 2.1999\n",
      "Epoch 720/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.0081 - mae: 0.8603 - val_loss: 11.7249 - val_mae: 2.2297\n",
      "Epoch 721/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.8939 - mae: 0.7299 - val_loss: 12.4947 - val_mae: 2.3238\n",
      "Epoch 722/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.4535 - mae: 0.5278 - val_loss: 11.6781 - val_mae: 2.2344\n",
      "Epoch 723/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.6291 - mae: 0.6054 - val_loss: 11.3518 - val_mae: 2.2263\n",
      "Epoch 724/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.3347 - mae: 1.3510 - val_loss: 11.0515 - val_mae: 2.1961\n",
      "Epoch 725/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.6292 - mae: 0.6351 - val_loss: 11.1427 - val_mae: 2.2291\n",
      "Epoch 726/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 1.6268 - mae: 1.0966 - val_loss: 11.4370 - val_mae: 2.2608\n",
      "Epoch 727/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.6429 - mae: 0.6532 - val_loss: 10.5172 - val_mae: 2.2046\n",
      "Epoch 728/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.6765 - mae: 1.1194 - val_loss: 9.9452 - val_mae: 2.1613\n",
      "Epoch 729/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.1820 - mae: 0.9387 - val_loss: 10.7469 - val_mae: 2.1709\n",
      "Epoch 730/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.5401 - mae: 0.5727 - val_loss: 10.2461 - val_mae: 2.1634\n",
      "Epoch 731/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.7203 - mae: 0.6738 - val_loss: 10.0760 - val_mae: 2.2002\n",
      "Epoch 732/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 5.2140 - mae: 1.9632 - val_loss: 11.2880 - val_mae: 2.2793\n",
      "Epoch 733/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.6047 - mae: 0.6058 - val_loss: 10.2690 - val_mae: 2.2272\n",
      "Epoch 734/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.5066 - mae: 0.5444 - val_loss: 11.1426 - val_mae: 2.2561\n",
      "Epoch 735/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.6130 - mae: 1.0835 - val_loss: 10.6545 - val_mae: 2.1997\n",
      "Epoch 736/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.3705 - mae: 0.4596 - val_loss: 10.1991 - val_mae: 2.1962\n",
      "Epoch 737/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.4305 - mae: 1.3200 - val_loss: 11.4943 - val_mae: 2.2717\n",
      "Epoch 738/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.5385 - mae: 1.0117 - val_loss: 10.9278 - val_mae: 2.2444\n",
      "Epoch 739/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.0757 - mae: 0.8462 - val_loss: 10.7852 - val_mae: 2.2875\n",
      "Epoch 740/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 1.9539 - mae: 1.1584 - val_loss: 10.8848 - val_mae: 2.2314\n",
      "Epoch 741/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.1693 - mae: 1.2792 - val_loss: 10.4943 - val_mae: 2.2597\n",
      "Epoch 742/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 1.5306 - mae: 1.0518 - val_loss: 10.0313 - val_mae: 2.2227\n",
      "Epoch 743/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.0993 - mae: 1.2234 - val_loss: 10.5286 - val_mae: 2.1866\n",
      "Epoch 744/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7976 - mae: 0.7270 - val_loss: 9.8929 - val_mae: 2.1406\n",
      "Epoch 745/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 1.0798 - mae: 0.8260 - val_loss: 9.6092 - val_mae: 2.1499\n",
      "Epoch 746/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.6275 - mae: 0.6380 - val_loss: 10.5603 - val_mae: 2.2215\n",
      "Epoch 747/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8386 - mae: 0.7627 - val_loss: 10.7179 - val_mae: 2.2260\n",
      "Epoch 748/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.2632 - mae: 1.3856 - val_loss: 10.8457 - val_mae: 2.2691\n",
      "Epoch 749/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.3633 - mae: 0.4516 - val_loss: 10.6955 - val_mae: 2.2144\n",
      "Epoch 750/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.9426 - mae: 1.1421 - val_loss: 11.8516 - val_mae: 2.2920\n",
      "Epoch 751/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.7816 - mae: 1.1858 - val_loss: 12.4616 - val_mae: 2.3364\n",
      "Epoch 752/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 2.6689 - mae: 1.4648 - val_loss: 10.6397 - val_mae: 2.1784\n",
      "Epoch 753/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.9243 - mae: 0.7420 - val_loss: 10.7171 - val_mae: 2.2139\n",
      "Epoch 754/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.2127 - mae: 1.2493 - val_loss: 11.2752 - val_mae: 2.2359\n",
      "Epoch 755/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.3318 - mae: 0.9768 - val_loss: 10.8375 - val_mae: 2.2524\n",
      "Epoch 756/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.5642 - mae: 0.5957 - val_loss: 10.5766 - val_mae: 2.1970\n",
      "Epoch 757/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 2.0044 - mae: 1.1885 - val_loss: 9.8483 - val_mae: 2.1615\n",
      "Epoch 758/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.5608 - mae: 0.5996 - val_loss: 10.1792 - val_mae: 2.1862\n",
      "Epoch 759/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.0631 - mae: 1.2242 - val_loss: 11.0932 - val_mae: 2.2448\n",
      "Epoch 760/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.7862 - mae: 0.7196 - val_loss: 10.7086 - val_mae: 2.1985\n",
      "Epoch 761/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.6425 - mae: 1.0656 - val_loss: 10.1067 - val_mae: 2.1481\n",
      "Epoch 762/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 1.1937 - mae: 0.9048 - val_loss: 10.0921 - val_mae: 2.1473\n",
      "Epoch 763/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.5454 - mae: 0.5824 - val_loss: 11.6286 - val_mae: 2.2696\n",
      "Epoch 764/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.8811 - mae: 1.0591 - val_loss: 11.6570 - val_mae: 2.2473\n",
      "Epoch 765/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 3.1839 - mae: 1.4787 - val_loss: 11.4246 - val_mae: 2.2540\n",
      "Epoch 766/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 1.0440 - mae: 0.8311 - val_loss: 13.3319 - val_mae: 2.3336\n",
      "Epoch 767/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2.3267 - mae: 1.2953 - val_loss: 12.0117 - val_mae: 2.2562\n",
      "Epoch 768/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.5512 - mae: 0.6004 - val_loss: 11.7485 - val_mae: 2.2127\n",
      "Epoch 769/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.7819 - mae: 0.6648 - val_loss: 12.5197 - val_mae: 2.2843\n",
      "Epoch 770/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.6764 - mae: 0.6619 - val_loss: 11.3237 - val_mae: 2.2152\n",
      "Epoch 771/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.5556 - mae: 0.5942 - val_loss: 11.1443 - val_mae: 2.1850\n",
      "Epoch 772/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.5513 - mae: 0.5651 - val_loss: 11.8544 - val_mae: 2.2558\n",
      "Epoch 773/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.8244 - mae: 1.0497 - val_loss: 11.6000 - val_mae: 2.2491\n",
      "Epoch 774/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.5936 - mae: 1.0579 - val_loss: 11.8004 - val_mae: 2.2447\n",
      "Epoch 775/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.1537 - mae: 0.9309 - val_loss: 11.2507 - val_mae: 2.2146\n",
      "Epoch 776/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.1147 - mae: 0.8258 - val_loss: 11.1048 - val_mae: 2.2243\n",
      "Epoch 777/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.6529 - mae: 1.4358 - val_loss: 10.9660 - val_mae: 2.2447\n",
      "Epoch 778/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.2621 - mae: 0.9742 - val_loss: 9.8105 - val_mae: 2.1679\n",
      "Epoch 779/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 3.7221 - mae: 1.7209 - val_loss: 10.5024 - val_mae: 2.2131\n",
      "Epoch 780/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.4428 - mae: 1.0030 - val_loss: 10.4895 - val_mae: 2.2103\n",
      "Epoch 781/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8505 - mae: 0.7472 - val_loss: 10.9405 - val_mae: 2.2443\n",
      "Epoch 782/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.4960 - mae: 1.0669 - val_loss: 11.0938 - val_mae: 2.2670\n",
      "Epoch 783/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.6222 - mae: 0.6419 - val_loss: 10.9426 - val_mae: 2.2826\n",
      "Epoch 784/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.4619 - mae: 0.9859 - val_loss: 11.4690 - val_mae: 2.3454\n",
      "Epoch 785/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 1.1758 - mae: 0.8230 - val_loss: 10.9570 - val_mae: 2.2443\n",
      "Epoch 786/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.9044 - mae: 0.7560 - val_loss: 11.3201 - val_mae: 2.2367\n",
      "Epoch 787/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.6461 - mae: 1.1026 - val_loss: 11.1489 - val_mae: 2.2167\n",
      "Epoch 788/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.6713 - mae: 0.6456 - val_loss: 11.1568 - val_mae: 2.2509\n",
      "Epoch 789/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.9993 - mae: 0.7961 - val_loss: 11.2560 - val_mae: 2.2671\n",
      "Epoch 790/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.4125 - mae: 0.4902 - val_loss: 11.5027 - val_mae: 2.3027\n",
      "Epoch 791/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 1.2833 - mae: 0.9233 - val_loss: 10.2783 - val_mae: 2.1937\n",
      "Epoch 792/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.9094 - mae: 0.7539 - val_loss: 10.8098 - val_mae: 2.1391\n",
      "Epoch 793/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 3.6938 - mae: 1.6534 - val_loss: 10.8912 - val_mae: 2.1653\n",
      "Epoch 794/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.6566 - mae: 0.6623 - val_loss: 10.8729 - val_mae: 2.1828\n",
      "Epoch 795/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.4410 - mae: 1.0155 - val_loss: 11.3361 - val_mae: 2.2023\n",
      "Epoch 796/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.9201 - mae: 1.2213 - val_loss: 11.5487 - val_mae: 2.2346\n",
      "Epoch 797/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.4843 - mae: 0.5305 - val_loss: 10.8997 - val_mae: 2.1769\n",
      "Epoch 798/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.0650 - mae: 0.8543 - val_loss: 11.2166 - val_mae: 2.2102\n",
      "Epoch 799/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 1.4622 - mae: 0.9862 - val_loss: 11.9534 - val_mae: 2.2917\n",
      "Epoch 800/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 3.0782 - mae: 1.5911 - val_loss: 12.0526 - val_mae: 2.2731\n",
      "Epoch 801/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.5380 - mae: 0.5571 - val_loss: 11.4175 - val_mae: 2.2634\n",
      "Epoch 802/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.8959 - mae: 0.7349 - val_loss: 11.4077 - val_mae: 2.2435\n",
      "Epoch 803/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.8418 - mae: 0.7269 - val_loss: 10.7348 - val_mae: 2.2231\n",
      "Epoch 804/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 1.3350 - mae: 0.9718 - val_loss: 11.1016 - val_mae: 2.2607\n",
      "Epoch 805/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.5183 - mae: 0.5534 - val_loss: 11.1888 - val_mae: 2.2636\n",
      "Epoch 806/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.0389 - mae: 0.8682 - val_loss: 11.5040 - val_mae: 2.2385\n",
      "Epoch 807/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.9370 - mae: 0.7694 - val_loss: 10.3788 - val_mae: 2.1996\n",
      "Epoch 808/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.7369 - mae: 1.0004 - val_loss: 11.3748 - val_mae: 2.2126\n",
      "Epoch 809/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.8208 - mae: 0.7286 - val_loss: 11.2331 - val_mae: 2.1868\n",
      "Epoch 810/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.6419 - mae: 0.6559 - val_loss: 11.4562 - val_mae: 2.2289\n",
      "Epoch 811/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.3232 - mae: 0.9199 - val_loss: 11.1256 - val_mae: 2.1840\n",
      "Epoch 812/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 1.7598 - mae: 1.1018 - val_loss: 10.4033 - val_mae: 2.1689\n",
      "Epoch 813/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 1.0609 - mae: 0.8193 - val_loss: 11.0861 - val_mae: 2.2090\n",
      "Epoch 814/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.7014 - mae: 0.9588 - val_loss: 9.9296 - val_mae: 2.1502\n",
      "Epoch 815/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.3231 - mae: 0.8959 - val_loss: 10.5270 - val_mae: 2.1775\n",
      "Epoch 816/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.3401 - mae: 0.9979 - val_loss: 11.3640 - val_mae: 2.2101\n",
      "Epoch 817/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.7658 - mae: 1.5212 - val_loss: 10.4612 - val_mae: 2.1689\n",
      "Epoch 818/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.3945 - mae: 0.4689 - val_loss: 10.7033 - val_mae: 2.1867\n",
      "Epoch 819/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.9018 - mae: 1.2095 - val_loss: 10.7791 - val_mae: 2.1799\n",
      "Epoch 820/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.6670 - mae: 0.6914 - val_loss: 10.6361 - val_mae: 2.1878\n",
      "Epoch 821/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.5614 - mae: 1.0561 - val_loss: 10.9998 - val_mae: 2.1852\n",
      "Epoch 822/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.5896 - mae: 1.0372 - val_loss: 10.3421 - val_mae: 2.1566\n",
      "Epoch 823/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.5711 - mae: 0.5908 - val_loss: 10.4477 - val_mae: 2.1663\n",
      "Epoch 824/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.3804 - mae: 0.4863 - val_loss: 10.6051 - val_mae: 2.1922\n",
      "Epoch 825/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.0427 - mae: 0.8734 - val_loss: 10.0248 - val_mae: 2.1906\n",
      "Epoch 826/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.2566 - mae: 0.9440 - val_loss: 9.9310 - val_mae: 2.1512\n",
      "Epoch 827/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.9882 - mae: 0.8101 - val_loss: 10.0540 - val_mae: 2.1258\n",
      "Epoch 828/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.3919 - mae: 0.4953 - val_loss: 10.3235 - val_mae: 2.2049\n",
      "Epoch 829/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.6481 - mae: 0.6250 - val_loss: 11.1318 - val_mae: 2.2848\n",
      "Epoch 830/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.8224 - mae: 0.7310 - val_loss: 11.2647 - val_mae: 2.2660\n",
      "Epoch 831/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.3622 - mae: 1.2863 - val_loss: 11.5677 - val_mae: 2.2678\n",
      "Epoch 832/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 3.2562 - mae: 1.4848 - val_loss: 11.1568 - val_mae: 2.2727\n",
      "Epoch 833/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.7159 - mae: 1.0690 - val_loss: 11.8995 - val_mae: 2.3307\n",
      "Epoch 834/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.3649 - mae: 0.9062 - val_loss: 10.3022 - val_mae: 2.2467\n",
      "Epoch 835/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.8763 - mae: 0.7705 - val_loss: 11.0268 - val_mae: 2.2278\n",
      "Epoch 836/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.6693 - mae: 1.0711 - val_loss: 10.7734 - val_mae: 2.1803\n",
      "Epoch 837/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.5346 - mae: 1.0910 - val_loss: 10.5071 - val_mae: 2.1952\n",
      "Epoch 838/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 5.7627 - mae: 1.8942 - val_loss: 11.4027 - val_mae: 2.2391\n",
      "Epoch 839/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.6685 - mae: 0.6642 - val_loss: 11.4773 - val_mae: 2.2384\n",
      "Epoch 840/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.2464 - mae: 0.8352 - val_loss: 11.1778 - val_mae: 2.2381\n",
      "Epoch 841/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.0528 - mae: 1.1489 - val_loss: 11.1583 - val_mae: 2.2487\n",
      "Epoch 842/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.7244 - mae: 0.6694 - val_loss: 11.0162 - val_mae: 2.1562\n",
      "Epoch 843/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 4.2681 - mae: 1.8309 - val_loss: 10.6096 - val_mae: 2.1725\n",
      "Epoch 844/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 2.4237 - mae: 1.4020 - val_loss: 11.2149 - val_mae: 2.2784\n",
      "Epoch 845/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2.7992 - mae: 1.3708 - val_loss: 11.0382 - val_mae: 2.2106\n",
      "Epoch 846/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.7983 - mae: 0.7065 - val_loss: 10.6400 - val_mae: 2.2176\n",
      "Epoch 847/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.2287 - mae: 1.3469 - val_loss: 10.5020 - val_mae: 2.2076\n",
      "Epoch 848/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.4989 - mae: 0.5403 - val_loss: 10.2995 - val_mae: 2.2068\n",
      "Epoch 849/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.3259 - mae: 0.9457 - val_loss: 11.5518 - val_mae: 2.2883\n",
      "Epoch 850/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.6187 - mae: 0.6222 - val_loss: 10.6695 - val_mae: 2.2063\n",
      "Epoch 851/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.2246 - mae: 0.7853 - val_loss: 10.8912 - val_mae: 2.2125\n",
      "Epoch 852/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.3382 - mae: 0.9690 - val_loss: 11.1087 - val_mae: 2.1984\n",
      "Epoch 853/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.6027 - mae: 0.5975 - val_loss: 10.2479 - val_mae: 2.1208\n",
      "Epoch 854/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 1.6319 - mae: 1.0549 - val_loss: 11.4465 - val_mae: 2.1858\n",
      "Epoch 855/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1758 - mae: 0.9234 - val_loss: 10.5883 - val_mae: 2.1549\n",
      "Epoch 856/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 2.0257 - mae: 1.3018 - val_loss: 10.6955 - val_mae: 2.1466\n",
      "Epoch 857/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.8832 - mae: 0.7164 - val_loss: 10.9098 - val_mae: 2.1899\n",
      "Epoch 858/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.8378 - mae: 0.7466 - val_loss: 10.3914 - val_mae: 2.1333\n",
      "Epoch 859/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 2.9741 - mae: 1.5841 - val_loss: 10.3828 - val_mae: 2.1448\n",
      "Epoch 860/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 1.4766 - mae: 1.0084 - val_loss: 9.8146 - val_mae: 2.1038\n",
      "Epoch 861/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 2.0745 - mae: 1.2510 - val_loss: 9.6245 - val_mae: 2.1077\n",
      "Epoch 862/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.5369 - mae: 0.5768 - val_loss: 9.5839 - val_mae: 2.1093\n",
      "Epoch 863/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7703 - mae: 0.6999 - val_loss: 9.7535 - val_mae: 2.0892\n",
      "Epoch 864/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.1997 - mae: 0.8633 - val_loss: 10.1682 - val_mae: 2.1611\n",
      "Epoch 865/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.9684 - mae: 0.8017 - val_loss: 10.7347 - val_mae: 2.1845\n",
      "Epoch 866/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.4027 - mae: 0.4877 - val_loss: 10.0206 - val_mae: 2.1421\n",
      "Epoch 867/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.7947 - mae: 0.7161 - val_loss: 9.6709 - val_mae: 2.0868\n",
      "Epoch 868/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8257 - mae: 0.7671 - val_loss: 10.5214 - val_mae: 2.1274\n",
      "Epoch 869/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.2445 - mae: 0.9463 - val_loss: 10.3056 - val_mae: 2.1723\n",
      "Epoch 870/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 7.3280 - mae: 2.4051 - val_loss: 11.3121 - val_mae: 2.2413\n",
      "Epoch 871/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.7156 - mae: 0.6745 - val_loss: 10.1606 - val_mae: 2.2070\n",
      "Epoch 872/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.4831 - mae: 0.9928 - val_loss: 11.2959 - val_mae: 2.2738\n",
      "Epoch 873/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 1.3294 - mae: 1.0218 - val_loss: 11.5564 - val_mae: 2.2504\n",
      "Epoch 874/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.3961 - mae: 0.9946 - val_loss: 10.6357 - val_mae: 2.2348\n",
      "Epoch 875/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.6262 - mae: 0.6178 - val_loss: 11.0302 - val_mae: 2.2613\n",
      "Epoch 876/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.4751 - mae: 0.5563 - val_loss: 10.6759 - val_mae: 2.2272\n",
      "Epoch 877/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.6218 - mae: 1.0180 - val_loss: 10.0520 - val_mae: 2.2016\n",
      "Epoch 878/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.5539 - mae: 0.6303 - val_loss: 10.4784 - val_mae: 2.1706\n",
      "Epoch 879/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0971 - mae: 0.9033 - val_loss: 9.9472 - val_mae: 2.1734\n",
      "Epoch 880/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.4694 - mae: 1.1147 - val_loss: 10.5137 - val_mae: 2.1964\n",
      "Epoch 881/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 1.2971 - mae: 0.9711 - val_loss: 10.5261 - val_mae: 2.1737\n",
      "Epoch 882/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.3533 - mae: 0.4581 - val_loss: 9.9201 - val_mae: 2.1559\n",
      "Epoch 883/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 1.4380 - mae: 1.0146 - val_loss: 10.9477 - val_mae: 2.1621\n",
      "Epoch 884/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.8314 - mae: 0.7282 - val_loss: 10.0863 - val_mae: 2.1076\n",
      "Epoch 885/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.4151 - mae: 1.0344 - val_loss: 9.8752 - val_mae: 2.1479\n",
      "Epoch 886/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.8022 - mae: 0.7325 - val_loss: 10.5280 - val_mae: 2.1891\n",
      "Epoch 887/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.8249 - mae: 0.7424 - val_loss: 10.2488 - val_mae: 2.1747\n",
      "Epoch 888/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.5577 - mae: 1.0707 - val_loss: 10.0901 - val_mae: 2.1721\n",
      "Epoch 889/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.6114 - mae: 0.6238 - val_loss: 9.9826 - val_mae: 2.1903\n",
      "Epoch 890/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.4806 - mae: 1.0875 - val_loss: 9.8855 - val_mae: 2.1856\n",
      "Epoch 891/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.6499 - mae: 0.6810 - val_loss: 10.1240 - val_mae: 2.1783\n",
      "Epoch 892/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8663 - mae: 0.7035 - val_loss: 10.0500 - val_mae: 2.1776\n",
      "Epoch 893/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.9969 - mae: 0.7336 - val_loss: 10.3178 - val_mae: 2.2137\n",
      "Epoch 894/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.4308 - mae: 0.4862 - val_loss: 10.9513 - val_mae: 2.2602\n",
      "Epoch 895/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.9269 - mae: 1.1476 - val_loss: 10.8830 - val_mae: 2.2276\n",
      "Epoch 896/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 1.1257 - mae: 0.8575 - val_loss: 9.8442 - val_mae: 2.1748\n",
      "Epoch 897/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 1.2939 - mae: 0.9304 - val_loss: 10.1671 - val_mae: 2.1758\n",
      "Epoch 898/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.6108 - mae: 0.6250 - val_loss: 9.8121 - val_mae: 2.1591\n",
      "Epoch 899/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.8826 - mae: 0.7367 - val_loss: 9.7375 - val_mae: 2.1717\n",
      "Epoch 900/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.5375 - mae: 0.6040 - val_loss: 9.6497 - val_mae: 2.1444\n",
      "Epoch 901/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 2.0939 - mae: 1.2616 - val_loss: 9.2414 - val_mae: 2.0929\n",
      "Epoch 902/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 1.2382 - mae: 0.9459 - val_loss: 10.0269 - val_mae: 2.1233\n",
      "Epoch 903/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.3429 - mae: 1.0088 - val_loss: 10.0596 - val_mae: 2.1378\n",
      "Epoch 904/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.4292 - mae: 1.4526 - val_loss: 9.4513 - val_mae: 2.1345\n",
      "Epoch 905/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.2138 - mae: 1.2138 - val_loss: 10.5906 - val_mae: 2.1570\n",
      "Epoch 906/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9542 - mae: 0.8332 - val_loss: 10.1285 - val_mae: 2.1537\n",
      "Epoch 907/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.4679 - mae: 0.5552 - val_loss: 9.5900 - val_mae: 2.1183\n",
      "Epoch 908/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 3.3712 - mae: 1.4493 - val_loss: 10.1552 - val_mae: 2.1683\n",
      "Epoch 909/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.9088 - mae: 1.1204 - val_loss: 9.4927 - val_mae: 2.1090\n",
      "Epoch 910/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.1567 - mae: 0.9437 - val_loss: 9.6288 - val_mae: 2.1003\n",
      "Epoch 911/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.5616 - mae: 1.4536 - val_loss: 9.9953 - val_mae: 2.1466\n",
      "Epoch 912/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7661 - mae: 0.7240 - val_loss: 9.5789 - val_mae: 2.1401\n",
      "Epoch 913/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.4940 - mae: 0.9390 - val_loss: 11.0683 - val_mae: 2.2280\n",
      "Epoch 914/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.3907 - mae: 1.0062 - val_loss: 10.1839 - val_mae: 2.1900\n",
      "Epoch 915/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.9132 - mae: 1.1606 - val_loss: 10.3542 - val_mae: 2.2156\n",
      "Epoch 916/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.0587 - mae: 1.2100 - val_loss: 10.6675 - val_mae: 2.2212\n",
      "Epoch 917/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.7315 - mae: 0.6401 - val_loss: 10.3553 - val_mae: 2.2031\n",
      "Epoch 918/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.1130 - mae: 0.8329 - val_loss: 11.0654 - val_mae: 2.2303\n",
      "Epoch 919/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1639 - mae: 0.8979 - val_loss: 10.3433 - val_mae: 2.1584\n",
      "Epoch 920/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.7338 - mae: 0.6292 - val_loss: 9.6512 - val_mae: 2.1282\n",
      "Epoch 921/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.6904 - mae: 0.6833 - val_loss: 9.6350 - val_mae: 2.1292\n",
      "Epoch 922/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.5687 - mae: 1.0919 - val_loss: 10.2130 - val_mae: 2.1488\n",
      "Epoch 923/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.3570 - mae: 0.4736 - val_loss: 10.3751 - val_mae: 2.1556\n",
      "Epoch 924/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.4404 - mae: 0.9018 - val_loss: 10.2225 - val_mae: 2.1765\n",
      "Epoch 925/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.4381 - mae: 0.5278 - val_loss: 10.4217 - val_mae: 2.1638\n",
      "Epoch 926/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.9106 - mae: 0.8309 - val_loss: 10.7302 - val_mae: 2.1903\n",
      "Epoch 927/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.5671 - mae: 0.9400 - val_loss: 11.1428 - val_mae: 2.2281\n",
      "Epoch 928/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 1.3530 - mae: 0.9591 - val_loss: 10.0538 - val_mae: 2.1774\n",
      "Epoch 929/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.3928 - mae: 1.3913 - val_loss: 9.1985 - val_mae: 2.1087\n",
      "Epoch 930/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.7938 - mae: 0.7446 - val_loss: 9.1916 - val_mae: 2.0731\n",
      "Epoch 931/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.2021 - mae: 0.9098 - val_loss: 9.6029 - val_mae: 2.0748\n",
      "Epoch 932/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.6120 - mae: 0.6364 - val_loss: 9.7385 - val_mae: 2.0644\n",
      "Epoch 933/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.1039 - mae: 1.2726 - val_loss: 9.5145 - val_mae: 2.0904\n",
      "Epoch 934/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.5532 - mae: 1.0214 - val_loss: 10.0747 - val_mae: 2.1473\n",
      "Epoch 935/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.6073 - mae: 0.6572 - val_loss: 9.5288 - val_mae: 2.1232\n",
      "Epoch 936/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 3.0746 - mae: 1.4170 - val_loss: 9.9623 - val_mae: 2.1378\n",
      "Epoch 937/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.3309 - mae: 0.7792 - val_loss: 9.7163 - val_mae: 2.1311\n",
      "Epoch 938/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.1288 - mae: 0.8948 - val_loss: 9.6091 - val_mae: 2.1207\n",
      "Epoch 939/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.8066 - mae: 0.7428 - val_loss: 10.0486 - val_mae: 2.0974\n",
      "Epoch 940/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7837 - mae: 0.6885 - val_loss: 9.9175 - val_mae: 2.1008\n",
      "Epoch 941/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.4297 - mae: 0.9708 - val_loss: 9.8142 - val_mae: 2.1505\n",
      "Epoch 942/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.1086 - mae: 1.1542 - val_loss: 9.9960 - val_mae: 2.1832\n",
      "Epoch 943/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.0351 - mae: 0.8832 - val_loss: 10.2486 - val_mae: 2.1620\n",
      "Epoch 944/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.7720 - mae: 1.1529 - val_loss: 10.3770 - val_mae: 2.1573\n",
      "Epoch 945/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.8762 - mae: 1.0731 - val_loss: 10.4311 - val_mae: 2.1980\n",
      "Epoch 946/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.6453 - mae: 0.6231 - val_loss: 10.0404 - val_mae: 2.1719\n",
      "Epoch 947/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.7690 - mae: 0.6876 - val_loss: 10.3481 - val_mae: 2.1480\n",
      "Epoch 948/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.8238 - mae: 0.7563 - val_loss: 10.2697 - val_mae: 2.1657\n",
      "Epoch 949/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.7695 - mae: 1.0754 - val_loss: 10.4735 - val_mae: 2.2018\n",
      "Epoch 950/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1897 - mae: 0.8880 - val_loss: 10.5744 - val_mae: 2.2318\n",
      "Epoch 951/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.8498 - mae: 0.8116 - val_loss: 10.6070 - val_mae: 2.2649\n",
      "Epoch 952/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.3943 - mae: 0.4888 - val_loss: 11.1913 - val_mae: 2.3218\n",
      "Epoch 953/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.4830 - mae: 1.4132 - val_loss: 10.9398 - val_mae: 2.2737\n",
      "Epoch 954/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.1646 - mae: 0.9370 - val_loss: 10.4220 - val_mae: 2.2366\n",
      "Epoch 955/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 2.7124 - mae: 1.4167 - val_loss: 10.9870 - val_mae: 2.3035\n",
      "Epoch 956/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.5855 - mae: 0.5998 - val_loss: 10.4101 - val_mae: 2.2232\n",
      "Epoch 957/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.4138 - mae: 0.4996 - val_loss: 10.5457 - val_mae: 2.2014\n",
      "Epoch 958/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 1.3902 - mae: 1.0388 - val_loss: 10.6740 - val_mae: 2.2133\n",
      "Epoch 959/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.9617 - mae: 0.7801 - val_loss: 10.1383 - val_mae: 2.1802\n",
      "Epoch 960/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.9818 - mae: 0.6937 - val_loss: 11.0282 - val_mae: 2.2471\n",
      "Epoch 961/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7968 - mae: 0.7015 - val_loss: 10.7355 - val_mae: 2.2671\n",
      "Epoch 962/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.8632 - mae: 1.2486 - val_loss: 9.6227 - val_mae: 2.1640\n",
      "Epoch 963/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.1447 - mae: 0.8941 - val_loss: 9.9042 - val_mae: 2.1719\n",
      "Epoch 964/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.5056 - mae: 1.0551 - val_loss: 10.7028 - val_mae: 2.2473\n",
      "Epoch 965/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.4790 - mae: 0.5348 - val_loss: 10.5113 - val_mae: 2.2153\n",
      "Epoch 966/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.3906 - mae: 0.5166 - val_loss: 10.7224 - val_mae: 2.2137\n",
      "Epoch 967/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7199 - mae: 0.6636 - val_loss: 9.7973 - val_mae: 2.1416\n",
      "Epoch 968/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.7685 - mae: 0.6734 - val_loss: 9.9549 - val_mae: 2.1438\n",
      "Epoch 969/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.3957 - mae: 0.5039 - val_loss: 10.0248 - val_mae: 2.1884\n",
      "Epoch 970/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 2.4887 - mae: 1.2950 - val_loss: 9.8555 - val_mae: 2.1782\n",
      "Epoch 971/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.4073 - mae: 0.8876 - val_loss: 10.4648 - val_mae: 2.1762\n",
      "Epoch 972/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.3783 - mae: 0.4999 - val_loss: 9.8669 - val_mae: 2.1371\n",
      "Epoch 973/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.9261 - mae: 1.2399 - val_loss: 10.3936 - val_mae: 2.1843\n",
      "Epoch 974/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.5305 - mae: 0.5754 - val_loss: 9.7696 - val_mae: 2.1380\n",
      "Epoch 975/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.8030 - mae: 0.7572 - val_loss: 9.7758 - val_mae: 2.1481\n",
      "Epoch 976/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.4556 - mae: 0.4938 - val_loss: 9.6997 - val_mae: 2.1461\n",
      "Epoch 977/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.9866 - mae: 1.1339 - val_loss: 9.7557 - val_mae: 2.1746\n",
      "Epoch 978/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.4480 - mae: 0.4732 - val_loss: 9.1295 - val_mae: 2.1212\n",
      "Epoch 979/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.9861 - mae: 0.8244 - val_loss: 9.8919 - val_mae: 2.1592\n",
      "Epoch 980/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.1848 - mae: 0.9163 - val_loss: 9.8929 - val_mae: 2.1475\n",
      "Epoch 981/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.4159 - mae: 0.5030 - val_loss: 10.2628 - val_mae: 2.1714\n",
      "Epoch 982/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.8433 - mae: 0.6941 - val_loss: 10.5373 - val_mae: 2.1899\n",
      "Epoch 983/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.8035 - mae: 1.2021 - val_loss: 10.4251 - val_mae: 2.1887\n",
      "Epoch 984/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.3879 - mae: 0.4791 - val_loss: 10.2169 - val_mae: 2.2265\n",
      "Epoch 985/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 3.1908 - mae: 1.6781 - val_loss: 11.0357 - val_mae: 2.2789\n",
      "Epoch 986/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 1.2573 - mae: 0.9086 - val_loss: 10.4348 - val_mae: 2.2574\n",
      "Epoch 987/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 2.2813 - mae: 1.2997 - val_loss: 10.1432 - val_mae: 2.2294\n",
      "Epoch 988/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7516 - mae: 0.6824 - val_loss: 9.9683 - val_mae: 2.2171\n",
      "Epoch 989/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.0036 - mae: 0.8597 - val_loss: 9.9382 - val_mae: 2.1800\n",
      "Epoch 990/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.3175 - mae: 1.3685 - val_loss: 10.1405 - val_mae: 2.1617\n",
      "Epoch 991/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 3.1633 - mae: 1.6007 - val_loss: 10.0615 - val_mae: 2.2257\n",
      "Epoch 992/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.1257 - mae: 0.9252 - val_loss: 10.0793 - val_mae: 2.2094\n",
      "Epoch 993/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 2.1467 - mae: 1.1924 - val_loss: 10.6979 - val_mae: 2.2310\n",
      "Epoch 994/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.9104 - mae: 0.6905 - val_loss: 10.9467 - val_mae: 2.2480\n",
      "Epoch 995/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2922 - mae: 0.6876 - val_loss: 10.4051 - val_mae: 2.2130\n",
      "Epoch 996/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.5737 - mae: 0.5957 - val_loss: 10.3149 - val_mae: 2.2026\n",
      "Epoch 997/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.2392 - mae: 0.9940 - val_loss: 10.9607 - val_mae: 2.2184\n",
      "Epoch 998/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.2652 - mae: 0.4030 - val_loss: 10.1731 - val_mae: 2.1709\n",
      "Epoch 999/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.3985 - mae: 0.9744 - val_loss: 10.4056 - val_mae: 2.1756\n",
      "Epoch 1000/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.9267 - mae: 0.8076 - val_loss: 10.6067 - val_mae: 2.2077\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "history=model.fit(X_train,y_train,\n",
    "                  batch_size=64,\n",
    "                  epochs=1000,\n",
    "                  validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1edfed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mae'],label='train mae')\n",
    "plt.plot(history.history['val_mae'],label='val mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mae')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim([0,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "852ae8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5674 - mae: 0.3589\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 12.4091 - mae: 2.0055\n",
      "Train loss: 2.230\n",
      "Test loss : 15.956\n",
      "Train mae : 0.666\n",
      "Test mae  : 2.174\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "train_loss, train_mae = model.evaluate(X_train, y_train)\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Train loss: {train_loss:.3f}\")\n",
    "print(f\"Test loss : {test_loss:.3f}\")\n",
    "print(f\"Train mae : {train_mae:.3f}\")\n",
    "print(f\"Test mae  : {test_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b4464f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#Save model\n",
    "model.save(\"my_ann_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97258bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Then load the model\n",
    "model = load_model(\"my_ann_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5778a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6bf38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import ModelCheckpoint\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "155e119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set model checkpoint\n",
    "model_checkpoint = ModelCheckpoint(\"my_ann_model_2.h5\",\n",
    "                                   save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e38ccccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate and compile model\n",
    "model = ann()  # recreate a fresh model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae380391",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',  # or appropriate loss like 'binary_crossentropy' or 'categorical_crossentropy'\n",
    "              metrics=['mae'])  # or ['accuracy'] depending on task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1f2a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 606.2715 - mae: 23.0289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 601.8519 - mae: 22.9748 - val_loss: 560.8596 - val_mae: 21.4735\n",
      "Epoch 2/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 581.6492 - mae: 23.0490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 577.8068 - mae: 22.9846 - val_loss: 557.8279 - val_mae: 21.4741\n",
      "Epoch 3/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 549.1075 - mae: 22.6317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 548.9625 - mae: 22.6298 - val_loss: 554.8065 - val_mae: 21.4786\n",
      "Epoch 4/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 561.8769 - mae: 22.9954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 558.1549 - mae: 22.9255 - val_loss: 551.8721 - val_mae: 21.4841\n",
      "Epoch 5/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 570.3105 - mae: 23.3138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 564.2006 - mae: 23.1833 - val_loss: 549.1230 - val_mae: 21.4906\n",
      "Epoch 6/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 500.4127 - mae: 21.9676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 504.9112 - mae: 22.0535 - val_loss: 546.3794 - val_mae: 21.4957\n",
      "Epoch 7/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 522.8908 - mae: 22.3481"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 522.8170 - mae: 22.3625 - val_loss: 543.8526 - val_mae: 21.4946\n",
      "Epoch 8/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 509.5831 - mae: 22.1441"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 511.3695 - mae: 22.1839 - val_loss: 540.7261 - val_mae: 21.4796\n",
      "Epoch 9/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 531.5270 - mae: 22.7204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 528.6479 - mae: 22.6552 - val_loss: 537.5626 - val_mae: 21.4578\n",
      "Epoch 10/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 501.0500 - mae: 21.9743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 502.7226 - mae: 22.0241 - val_loss: 535.6213 - val_mae: 21.4548\n",
      "Epoch 11/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 503.2780 - mae: 22.1462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - loss: 503.7371 - mae: 22.1578 - val_loss: 534.1850 - val_mae: 21.4617\n",
      "Epoch 12/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 547.6301 - mae: 23.0744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 540.2532 - mae: 22.9213 - val_loss: 532.9342 - val_mae: 21.4660\n",
      "Epoch 13/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 525.8057 - mae: 22.5659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 521.7411 - mae: 22.4872 - val_loss: 531.9478 - val_mae: 21.4845\n",
      "Epoch 14/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 491.3045 - mae: 21.9295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 491.8729 - mae: 21.9462 - val_loss: 530.2169 - val_mae: 21.4806\n",
      "Epoch 15/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 499.0144 - mae: 22.1175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 498.2816 - mae: 22.0919 - val_loss: 529.1161 - val_mae: 21.4665\n",
      "Epoch 16/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 507.4180 - mae: 22.2627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 504.3437 - mae: 22.2015 - val_loss: 527.6808 - val_mae: 21.4677\n",
      "Epoch 17/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 470.7509 - mae: 21.4949 - val_loss: 528.5308 - val_mae: 21.5325\n",
      "Epoch 18/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 462.6664 - mae: 21.3040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 466.0463 - mae: 21.3788 - val_loss: 526.9471 - val_mae: 21.5159\n",
      "Epoch 19/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 469.9911 - mae: 21.5267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 471.0954 - mae: 21.5519 - val_loss: 524.1369 - val_mae: 21.4646\n",
      "Epoch 20/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 467.7178 - mae: 21.4890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 468.7425 - mae: 21.5076 - val_loss: 522.4704 - val_mae: 21.4530\n",
      "Epoch 21/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 465.6586 - mae: 21.4083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 466.3210 - mae: 21.4270 - val_loss: 521.8776 - val_mae: 21.4911\n",
      "Epoch 22/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 481.0381 - mae: 21.7983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 478.4070 - mae: 21.7382 - val_loss: 520.9669 - val_mae: 21.4849\n",
      "Epoch 23/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 457.7794 - mae: 21.2460"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 458.5406 - mae: 21.2639 - val_loss: 518.4040 - val_mae: 21.4001\n",
      "Epoch 24/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 436.2701 - mae: 20.7738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 439.9228 - mae: 20.8560 - val_loss: 514.2913 - val_mae: 21.3407\n",
      "Epoch 25/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 453.2822 - mae: 21.1833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 453.2335 - mae: 21.1823 - val_loss: 510.0248 - val_mae: 21.3097\n",
      "Epoch 26/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 438.5103 - mae: 20.8330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 440.3365 - mae: 20.8749 - val_loss: 505.5378 - val_mae: 21.2385\n",
      "Epoch 27/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 442.4589 - mae: 20.9238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 442.8189 - mae: 20.9348 - val_loss: 502.5622 - val_mae: 21.1810\n",
      "Epoch 28/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 429.3231 - mae: 20.5908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 431.2691 - mae: 20.6410 - val_loss: 496.1301 - val_mae: 21.0659\n",
      "Epoch 29/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 438.2544 - mae: 20.8661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 437.8723 - mae: 20.8537 - val_loss: 488.7452 - val_mae: 20.8899\n",
      "Epoch 30/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 421.5256 - mae: 20.4146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 423.3238 - mae: 20.4603 - val_loss: 484.4983 - val_mae: 20.8109\n",
      "Epoch 31/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 415.1327 - mae: 20.2177"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 417.5712 - mae: 20.2786 - val_loss: 475.6179 - val_mae: 20.6453\n",
      "Epoch 32/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 424.0241 - mae: 20.5193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 423.8139 - mae: 20.5117 - val_loss: 470.0209 - val_mae: 20.5504\n",
      "Epoch 33/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 417.4962 - mae: 20.3522"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 417.7392 - mae: 20.3537 - val_loss: 464.3672 - val_mae: 20.4292\n",
      "Epoch 34/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 400.2739 - mae: 19.9426"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 402.4481 - mae: 19.9933 - val_loss: 463.9530 - val_mae: 20.4214\n",
      "Epoch 35/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 425.3259 - mae: 20.5555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 422.5677 - mae: 20.4845 - val_loss: 457.8559 - val_mae: 20.2888\n",
      "Epoch 36/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 415.2708 - mae: 20.2686"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 413.6573 - mae: 20.2251 - val_loss: 449.7433 - val_mae: 20.1780\n",
      "Epoch 37/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 409.7392 - mae: 20.1456 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 408.0556 - mae: 20.1019 - val_loss: 441.6322 - val_mae: 19.9388\n",
      "Epoch 38/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 379.7018 - mae: 19.3923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 382.2841 - mae: 19.4529 - val_loss: 432.0474 - val_mae: 19.8237\n",
      "Epoch 39/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 398.7827 - mae: 19.9003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 397.2747 - mae: 19.8544 - val_loss: 426.5423 - val_mae: 19.7233\n",
      "Epoch 40/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 375.3240 - mae: 19.2679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 376.8004 - mae: 19.3053 - val_loss: 419.8124 - val_mae: 19.5419\n",
      "Epoch 41/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 367.8970 - mae: 19.0917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 369.5697 - mae: 19.1358 - val_loss: 408.5629 - val_mae: 19.2890\n",
      "Epoch 42/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 355.0376 - mae: 18.6955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 358.1319 - mae: 18.7824 - val_loss: 398.1579 - val_mae: 19.0306\n",
      "Epoch 43/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 385.3725 - mae: 19.5096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 382.4855 - mae: 19.4368 - val_loss: 390.2960 - val_mae: 18.8191\n",
      "Epoch 44/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 381.2165 - mae: 19.4599"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 377.9814 - mae: 19.3711 - val_loss: 389.0892 - val_mae: 18.8626\n",
      "Epoch 45/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 352.4731 - mae: 18.6659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 353.4718 - mae: 18.6845 - val_loss: 386.1951 - val_mae: 18.7894\n",
      "Epoch 46/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 335.3909 - mae: 18.1941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 338.2414 - mae: 18.2662 - val_loss: 372.4516 - val_mae: 18.3378\n",
      "Epoch 47/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 354.9622 - mae: 18.7520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 353.2943 - mae: 18.7054 - val_loss: 363.0588 - val_mae: 18.3004\n",
      "Epoch 48/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 348.3138 - mae: 18.5826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 346.6733 - mae: 18.5377 - val_loss: 356.0507 - val_mae: 18.1781\n",
      "Epoch 49/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 335.2138 - mae: 18.2194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 334.9050 - mae: 18.2082 - val_loss: 354.5968 - val_mae: 18.0229\n",
      "Epoch 50/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 337.0564 - mae: 18.1975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 335.7157 - mae: 18.1626 - val_loss: 346.8630 - val_mae: 17.9382\n",
      "Epoch 51/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 342.6701 - mae: 18.3280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 339.4804 - mae: 18.2435 - val_loss: 333.0398 - val_mae: 17.5914\n",
      "Epoch 52/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 310.2539 - mae: 17.5081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 311.1245 - mae: 17.5321 - val_loss: 324.1506 - val_mae: 17.3119\n",
      "Epoch 53/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 302.4878 - mae: 17.2901"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - loss: 303.7587 - mae: 17.3220 - val_loss: 317.2880 - val_mae: 17.1962\n",
      "Epoch 54/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 296.7322 - mae: 17.1478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 297.7123 - mae: 17.1742 - val_loss: 310.5311 - val_mae: 17.0572\n",
      "Epoch 55/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 296.4547 - mae: 17.0787"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 296.7606 - mae: 17.0871 - val_loss: 300.2152 - val_mae: 16.7105\n",
      "Epoch 56/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 305.3848 - mae: 17.3623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 303.1284 - mae: 17.2933 - val_loss: 296.5822 - val_mae: 16.6281\n",
      "Epoch 57/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 275.3602 - mae: 16.5137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 276.7989 - mae: 16.5558 - val_loss: 287.9012 - val_mae: 16.3473\n",
      "Epoch 58/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 280.4302 - mae: 16.6741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 279.9429 - mae: 16.6586 - val_loss: 276.6534 - val_mae: 16.0093\n",
      "Epoch 59/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 286.8649 - mae: 16.8549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 284.3062 - mae: 16.7780 - val_loss: 272.8050 - val_mae: 15.9697\n",
      "Epoch 60/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 249.5791 - mae: 15.6867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 252.2769 - mae: 15.7731 - val_loss: 265.2615 - val_mae: 15.7410\n",
      "Epoch 61/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 255.8857 - mae: 15.8572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - loss: 256.7907 - mae: 15.8835 - val_loss: 252.9823 - val_mae: 15.3601\n",
      "Epoch 62/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 259.2057 - mae: 16.0324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - loss: 258.1180 - mae: 15.9972 - val_loss: 245.8649 - val_mae: 15.1485\n",
      "Epoch 63/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 257.5317 - mae: 15.9661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 255.8865 - mae: 15.9092 - val_loss: 242.9319 - val_mae: 15.1055\n",
      "Epoch 64/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 235.6581 - mae: 15.2746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 236.5470 - mae: 15.3000 - val_loss: 235.7322 - val_mae: 14.7734\n",
      "Epoch 65/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 240.5533 - mae: 15.4500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 239.5577 - mae: 15.4131 - val_loss: 230.5249 - val_mae: 14.5508\n",
      "Epoch 66/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 214.6601 - mae: 14.5459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 216.9708 - mae: 14.6264 - val_loss: 227.3916 - val_mae: 14.5600\n",
      "Epoch 67/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 206.1358 - mae: 14.2488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 208.9816 - mae: 14.3452 - val_loss: 218.2183 - val_mae: 14.2116\n",
      "Epoch 68/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 235.5590 - mae: 15.2250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 232.4765 - mae: 15.1246 - val_loss: 210.4586 - val_mae: 13.9472\n",
      "Epoch 69/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 209.2960 - mae: 14.3694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - loss: 209.5528 - mae: 14.3774 - val_loss: 210.2660 - val_mae: 13.9588\n",
      "Epoch 70/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 211.7567 - mae: 14.4750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 210.6040 - mae: 14.4309 - val_loss: 206.5662 - val_mae: 13.7812\n",
      "Epoch 71/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 210.3428 - mae: 14.4283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 208.3879 - mae: 14.3572 - val_loss: 200.5951 - val_mae: 13.6318\n",
      "Epoch 72/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 199.6460 - mae: 14.0683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 198.4767 - mae: 14.0223 - val_loss: 197.0639 - val_mae: 13.5715\n",
      "Epoch 73/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 181.5545 - mae: 13.3925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 182.6150 - mae: 13.4242 - val_loss: 185.5207 - val_mae: 13.1323\n",
      "Epoch 74/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 163.2748 - mae: 12.5727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 166.5916 - mae: 12.7063 - val_loss: 180.4711 - val_mae: 12.8208\n",
      "Epoch 75/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 168.4928 - mae: 12.8724"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 169.7793 - mae: 12.9208 - val_loss: 177.4384 - val_mae: 12.8003\n",
      "Epoch 76/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 172.3640 - mae: 13.0221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 172.1132 - mae: 13.0099 - val_loss: 164.3560 - val_mae: 12.2758\n",
      "Epoch 77/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 163.8126 - mae: 12.7037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 163.9707 - mae: 12.7089 - val_loss: 161.8827 - val_mae: 12.1897\n",
      "Epoch 78/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 164.6334 - mae: 12.7524 - val_loss: 163.1364 - val_mae: 12.2718\n",
      "Epoch 79/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 154.2931 - mae: 12.3281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - loss: 154.2467 - mae: 12.3246 - val_loss: 157.8019 - val_mae: 12.0041\n",
      "Epoch 80/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 148.0596 - mae: 12.0384"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 148.3108 - mae: 12.0475 - val_loss: 153.6583 - val_mae: 11.8793\n",
      "Epoch 81/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 153.9157 - mae: 12.2931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 152.2109 - mae: 12.2237 - val_loss: 143.1767 - val_mae: 11.5112\n",
      "Epoch 82/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 154.3570 - mae: 12.2991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - loss: 151.8104 - mae: 12.1926 - val_loss: 137.6424 - val_mae: 11.1719\n",
      "Epoch 83/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 139.6869 - mae: 11.6592"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 138.8793 - mae: 11.6237 - val_loss: 131.6586 - val_mae: 10.7853\n",
      "Epoch 84/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 142.7415 - mae: 11.7607"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 140.6487 - mae: 11.6725 - val_loss: 124.1239 - val_mae: 10.6387\n",
      "Epoch 85/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 117.2350 - mae: 10.6140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - loss: 118.6049 - mae: 10.6813 - val_loss: 115.9598 - val_mae: 10.3147\n",
      "Epoch 86/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 129.5189 - mae: 11.1429 - val_loss: 116.3176 - val_mae: 10.1614\n",
      "Epoch 87/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 117.1401 - mae: 10.5457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 117.2822 - mae: 10.5532 - val_loss: 114.2263 - val_mae: 10.0976\n",
      "Epoch 88/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 109.1336 - mae: 10.3594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 109.2266 - mae: 10.3624 - val_loss: 105.8752 - val_mae: 9.7181\n",
      "Epoch 89/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 104.4982 - mae: 10.0984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - loss: 104.8967 - mae: 10.1097 - val_loss: 100.7742 - val_mae: 9.4935\n",
      "Epoch 90/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 109.4101 - mae: 10.3836"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - loss: 108.0515 - mae: 10.3120 - val_loss: 98.5993 - val_mae: 9.4021\n",
      "Epoch 91/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 103.1638 - mae: 10.0445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 102.1840 - mae: 9.9943 - val_loss: 93.6781 - val_mae: 9.1111\n",
      "Epoch 92/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 87.0077 - mae: 9.1977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 88.1664 - mae: 9.2539 - val_loss: 90.1723 - val_mae: 8.9059\n",
      "Epoch 93/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 88.5072 - mae: 9.2521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 88.7408 - mae: 9.2647 - val_loss: 86.1889 - val_mae: 8.7739\n",
      "Epoch 94/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 86.3460 - mae: 9.1812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 86.2046 - mae: 9.1710 - val_loss: 79.7842 - val_mae: 8.4471\n",
      "Epoch 95/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 87.8036 - mae: 9.1974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 87.1003 - mae: 9.1500 - val_loss: 74.3363 - val_mae: 8.1484\n",
      "Epoch 96/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 70.9764 - mae: 8.2001 - val_loss: 74.5133 - val_mae: 8.0742\n",
      "Epoch 97/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 71.2284 - mae: 8.3354"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 71.8048 - mae: 8.3639 - val_loss: 68.2224 - val_mae: 7.7164\n",
      "Epoch 98/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 72.1749 - mae: 8.3345"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 72.1471 - mae: 8.3294 - val_loss: 63.0605 - val_mae: 7.3992\n",
      "Epoch 99/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 90.8592 - mae: 9.2117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 87.6559 - mae: 9.0264 - val_loss: 58.7449 - val_mae: 7.1411\n",
      "Epoch 100/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 63.2519 - mae: 7.7554"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 63.8003 - mae: 7.7810 - val_loss: 57.3046 - val_mae: 6.9962\n",
      "Epoch 101/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 60.3533 - mae: 7.6015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - loss: 60.9255 - mae: 7.6205 - val_loss: 56.4439 - val_mae: 6.8963\n",
      "Epoch 102/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 56.5020 - mae: 7.3614"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 56.9530 - mae: 7.3865 - val_loss: 51.8448 - val_mae: 6.6719\n",
      "Epoch 103/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 59.6575 - mae: 7.5176"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 59.2497 - mae: 7.4845 - val_loss: 48.2542 - val_mae: 6.4442\n",
      "Epoch 104/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 54.2198 - mae: 7.2077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - loss: 53.9909 - mae: 7.1944 - val_loss: 47.9183 - val_mae: 6.4077\n",
      "Epoch 105/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 50.1756 - mae: 6.8937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 50.3286 - mae: 6.9013 - val_loss: 45.3959 - val_mae: 6.2095\n",
      "Epoch 106/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 44.1017 - mae: 6.5198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 44.6730 - mae: 6.5589 - val_loss: 42.7506 - val_mae: 5.9772\n",
      "Epoch 107/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 44.8771 - mae: 6.5659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 45.0956 - mae: 6.5703 - val_loss: 40.2494 - val_mae: 5.8357\n",
      "Epoch 108/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 40.2735 - mae: 6.0283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 41.0676 - mae: 6.0901 - val_loss: 39.6224 - val_mae: 5.7485\n",
      "Epoch 109/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 38.1554 - mae: 5.9963 - val_loss: 40.8265 - val_mae: 5.8911\n",
      "Epoch 110/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 41.6424 - mae: 6.2373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 41.2569 - mae: 6.2078 - val_loss: 38.5459 - val_mae: 5.7126\n",
      "Epoch 111/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 41.9327 - mae: 6.2810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 41.0879 - mae: 6.2109 - val_loss: 37.2509 - val_mae: 5.5533\n",
      "Epoch 112/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 35.0493 - mae: 5.7696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 34.9917 - mae: 5.7559 - val_loss: 35.1037 - val_mae: 5.4013\n",
      "Epoch 113/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 31.8921 - mae: 5.4954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 32.0210 - mae: 5.5003 - val_loss: 33.7647 - val_mae: 5.2774\n",
      "Epoch 114/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 31.8314 - mae: 5.4423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - loss: 31.7251 - mae: 5.4276 - val_loss: 32.5102 - val_mae: 5.1755\n",
      "Epoch 115/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 33.8794 - mae: 5.6452"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 33.1519 - mae: 5.5695 - val_loss: 29.8341 - val_mae: 4.9775\n",
      "Epoch 116/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 23.9050 - mae: 4.6636"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 24.6290 - mae: 4.7252 - val_loss: 29.4400 - val_mae: 4.8786\n",
      "Epoch 117/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 28.3942 - mae: 5.1513"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 27.9539 - mae: 5.1053 - val_loss: 27.1419 - val_mae: 4.6614\n",
      "Epoch 118/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 20.0706 - mae: 4.3001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 20.7269 - mae: 4.3704 - val_loss: 24.4487 - val_mae: 4.4116\n",
      "Epoch 119/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 34.0580 - mae: 5.5173"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - loss: 32.4643 - mae: 5.3588 - val_loss: 24.1286 - val_mae: 4.3710\n",
      "Epoch 120/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 21.3445 - mae: 4.3979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 21.3899 - mae: 4.4026 - val_loss: 23.4318 - val_mae: 4.2982\n",
      "Epoch 121/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 21.9052 - mae: 4.4617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 21.7303 - mae: 4.4326 - val_loss: 21.8274 - val_mae: 4.0882\n",
      "Epoch 122/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 17.7382 - mae: 3.8732"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 18.1132 - mae: 3.9162 - val_loss: 21.1007 - val_mae: 3.9895\n",
      "Epoch 123/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 18.0322 - mae: 4.0901"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 17.9355 - mae: 4.0738 - val_loss: 20.6229 - val_mae: 3.9770\n",
      "Epoch 124/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 17.7260 - mae: 4.0038 - val_loss: 21.1502 - val_mae: 3.9675\n",
      "Epoch 125/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 16.2975 - mae: 3.8482"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 16.2717 - mae: 3.8309 - val_loss: 20.4639 - val_mae: 3.8583\n",
      "Epoch 126/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 17.9585 - mae: 4.0041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 17.4478 - mae: 3.9357 - val_loss: 19.2978 - val_mae: 3.7447\n",
      "Epoch 127/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 13.7541 - mae: 3.4900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - loss: 13.7566 - mae: 3.4872 - val_loss: 18.7225 - val_mae: 3.7308\n",
      "Epoch 128/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 15.7036 - mae: 3.6268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 15.3975 - mae: 3.5835 - val_loss: 18.0164 - val_mae: 3.7010\n",
      "Epoch 129/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 11.9045 - mae: 3.2841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 11.8678 - mae: 3.2757 - val_loss: 17.1999 - val_mae: 3.4767\n",
      "Epoch 130/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 13.8561 - mae: 3.3766"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 13.7745 - mae: 3.3471 - val_loss: 16.4859 - val_mae: 3.2936\n",
      "Epoch 131/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 12.0161 - mae: 3.1838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 11.8195 - mae: 3.1544 - val_loss: 14.9616 - val_mae: 3.1488\n",
      "Epoch 132/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 9.8626 - mae: 2.8543"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - loss: 9.9680 - mae: 2.8671 - val_loss: 14.2170 - val_mae: 3.0910\n",
      "Epoch 133/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 8.7495 - mae: 2.4836"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 9.0984 - mae: 2.5452 - val_loss: 13.9668 - val_mae: 3.0401\n",
      "Epoch 134/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 11.1569 - mae: 2.9721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 10.8241 - mae: 2.9264 - val_loss: 13.2876 - val_mae: 2.9180\n",
      "Epoch 135/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 7.7613 - mae: 2.3066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 8.0363 - mae: 2.3649 - val_loss: 13.0150 - val_mae: 2.8932\n",
      "Epoch 136/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 8.7839 - mae: 2.6590"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 8.7241 - mae: 2.6361 - val_loss: 12.6552 - val_mae: 2.8609\n",
      "Epoch 137/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 11.9901 - mae: 3.1552 - val_loss: 12.8361 - val_mae: 2.8142\n",
      "Epoch 138/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 6.2131 - mae: 2.1802 - val_loss: 12.6805 - val_mae: 2.8214\n",
      "Epoch 139/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 8.5669 - mae: 2.5611"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 8.3162 - mae: 2.5139 - val_loss: 12.0564 - val_mae: 2.7811\n",
      "Epoch 140/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 6.6835 - mae: 2.3140 - val_loss: 12.1910 - val_mae: 2.7570\n",
      "Epoch 141/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5.5275 - mae: 2.1592"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 5.5088 - mae: 2.1484 - val_loss: 12.0069 - val_mae: 2.7210\n",
      "Epoch 142/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 6.3710 - mae: 2.0273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 6.4692 - mae: 2.0414 - val_loss: 11.6278 - val_mae: 2.6929\n",
      "Epoch 143/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 6.2202 - mae: 2.2349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 6.0240 - mae: 2.1887 - val_loss: 10.9953 - val_mae: 2.6326\n",
      "Epoch 144/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 6.0607 - mae: 2.1163 - val_loss: 11.1936 - val_mae: 2.5754\n",
      "Epoch 145/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 6.2061 - mae: 2.0887 - val_loss: 11.0481 - val_mae: 2.4489\n",
      "Epoch 146/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 5.5713 - mae: 2.0510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 5.4018 - mae: 2.0117 - val_loss: 10.4565 - val_mae: 2.4328\n",
      "Epoch 147/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 4.2884 - mae: 1.7667 - val_loss: 11.2761 - val_mae: 2.4908\n",
      "Epoch 148/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 4.4725 - mae: 1.6176 - val_loss: 11.7640 - val_mae: 2.5641\n",
      "Epoch 149/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 3.5547 - mae: 1.6142 - val_loss: 11.3329 - val_mae: 2.5240\n",
      "Epoch 150/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 5.1551 - mae: 1.9931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 5.0264 - mae: 1.9562 - val_loss: 10.2933 - val_mae: 2.3492\n",
      "Epoch 151/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 5.6366 - mae: 2.0961 - val_loss: 12.0764 - val_mae: 2.4860\n",
      "Epoch 152/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3.5914 - mae: 1.5259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 3.6155 - mae: 1.5367 - val_loss: 10.2187 - val_mae: 2.3546\n",
      "Epoch 153/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 5.3210 - mae: 1.9843"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 5.1482 - mae: 1.9423 - val_loss: 9.7704 - val_mae: 2.3286\n",
      "Epoch 154/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 4.5604 - mae: 1.7005 - val_loss: 11.9783 - val_mae: 2.3921\n",
      "Epoch 155/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.7893 - mae: 1.3995 - val_loss: 10.8565 - val_mae: 2.3366\n",
      "Epoch 156/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.4763 - mae: 1.3022 - val_loss: 10.5412 - val_mae: 2.3508\n",
      "Epoch 157/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 3.9463 - mae: 1.5745 - val_loss: 11.0137 - val_mae: 2.3546\n",
      "Epoch 158/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 4.8676 - mae: 1.7741 - val_loss: 11.1776 - val_mae: 2.3959\n",
      "Epoch 159/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.5451 - mae: 1.2921 - val_loss: 10.8441 - val_mae: 2.3648\n",
      "Epoch 160/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.5247 - mae: 1.2281 - val_loss: 11.3949 - val_mae: 2.3430\n",
      "Epoch 161/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 1.9078 - mae: 1.1137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 1.9505 - mae: 1.1234 - val_loss: 9.4843 - val_mae: 2.2599\n",
      "Epoch 162/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 2.7087 - mae: 1.2789 - val_loss: 9.6509 - val_mae: 2.1623\n",
      "Epoch 163/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.8706 - mae: 1.0617 - val_loss: 10.7000 - val_mae: 2.2182\n",
      "Epoch 164/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 4.3156 - mae: 1.6469 - val_loss: 9.7271 - val_mae: 2.2921\n",
      "Epoch 165/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.8386 - mae: 1.3325 - val_loss: 10.3079 - val_mae: 2.2595\n",
      "Epoch 166/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 7.2514 - mae: 2.1261 - val_loss: 10.4751 - val_mae: 2.2372\n",
      "Epoch 167/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.7425 - mae: 1.0610 - val_loss: 9.7617 - val_mae: 2.2539\n",
      "Epoch 168/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.6294 - mae: 1.3084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 2.6364 - mae: 1.3098 - val_loss: 9.4709 - val_mae: 2.1817\n",
      "Epoch 169/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 2.7137 - mae: 1.2353"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 2.8453 - mae: 1.2721 - val_loss: 9.2632 - val_mae: 2.1558\n",
      "Epoch 170/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 3.0596 - mae: 1.3393 - val_loss: 9.4390 - val_mae: 2.1880\n",
      "Epoch 171/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 4.1874 - mae: 1.6595 - val_loss: 10.9959 - val_mae: 2.2460\n",
      "Epoch 172/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.5270 - mae: 0.9416 - val_loss: 9.5474 - val_mae: 2.2447\n",
      "Epoch 173/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 3.1121 - mae: 1.4965 - val_loss: 9.7293 - val_mae: 2.2724\n",
      "Epoch 174/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.5957 - mae: 0.9898 - val_loss: 11.2198 - val_mae: 2.3641\n",
      "Epoch 175/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 3.3601 - mae: 1.4873 - val_loss: 10.6211 - val_mae: 2.2615\n",
      "Epoch 176/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 2.0239 - mae: 1.1414 - val_loss: 10.3192 - val_mae: 2.3065\n",
      "Epoch 177/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.7927 - mae: 1.0050 - val_loss: 10.0807 - val_mae: 2.2226\n",
      "Epoch 178/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 1.6205 - mae: 0.9788 - val_loss: 11.0048 - val_mae: 2.2353\n",
      "Epoch 179/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0802 - mae: 0.7731 - val_loss: 10.2841 - val_mae: 2.2298\n",
      "Epoch 180/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 5.4103 - mae: 1.8286 - val_loss: 10.2168 - val_mae: 2.2447\n",
      "Epoch 181/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.7604 - mae: 1.0243 - val_loss: 10.2340 - val_mae: 2.2722\n",
      "Epoch 182/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.4498 - mae: 0.8924 - val_loss: 10.2000 - val_mae: 2.2718\n",
      "Epoch 183/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 3.7196 - mae: 1.5189 - val_loss: 10.4028 - val_mae: 2.2390\n",
      "Epoch 184/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.4269 - mae: 0.9286 - val_loss: 10.3163 - val_mae: 2.2386\n",
      "Epoch 185/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.1754 - mae: 1.1844 - val_loss: 9.5576 - val_mae: 2.1798\n",
      "Epoch 186/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 2.3147 - mae: 1.2257 - val_loss: 10.7246 - val_mae: 2.2973\n",
      "Epoch 187/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.7145 - mae: 0.9530 - val_loss: 10.8466 - val_mae: 2.3505\n",
      "Epoch 188/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.2582 - mae: 0.8867 - val_loss: 10.8116 - val_mae: 2.2930\n",
      "Epoch 189/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 2.7472 - mae: 1.3808 - val_loss: 11.3522 - val_mae: 2.2371\n",
      "Epoch 190/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.5887 - mae: 0.9574 - val_loss: 9.7374 - val_mae: 2.1703\n",
      "Epoch 191/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.6032 - mae: 1.3767 - val_loss: 9.4918 - val_mae: 2.1455\n",
      "Epoch 192/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.8090 - mae: 1.3429 - val_loss: 10.5751 - val_mae: 2.2586\n",
      "Epoch 193/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.8733 - mae: 1.0278 - val_loss: 10.3633 - val_mae: 2.2389\n",
      "Epoch 194/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.4632 - mae: 0.9207 - val_loss: 10.5890 - val_mae: 2.2737\n",
      "Epoch 195/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.6225 - mae: 0.9939 - val_loss: 10.3468 - val_mae: 2.1927\n",
      "Epoch 196/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.0375 - mae: 0.7849 - val_loss: 9.9107 - val_mae: 2.1550\n",
      "Epoch 197/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.3874 - mae: 1.1896 - val_loss: 9.8180 - val_mae: 2.2064\n",
      "Epoch 198/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.3013 - mae: 0.8541 - val_loss: 10.4959 - val_mae: 2.2298\n",
      "Epoch 199/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.7038 - mae: 1.0241 - val_loss: 10.2320 - val_mae: 2.2295\n",
      "Epoch 200/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.1759 - mae: 0.8457 - val_loss: 10.4818 - val_mae: 2.2223\n",
      "Epoch 201/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.4341 - mae: 0.9656 - val_loss: 10.9197 - val_mae: 2.2410\n",
      "Epoch 202/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 2.7234 - mae: 1.2454 - val_loss: 10.5455 - val_mae: 2.1850\n",
      "Epoch 203/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 2.2572 - mae: 1.1623 - val_loss: 12.2319 - val_mae: 2.3210\n",
      "Epoch 204/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.7278 - mae: 0.9903 - val_loss: 10.5486 - val_mae: 2.2167\n",
      "Epoch 205/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.3980 - mae: 1.1670 - val_loss: 11.8156 - val_mae: 2.3003\n",
      "Epoch 206/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 1.7894 - mae: 1.0536 - val_loss: 11.6192 - val_mae: 2.3129\n",
      "Epoch 207/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 2.4045 - mae: 1.2079 - val_loss: 10.5522 - val_mae: 2.1765\n",
      "Epoch 208/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 1.6224 - mae: 1.0090 - val_loss: 10.0757 - val_mae: 2.1030\n",
      "Epoch 209/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 2.5790 - mae: 1.3447 - val_loss: 10.5069 - val_mae: 2.1872\n",
      "Epoch 210/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.5526 - mae: 0.9252 - val_loss: 10.3502 - val_mae: 2.2165\n",
      "Epoch 211/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.2340 - mae: 1.2156 - val_loss: 10.1697 - val_mae: 2.2674\n",
      "Epoch 212/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.9940 - mae: 1.0703 - val_loss: 9.4791 - val_mae: 2.2018\n",
      "Epoch 213/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 3.1200 - mae: 1.3920 - val_loss: 11.0189 - val_mae: 2.2551\n",
      "Epoch 214/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 2.5384 - mae: 1.2116 - val_loss: 11.0707 - val_mae: 2.2770\n",
      "Epoch 215/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.1516 - mae: 1.1938 - val_loss: 10.2149 - val_mae: 2.2161\n",
      "Epoch 216/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.3798 - mae: 0.9093 - val_loss: 10.0900 - val_mae: 2.2215\n",
      "Epoch 217/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.4745 - mae: 0.9312 - val_loss: 11.0543 - val_mae: 2.2369\n",
      "Epoch 218/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.5218 - mae: 1.2971 - val_loss: 10.0774 - val_mae: 2.1833\n",
      "Epoch 219/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.8320 - mae: 1.0850 - val_loss: 10.9713 - val_mae: 2.2124\n",
      "Epoch 220/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 2.1156 - mae: 1.1770 - val_loss: 10.9320 - val_mae: 2.2463\n",
      "Epoch 221/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.5431 - mae: 0.9712 - val_loss: 9.9747 - val_mae: 2.2143\n",
      "Epoch 222/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.5471 - mae: 1.0236 - val_loss: 10.0731 - val_mae: 2.1698\n",
      "Epoch 223/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 1.8236 - mae: 1.0915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 1.8645 - mae: 1.0999 - val_loss: 8.9488 - val_mae: 2.1809\n",
      "Epoch 224/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.3038 - mae: 1.1839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 2.3290 - mae: 1.1908 - val_loss: 8.4513 - val_mae: 2.1401\n",
      "Epoch 225/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 1.6151 - mae: 1.0028 - val_loss: 9.9622 - val_mae: 2.1096\n",
      "Epoch 226/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 3.1477 - mae: 1.4502 - val_loss: 9.7475 - val_mae: 2.1479\n",
      "Epoch 227/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.7862 - mae: 1.0111 - val_loss: 9.2901 - val_mae: 2.2023\n",
      "Epoch 228/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.7085 - mae: 1.0355 - val_loss: 10.2264 - val_mae: 2.2328\n",
      "Epoch 229/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 1.4709 - mae: 1.0186 - val_loss: 10.9424 - val_mae: 2.3649\n",
      "Epoch 230/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.3600 - mae: 1.2157 - val_loss: 9.2052 - val_mae: 2.1519\n",
      "Epoch 231/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.2405 - mae: 1.2718 - val_loss: 10.5626 - val_mae: 2.2828\n",
      "Epoch 232/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 2.2179 - mae: 1.1281 - val_loss: 9.9302 - val_mae: 2.2834\n",
      "Epoch 233/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.2106 - mae: 1.2388 - val_loss: 9.5035 - val_mae: 2.2649\n",
      "Epoch 234/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 3.8013 - mae: 1.5335 - val_loss: 10.2977 - val_mae: 2.3303\n",
      "Epoch 235/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.7117 - mae: 1.1004 - val_loss: 10.6219 - val_mae: 2.3624\n",
      "Epoch 236/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.9696 - mae: 0.7314 - val_loss: 9.5781 - val_mae: 2.2381\n",
      "Epoch 237/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.5534 - mae: 1.1713 - val_loss: 9.5538 - val_mae: 2.2032\n",
      "Epoch 238/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 3.0123 - mae: 1.4594 - val_loss: 9.5326 - val_mae: 2.1841\n",
      "Epoch 239/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.9332 - mae: 1.0976 - val_loss: 10.5778 - val_mae: 2.2141\n",
      "Epoch 240/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 2.3809 - mae: 1.3049 - val_loss: 9.6811 - val_mae: 2.1855\n",
      "Epoch 241/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.3066 - mae: 0.8830 - val_loss: 9.7111 - val_mae: 2.1650\n",
      "Epoch 242/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.2328 - mae: 0.8972 - val_loss: 10.3671 - val_mae: 2.1919\n",
      "Epoch 243/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 1.8783 - mae: 1.1092 - val_loss: 10.0800 - val_mae: 2.1353\n",
      "Epoch 244/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.3141 - mae: 0.9281 - val_loss: 10.4899 - val_mae: 2.2107\n",
      "Epoch 245/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.3023 - mae: 1.2301 - val_loss: 10.3757 - val_mae: 2.2610\n",
      "Epoch 246/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9642 - mae: 0.7659 - val_loss: 10.1117 - val_mae: 2.2476\n",
      "Epoch 247/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1456 - mae: 0.8154 - val_loss: 10.1359 - val_mae: 2.2116\n",
      "Epoch 248/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.8522 - mae: 0.6667 - val_loss: 9.3227 - val_mae: 2.1957\n",
      "Epoch 249/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.7155 - mae: 1.0915 - val_loss: 9.8887 - val_mae: 2.2010\n",
      "Epoch 250/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.9838 - mae: 0.7491 - val_loss: 9.6897 - val_mae: 2.1743\n",
      "Epoch 251/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.9189 - mae: 1.0998 - val_loss: 10.2896 - val_mae: 2.2662\n",
      "Epoch 252/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.4197 - mae: 1.2454 - val_loss: 8.9511 - val_mae: 2.1295\n",
      "Epoch 253/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 2.5570 - mae: 1.2164 - val_loss: 10.0053 - val_mae: 2.2031\n",
      "Epoch 254/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.4057 - mae: 1.2902 - val_loss: 9.5587 - val_mae: 2.1928\n",
      "Epoch 255/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.1516 - mae: 0.8113 - val_loss: 9.6472 - val_mae: 2.1844\n",
      "Epoch 256/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.0149 - mae: 1.1072 - val_loss: 9.5225 - val_mae: 2.1957\n",
      "Epoch 257/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.7495 - mae: 1.3729 - val_loss: 10.0372 - val_mae: 2.2177\n",
      "Epoch 258/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.5835 - mae: 1.0072 - val_loss: 9.5369 - val_mae: 2.1758\n",
      "Epoch 259/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.1873 - mae: 0.8869 - val_loss: 9.3634 - val_mae: 2.1661\n",
      "Epoch 260/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.9750 - mae: 1.3723 - val_loss: 9.6144 - val_mae: 2.1510\n",
      "Epoch 261/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.5445 - mae: 1.2776 - val_loss: 9.2783 - val_mae: 2.1231\n",
      "Epoch 262/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.4959 - mae: 0.9688 - val_loss: 9.9237 - val_mae: 2.1734\n",
      "Epoch 263/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.6337 - mae: 1.0236 - val_loss: 8.8770 - val_mae: 2.1202\n",
      "Epoch 264/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.3843 - mae: 0.9247 - val_loss: 9.0898 - val_mae: 2.1099\n",
      "Epoch 265/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.6967 - mae: 1.0461 - val_loss: 9.8349 - val_mae: 2.1752\n",
      "Epoch 266/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.3184 - mae: 0.9559 - val_loss: 9.4666 - val_mae: 2.1238\n",
      "Epoch 267/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.2201 - mae: 0.8518 - val_loss: 9.7965 - val_mae: 2.1662\n",
      "Epoch 268/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0285 - mae: 0.8221 - val_loss: 10.5911 - val_mae: 2.2466\n",
      "Epoch 269/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.0128 - mae: 1.1591 - val_loss: 10.2971 - val_mae: 2.2459\n",
      "Epoch 270/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.1522 - mae: 1.2654 - val_loss: 10.0646 - val_mae: 2.1985\n",
      "Epoch 271/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.6375 - mae: 1.2897 - val_loss: 10.7754 - val_mae: 2.2058\n",
      "Epoch 272/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.1990 - mae: 0.8957 - val_loss: 9.9805 - val_mae: 2.1107\n",
      "Epoch 273/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.5479 - mae: 1.3066 - val_loss: 9.7006 - val_mae: 2.0924\n",
      "Epoch 274/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.3868 - mae: 0.9165 - val_loss: 9.7886 - val_mae: 2.1052\n",
      "Epoch 275/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.1615 - mae: 0.8356 - val_loss: 9.8805 - val_mae: 2.1351\n",
      "Epoch 276/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.6057 - mae: 1.3137 - val_loss: 9.5504 - val_mae: 2.1036\n",
      "Epoch 277/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 1.7471 - mae: 1.0740 - val_loss: 9.4752 - val_mae: 2.1245\n",
      "Epoch 278/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.9835 - mae: 0.7769 - val_loss: 10.5491 - val_mae: 2.1938\n",
      "Epoch 279/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9825 - mae: 0.7718 - val_loss: 10.2638 - val_mae: 2.1973\n",
      "Epoch 280/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 4.2980 - mae: 1.6708 - val_loss: 10.1869 - val_mae: 2.2354\n",
      "Epoch 281/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.6205 - mae: 1.3945 - val_loss: 10.4442 - val_mae: 2.2079\n",
      "Epoch 282/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8879 - mae: 0.7405 - val_loss: 9.6050 - val_mae: 2.1646\n",
      "Epoch 283/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.4258 - mae: 0.8817 - val_loss: 9.2140 - val_mae: 2.1224\n",
      "Epoch 284/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.8125 - mae: 1.1173 - val_loss: 10.8261 - val_mae: 2.1994\n",
      "Epoch 285/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.9797 - mae: 0.7299 - val_loss: 9.2875 - val_mae: 2.0821\n",
      "Epoch 286/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.6750 - mae: 1.0541 - val_loss: 8.7315 - val_mae: 2.0571\n",
      "Epoch 287/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 3.7388 - mae: 1.5845 - val_loss: 9.1302 - val_mae: 2.0455\n",
      "Epoch 288/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.3026 - mae: 0.8853 - val_loss: 8.9734 - val_mae: 2.0967\n",
      "Epoch 289/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.8926 - mae: 0.7292 - val_loss: 9.0693 - val_mae: 2.1372\n",
      "Epoch 290/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 2.7898 - mae: 1.3901 - val_loss: 9.4647 - val_mae: 2.1111\n",
      "Epoch 291/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9189 - mae: 0.7450 - val_loss: 9.4045 - val_mae: 2.1222\n",
      "Epoch 292/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 4.4956 - mae: 1.6960 - val_loss: 10.1311 - val_mae: 2.1260\n",
      "Epoch 293/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 1.3723 - mae: 0.8905 - val_loss: 10.0950 - val_mae: 2.1694\n",
      "Epoch 294/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.5575 - mae: 1.0542 - val_loss: 9.8856 - val_mae: 2.1688\n",
      "Epoch 295/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.9916 - mae: 1.4022 - val_loss: 10.3528 - val_mae: 2.1795\n",
      "Epoch 296/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.7922 - mae: 0.6651 - val_loss: 9.9283 - val_mae: 2.1610\n",
      "Epoch 297/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.3841 - mae: 1.2822 - val_loss: 10.0296 - val_mae: 2.0903\n",
      "Epoch 298/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9622 - mae: 0.7670 - val_loss: 10.6472 - val_mae: 2.1097\n",
      "Epoch 299/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.1433 - mae: 0.7888 - val_loss: 9.9162 - val_mae: 2.0498\n",
      "Epoch 300/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.6600 - mae: 0.6376 - val_loss: 10.7773 - val_mae: 2.1098\n",
      "Epoch 301/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.2155 - mae: 0.8999 - val_loss: 10.9506 - val_mae: 2.1069\n",
      "Epoch 302/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.7646 - mae: 1.0577 - val_loss: 10.7872 - val_mae: 2.1128\n",
      "Epoch 303/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 3.5669 - mae: 1.6299 - val_loss: 11.2813 - val_mae: 2.1582\n",
      "Epoch 304/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8381 - mae: 0.6878 - val_loss: 10.2360 - val_mae: 2.1266\n",
      "Epoch 305/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.0093 - mae: 0.7763 - val_loss: 9.9193 - val_mae: 2.1460\n",
      "Epoch 306/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 2.0644 - mae: 1.2457 - val_loss: 9.9126 - val_mae: 2.1554\n",
      "Epoch 307/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 1.5855 - mae: 1.0333 - val_loss: 10.0542 - val_mae: 2.0979\n",
      "Epoch 308/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.9534 - mae: 0.7331 - val_loss: 10.3998 - val_mae: 2.1132\n",
      "Epoch 309/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.2390 - mae: 1.2336 - val_loss: 10.1760 - val_mae: 2.1192\n",
      "Epoch 310/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.6582 - mae: 1.0562 - val_loss: 10.6107 - val_mae: 2.1813\n",
      "Epoch 311/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 1.6116 - mae: 1.0280 - val_loss: 9.7755 - val_mae: 2.1181\n",
      "Epoch 312/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 2.0413 - mae: 1.1434 - val_loss: 9.8497 - val_mae: 2.1411\n",
      "Epoch 313/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 3.3503 - mae: 1.4386 - val_loss: 10.5782 - val_mae: 2.1899\n",
      "Epoch 314/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 1.1765 - mae: 0.8629 - val_loss: 10.2600 - val_mae: 2.1756\n",
      "Epoch 315/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.7507 - mae: 0.6777 - val_loss: 9.6381 - val_mae: 2.1181\n",
      "Epoch 316/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.8505 - mae: 0.7326 - val_loss: 9.7664 - val_mae: 2.1778\n",
      "Epoch 317/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.9172 - mae: 1.0874 - val_loss: 10.4423 - val_mae: 2.2024\n",
      "Epoch 318/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.8231 - mae: 1.0938 - val_loss: 10.7900 - val_mae: 2.2194\n",
      "Epoch 319/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.4179 - mae: 0.9741 - val_loss: 9.0401 - val_mae: 2.0615\n",
      "Epoch 320/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9817 - mae: 0.7791 - val_loss: 9.1506 - val_mae: 2.0745\n",
      "Epoch 321/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.5381 - mae: 0.9979 - val_loss: 10.7663 - val_mae: 2.2114\n",
      "Epoch 322/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.8611 - mae: 1.2782 - val_loss: 10.5456 - val_mae: 2.2036\n",
      "Epoch 323/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.9963 - mae: 0.8002 - val_loss: 10.6876 - val_mae: 2.2122\n",
      "Epoch 324/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.8292 - mae: 0.6983 - val_loss: 9.9874 - val_mae: 2.2113\n",
      "Epoch 325/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.6631 - mae: 1.2879 - val_loss: 9.0364 - val_mae: 2.0900\n",
      "Epoch 326/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.8217 - mae: 1.0196 - val_loss: 9.8383 - val_mae: 2.1052\n",
      "Epoch 327/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.1454 - mae: 0.8328 - val_loss: 8.8519 - val_mae: 2.0492\n",
      "Epoch 328/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.9997 - mae: 1.1313 - val_loss: 8.9460 - val_mae: 2.0469\n",
      "Epoch 329/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 2.5538 - mae: 1.3930 - val_loss: 9.2701 - val_mae: 2.0898\n",
      "Epoch 330/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 1.0937 - mae: 0.7842 - val_loss: 9.2007 - val_mae: 2.0282\n",
      "Epoch 331/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.7671 - mae: 0.6448 - val_loss: 9.2654 - val_mae: 2.0562\n",
      "Epoch 332/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 1.4923 - mae: 0.9200 - val_loss: 9.0882 - val_mae: 2.0691\n",
      "Epoch 333/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 1.3901 - mae: 0.9320 - val_loss: 8.7314 - val_mae: 2.0346\n",
      "Epoch 334/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.7858 - mae: 1.0848 - val_loss: 8.9945 - val_mae: 2.0164\n",
      "Epoch 335/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.0555 - mae: 0.7778 - val_loss: 8.8997 - val_mae: 2.0559\n",
      "Epoch 336/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1260 - mae: 0.8469 - val_loss: 9.3581 - val_mae: 2.1164\n",
      "Epoch 337/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.9967 - mae: 0.7444 - val_loss: 8.6595 - val_mae: 1.9946\n",
      "Epoch 338/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 3.3617 - mae: 1.5554 - val_loss: 8.5996 - val_mae: 2.0017\n",
      "Epoch 339/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.6961 - mae: 1.0948 - val_loss: 8.7167 - val_mae: 2.0014\n",
      "Epoch 340/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.1547 - mae: 1.2512 - val_loss: 9.0906 - val_mae: 2.0241\n",
      "Epoch 341/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.6027 - mae: 0.6233 - val_loss: 8.8724 - val_mae: 2.0718\n",
      "Epoch 342/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.8984 - mae: 0.7288 - val_loss: 9.1777 - val_mae: 2.0753\n",
      "Epoch 343/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1446 - mae: 0.8725 - val_loss: 9.2658 - val_mae: 2.0332\n",
      "Epoch 344/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 3.5930 - mae: 1.6261 - val_loss: 8.9606 - val_mae: 2.0273\n",
      "Epoch 345/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.0358 - mae: 1.1715 - val_loss: 9.4314 - val_mae: 2.0528\n",
      "Epoch 346/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.2799 - mae: 1.1717 - val_loss: 9.7151 - val_mae: 2.1252\n",
      "Epoch 347/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.4856 - mae: 1.0172 - val_loss: 8.6956 - val_mae: 2.0411\n",
      "Epoch 348/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.1594 - mae: 0.8411 - val_loss: 8.7742 - val_mae: 2.0447\n",
      "Epoch 349/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 2.0397 - mae: 1.1557 - val_loss: 9.8997 - val_mae: 2.2140\n",
      "Epoch 350/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.1393 - mae: 0.8032 - val_loss: 9.6572 - val_mae: 2.1911\n",
      "Epoch 351/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.8949 - mae: 0.7464 - val_loss: 9.9216 - val_mae: 2.1826\n",
      "Epoch 352/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.2819 - mae: 1.0815 - val_loss: 10.7966 - val_mae: 2.2463\n",
      "Epoch 353/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.1666 - mae: 1.2203 - val_loss: 9.1373 - val_mae: 2.1372\n",
      "Epoch 354/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 3.0861 - mae: 1.5604 - val_loss: 9.9113 - val_mae: 2.1823\n",
      "Epoch 355/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.7318 - mae: 1.0454 - val_loss: 9.9309 - val_mae: 2.1773\n",
      "Epoch 356/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.5979 - mae: 1.0553 - val_loss: 9.6490 - val_mae: 2.1175\n",
      "Epoch 357/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.4133 - mae: 0.8080 - val_loss: 9.5294 - val_mae: 2.1187\n",
      "Epoch 358/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.6678 - mae: 1.0421 - val_loss: 10.4552 - val_mae: 2.1970\n",
      "Epoch 359/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.3630 - mae: 0.9425 - val_loss: 9.8038 - val_mae: 2.1031\n",
      "Epoch 360/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.2527 - mae: 0.8657 - val_loss: 10.0404 - val_mae: 2.1135\n",
      "Epoch 361/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.3245 - mae: 0.9050 - val_loss: 10.5661 - val_mae: 2.1683\n",
      "Epoch 362/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.6206 - mae: 1.0309 - val_loss: 9.7353 - val_mae: 2.1293\n",
      "Epoch 363/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.6504 - mae: 0.6412 - val_loss: 9.7270 - val_mae: 2.1051\n",
      "Epoch 364/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.3032 - mae: 1.2926 - val_loss: 9.5556 - val_mae: 2.0947\n",
      "Epoch 365/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.9742 - mae: 0.7594 - val_loss: 9.8122 - val_mae: 2.0931\n",
      "Epoch 366/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.7684 - mae: 1.0349 - val_loss: 9.6196 - val_mae: 2.0581\n",
      "Epoch 367/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.8959 - mae: 1.1823 - val_loss: 10.3705 - val_mae: 2.1173\n",
      "Epoch 368/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.9698 - mae: 1.1972 - val_loss: 10.3120 - val_mae: 2.1365\n",
      "Epoch 369/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 1.7018 - mae: 1.1072 - val_loss: 9.8209 - val_mae: 2.0874\n",
      "Epoch 370/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.6877 - mae: 0.6466 - val_loss: 10.2674 - val_mae: 2.1455\n",
      "Epoch 371/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.0513 - mae: 1.0270 - val_loss: 10.3382 - val_mae: 2.1625\n",
      "Epoch 372/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.9642 - mae: 0.7646 - val_loss: 10.9605 - val_mae: 2.2587\n",
      "Epoch 373/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.1611 - mae: 1.1297 - val_loss: 10.6212 - val_mae: 2.2046\n",
      "Epoch 374/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9125 - mae: 0.7250 - val_loss: 10.6639 - val_mae: 2.1552\n",
      "Epoch 375/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8172 - mae: 0.7135 - val_loss: 10.6303 - val_mae: 2.1779\n",
      "Epoch 376/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 3.6217 - mae: 1.5370 - val_loss: 9.9994 - val_mae: 2.1759\n",
      "Epoch 377/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.0704 - mae: 1.1038 - val_loss: 10.3997 - val_mae: 2.1949\n",
      "Epoch 378/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 3.2423 - mae: 1.3139 - val_loss: 12.8990 - val_mae: 2.3429\n",
      "Epoch 379/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.7349 - mae: 1.0567 - val_loss: 11.8490 - val_mae: 2.2610\n",
      "Epoch 380/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.7634 - mae: 1.0228 - val_loss: 10.5151 - val_mae: 2.1726\n",
      "Epoch 381/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 2.0834 - mae: 1.1572 - val_loss: 10.3150 - val_mae: 2.1856\n",
      "Epoch 382/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.3428 - mae: 1.3328 - val_loss: 9.8521 - val_mae: 2.1348\n",
      "Epoch 383/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 4.9501 - mae: 1.8352 - val_loss: 10.4978 - val_mae: 2.1540\n",
      "Epoch 384/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.0364 - mae: 0.7867 - val_loss: 10.4436 - val_mae: 2.1451\n",
      "Epoch 385/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.7003 - mae: 0.6749 - val_loss: 10.6223 - val_mae: 2.1903\n",
      "Epoch 386/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.5591 - mae: 0.5981 - val_loss: 10.8858 - val_mae: 2.2311\n",
      "Epoch 387/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.7367 - mae: 1.0613 - val_loss: 10.2939 - val_mae: 2.2280\n",
      "Epoch 388/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.8421 - mae: 0.7182 - val_loss: 10.1089 - val_mae: 2.2040\n",
      "Epoch 389/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.9237 - mae: 0.7392 - val_loss: 11.3588 - val_mae: 2.2457\n",
      "Epoch 390/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.0474 - mae: 0.8144 - val_loss: 10.6187 - val_mae: 2.1730\n",
      "Epoch 391/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.0808 - mae: 1.1303 - val_loss: 9.7492 - val_mae: 2.1559\n",
      "Epoch 392/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.8384 - mae: 0.6906 - val_loss: 8.9543 - val_mae: 2.0852\n",
      "Epoch 393/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9077 - mae: 0.7728 - val_loss: 9.3011 - val_mae: 2.1277\n",
      "Epoch 394/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.5443 - mae: 0.5666 - val_loss: 9.0828 - val_mae: 2.1102\n",
      "Epoch 395/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.0531 - mae: 0.7530 - val_loss: 9.4414 - val_mae: 2.1170\n",
      "Epoch 396/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.4319 - mae: 0.9454 - val_loss: 10.3898 - val_mae: 2.1692\n",
      "Epoch 397/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.4082 - mae: 0.9726 - val_loss: 10.5877 - val_mae: 2.2102\n",
      "Epoch 398/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.1843 - mae: 0.8515 - val_loss: 10.2365 - val_mae: 2.1565\n",
      "Epoch 399/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.8882 - mae: 0.7384 - val_loss: 9.0737 - val_mae: 2.0693\n",
      "Epoch 400/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.8369 - mae: 0.7134 - val_loss: 9.8382 - val_mae: 2.1467\n",
      "Epoch 401/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.2607 - mae: 0.8447 - val_loss: 11.1771 - val_mae: 2.2872\n",
      "Epoch 402/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 4.9569 - mae: 1.8909 - val_loss: 9.9331 - val_mae: 2.1303\n",
      "Epoch 403/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.1837 - mae: 0.8597 - val_loss: 10.5080 - val_mae: 2.1279\n",
      "Epoch 404/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.3332 - mae: 0.9684 - val_loss: 10.6549 - val_mae: 2.1764\n",
      "Epoch 405/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.3717 - mae: 0.8326 - val_loss: 10.2040 - val_mae: 2.1838\n",
      "Epoch 406/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.0935 - mae: 0.8263 - val_loss: 9.6957 - val_mae: 2.1725\n",
      "Epoch 407/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.3660 - mae: 0.8663 - val_loss: 9.9680 - val_mae: 2.2044\n",
      "Epoch 408/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.9598 - mae: 1.5116 - val_loss: 10.7009 - val_mae: 2.2303\n",
      "Epoch 409/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 1.2623 - mae: 0.9243 - val_loss: 9.8253 - val_mae: 2.1427\n",
      "Epoch 410/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 321ms/step - loss: 1.9737 - mae: 1.1569 - val_loss: 9.9151 - val_mae: 2.0889\n",
      "Epoch 411/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 329ms/step - loss: 1.0230 - mae: 0.7692 - val_loss: 10.1333 - val_mae: 2.1373\n",
      "Epoch 412/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - loss: 0.9859 - mae: 0.8009 - val_loss: 9.2113 - val_mae: 2.0414\n",
      "Epoch 413/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 332ms/step - loss: 0.8700 - mae: 0.7463 - val_loss: 9.6627 - val_mae: 2.0788\n",
      "Epoch 414/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 343ms/step - loss: 2.2607 - mae: 1.2441 - val_loss: 10.5992 - val_mae: 2.1823\n",
      "Epoch 415/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 556ms/step - loss: 1.3886 - mae: 0.9165 - val_loss: 9.7213 - val_mae: 2.1623\n",
      "Epoch 416/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 845ms/step - loss: 0.9236 - mae: 0.7248 - val_loss: 9.5116 - val_mae: 2.1368\n",
      "Epoch 417/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 870ms/step - loss: 2.9807 - mae: 1.4711 - val_loss: 9.8619 - val_mae: 2.1998\n",
      "Epoch 418/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 989ms/step - loss: 2.7885 - mae: 1.3961 - val_loss: 10.1130 - val_mae: 2.1484\n",
      "Epoch 419/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 891ms/step - loss: 2.2104 - mae: 1.2335 - val_loss: 10.6305 - val_mae: 2.1134\n",
      "Epoch 420/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 940ms/step - loss: 1.1767 - mae: 0.8371 - val_loss: 10.0026 - val_mae: 2.1223\n",
      "Epoch 421/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 865ms/step - loss: 2.6902 - mae: 1.4010 - val_loss: 9.6517 - val_mae: 2.1172\n",
      "Epoch 422/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 890ms/step - loss: 1.2781 - mae: 0.8573 - val_loss: 9.4768 - val_mae: 2.0956\n",
      "Epoch 423/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 854ms/step - loss: 1.0321 - mae: 0.7906 - val_loss: 9.2878 - val_mae: 2.1069\n",
      "Epoch 424/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 884ms/step - loss: 0.9933 - mae: 0.7692 - val_loss: 9.7342 - val_mae: 2.1059\n",
      "Epoch 425/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 887ms/step - loss: 1.1038 - mae: 0.7399 - val_loss: 9.6201 - val_mae: 2.0858\n",
      "Epoch 426/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 960ms/step - loss: 0.5847 - mae: 0.6012 - val_loss: 9.2053 - val_mae: 2.0181\n",
      "Epoch 427/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 875ms/step - loss: 2.9675 - mae: 1.3132 - val_loss: 9.2036 - val_mae: 2.0185\n",
      "Epoch 428/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 852ms/step - loss: 3.3897 - mae: 1.3601 - val_loss: 9.4506 - val_mae: 2.0467\n",
      "Epoch 429/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 913ms/step - loss: 1.1188 - mae: 0.8404 - val_loss: 8.8635 - val_mae: 1.9921\n",
      "Epoch 430/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 864ms/step - loss: 1.8762 - mae: 1.1454 - val_loss: 9.1148 - val_mae: 1.9985\n",
      "Epoch 431/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 862ms/step - loss: 0.9359 - mae: 0.7462 - val_loss: 9.4959 - val_mae: 2.0408\n",
      "Epoch 432/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 866ms/step - loss: 0.7133 - mae: 0.6313 - val_loss: 9.2603 - val_mae: 2.0375\n",
      "Epoch 433/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 854ms/step - loss: 0.6473 - mae: 0.6268 - val_loss: 9.0917 - val_mae: 1.9889\n",
      "Epoch 434/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 861ms/step - loss: 0.7287 - mae: 0.6750 - val_loss: 9.4786 - val_mae: 2.0542\n",
      "Epoch 435/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 866ms/step - loss: 1.6106 - mae: 1.0636 - val_loss: 9.0359 - val_mae: 2.0682\n",
      "Epoch 436/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 869ms/step - loss: 1.0835 - mae: 0.8506 - val_loss: 9.6732 - val_mae: 2.1042\n",
      "Epoch 437/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 874ms/step - loss: 1.2585 - mae: 0.9490 - val_loss: 9.5493 - val_mae: 2.1058\n",
      "Epoch 438/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 855ms/step - loss: 3.7369 - mae: 1.6695 - val_loss: 8.9548 - val_mae: 2.0336\n",
      "Epoch 439/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 895ms/step - loss: 0.9135 - mae: 0.7736 - val_loss: 9.2307 - val_mae: 2.0555\n",
      "Epoch 440/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 910ms/step - loss: 0.8279 - mae: 0.7398 - val_loss: 9.1661 - val_mae: 2.0705\n",
      "Epoch 441/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 867ms/step - loss: 1.3084 - mae: 0.8801 - val_loss: 9.0742 - val_mae: 2.0479\n",
      "Epoch 442/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 991ms/step - loss: 1.7745 - mae: 1.1427 - val_loss: 9.6780 - val_mae: 2.1024\n",
      "Epoch 443/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 849ms/step - loss: 1.4461 - mae: 1.0033 - val_loss: 8.9358 - val_mae: 2.0494\n",
      "Epoch 444/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 867ms/step - loss: 0.6367 - mae: 0.6142 - val_loss: 9.5115 - val_mae: 2.1010\n",
      "Epoch 445/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 856ms/step - loss: 2.0643 - mae: 1.1877 - val_loss: 9.9660 - val_mae: 2.1682\n",
      "Epoch 446/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 873ms/step - loss: 0.7783 - mae: 0.6705 - val_loss: 9.0964 - val_mae: 2.0999\n",
      "Epoch 447/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 878ms/step - loss: 0.9591 - mae: 0.7786 - val_loss: 8.9691 - val_mae: 2.0839\n",
      "Epoch 448/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 850ms/step - loss: 1.2634 - mae: 0.9006 - val_loss: 10.0593 - val_mae: 2.1230\n",
      "Epoch 449/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 901ms/step - loss: 3.6748 - mae: 1.5935 - val_loss: 8.9722 - val_mae: 2.1043\n",
      "Epoch 450/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 889ms/step - loss: 2.5671 - mae: 1.2917 - val_loss: 9.0693 - val_mae: 2.0977\n",
      "Epoch 451/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 874ms/step - loss: 1.5923 - mae: 1.0591 - val_loss: 9.7323 - val_mae: 2.1263\n",
      "Epoch 452/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 881ms/step - loss: 0.7531 - mae: 0.6613 - val_loss: 9.0144 - val_mae: 2.0721\n",
      "Epoch 453/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 858ms/step - loss: 2.0206 - mae: 1.0703 - val_loss: 8.8418 - val_mae: 2.0332\n",
      "Epoch 454/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 869ms/step - loss: 0.7335 - mae: 0.6604 - val_loss: 9.0319 - val_mae: 2.0592\n",
      "Epoch 455/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 867ms/step - loss: 0.7672 - mae: 0.6545 - val_loss: 9.0697 - val_mae: 2.1028\n",
      "Epoch 456/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 914ms/step - loss: 0.5214 - mae: 0.5662 - val_loss: 9.1374 - val_mae: 2.1440\n",
      "Epoch 457/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 867ms/step - loss: 1.0836 - mae: 0.8749 - val_loss: 9.1624 - val_mae: 2.1358\n",
      "Epoch 458/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 952ms/step - loss: 1.5869 - mae: 1.0074 - val_loss: 9.0639 - val_mae: 2.1437\n",
      "Epoch 459/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 862ms/step - loss: 1.6211 - mae: 1.0752 - val_loss: 9.3346 - val_mae: 2.1622\n",
      "Epoch 460/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 862ms/step - loss: 1.8138 - mae: 1.0749 - val_loss: 9.2235 - val_mae: 2.1296\n",
      "Epoch 461/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 904ms/step - loss: 1.8422 - mae: 1.1260 - val_loss: 9.2459 - val_mae: 2.1526\n",
      "Epoch 462/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 863ms/step - loss: 2.6057 - mae: 1.3664 - val_loss: 9.8767 - val_mae: 2.2168\n",
      "Epoch 463/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 925ms/step - loss: 1.9335 - mae: 1.2073 - val_loss: 9.5421 - val_mae: 2.1816\n",
      "Epoch 464/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 880ms/step - loss: 1.0504 - mae: 0.7895 - val_loss: 9.5261 - val_mae: 2.1656\n",
      "Epoch 465/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 979ms/step - loss: 1.0161 - mae: 0.7800 - val_loss: 9.3906 - val_mae: 2.1578\n",
      "Epoch 466/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 873ms/step - loss: 1.1143 - mae: 0.8817 - val_loss: 9.1800 - val_mae: 2.1570\n",
      "Epoch 467/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 850ms/step - loss: 0.9988 - mae: 0.7877 - val_loss: 8.6441 - val_mae: 2.0797\n",
      "Epoch 468/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 943ms/step - loss: 0.8209 - mae: 0.6911 - val_loss: 8.9886 - val_mae: 2.1201\n",
      "Epoch 469/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 874ms/step - loss: 3.7204 - mae: 1.5352 - val_loss: 10.1505 - val_mae: 2.2497\n",
      "Epoch 470/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 855ms/step - loss: 4.1460 - mae: 1.8388 - val_loss: 9.8780 - val_mae: 2.2298\n",
      "Epoch 471/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 875ms/step - loss: 0.7984 - mae: 0.6945 - val_loss: 8.9760 - val_mae: 2.1181\n",
      "Epoch 472/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 966ms/step - loss: 4.0555 - mae: 1.6278 - val_loss: 9.4377 - val_mae: 2.1771\n",
      "Epoch 473/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 859ms/step - loss: 1.7515 - mae: 1.0237 - val_loss: 9.8720 - val_mae: 2.1991\n",
      "Epoch 474/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 877ms/step - loss: 1.0107 - mae: 0.8074 - val_loss: 9.2953 - val_mae: 2.1356\n",
      "Epoch 475/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 857ms/step - loss: 0.8501 - mae: 0.6517 - val_loss: 9.5053 - val_mae: 2.1704\n",
      "Epoch 476/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 887ms/step - loss: 2.7143 - mae: 1.4250 - val_loss: 10.2138 - val_mae: 2.2291\n",
      "Epoch 477/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 870ms/step - loss: 1.2095 - mae: 0.8549 - val_loss: 10.0191 - val_mae: 2.1671\n",
      "Epoch 478/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 938ms/step - loss: 0.8281 - mae: 0.7255 - val_loss: 10.4714 - val_mae: 2.2271\n",
      "Epoch 479/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 891ms/step - loss: 1.9408 - mae: 1.1702 - val_loss: 9.8455 - val_mae: 2.1851\n",
      "Epoch 480/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 932ms/step - loss: 2.3635 - mae: 1.2394 - val_loss: 9.4727 - val_mae: 2.1374\n",
      "Epoch 481/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 861ms/step - loss: 1.6663 - mae: 1.0904 - val_loss: 9.8422 - val_mae: 2.1963\n",
      "Epoch 482/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 875ms/step - loss: 2.0001 - mae: 1.1140 - val_loss: 10.5545 - val_mae: 2.2277\n",
      "Epoch 483/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 900ms/step - loss: 2.8987 - mae: 1.4429 - val_loss: 9.9574 - val_mae: 2.1423\n",
      "Epoch 484/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 2.9210 - mae: 1.3321 - val_loss: 9.8802 - val_mae: 2.2051\n",
      "Epoch 485/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.0787 - mae: 0.8315 - val_loss: 9.3821 - val_mae: 2.1889\n",
      "Epoch 486/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.3228 - mae: 0.9314 - val_loss: 8.9410 - val_mae: 2.0863\n",
      "Epoch 487/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.7245 - mae: 1.1139 - val_loss: 9.5631 - val_mae: 2.1095\n",
      "Epoch 488/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 3.0484 - mae: 1.3383 - val_loss: 9.6248 - val_mae: 2.1400\n",
      "Epoch 489/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0172 - mae: 0.8288 - val_loss: 9.4533 - val_mae: 2.1239\n",
      "Epoch 490/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.8606 - mae: 0.7433 - val_loss: 8.9190 - val_mae: 2.0963\n",
      "Epoch 491/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.4050 - mae: 0.9718 - val_loss: 9.6006 - val_mae: 2.1031\n",
      "Epoch 492/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.2542 - mae: 0.9030 - val_loss: 9.2896 - val_mae: 2.1233\n",
      "Epoch 493/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.4210 - mae: 1.0182 - val_loss: 9.3298 - val_mae: 2.1268\n",
      "Epoch 494/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.9094 - mae: 0.7485 - val_loss: 8.8389 - val_mae: 2.0822\n",
      "Epoch 495/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.0454 - mae: 0.8343 - val_loss: 9.4197 - val_mae: 2.1556\n",
      "Epoch 496/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.6448 - mae: 1.1255 - val_loss: 10.7947 - val_mae: 2.2658\n",
      "Epoch 497/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.5360 - mae: 0.5853 - val_loss: 9.9638 - val_mae: 2.2280\n",
      "Epoch 498/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 1.5128 - mae: 1.0289 - val_loss: 11.0770 - val_mae: 2.3228\n",
      "Epoch 499/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.0498 - mae: 0.8413 - val_loss: 10.0067 - val_mae: 2.2564\n",
      "Epoch 500/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.9250 - mae: 0.7991 - val_loss: 9.4500 - val_mae: 2.1756\n",
      "Epoch 501/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.6672 - mae: 1.0720 - val_loss: 10.6138 - val_mae: 2.2801\n",
      "Epoch 502/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.3764 - mae: 0.9632 - val_loss: 9.1059 - val_mae: 2.1394\n",
      "Epoch 503/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.2460 - mae: 0.8900 - val_loss: 9.8449 - val_mae: 2.1920\n",
      "Epoch 504/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.1063 - mae: 0.8195 - val_loss: 10.1116 - val_mae: 2.2396\n",
      "Epoch 505/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.2613 - mae: 1.5054 - val_loss: 9.1652 - val_mae: 2.1364\n",
      "Epoch 506/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 1.3378 - mae: 0.9512 - val_loss: 8.7385 - val_mae: 2.0776\n",
      "Epoch 507/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.3067 - mae: 0.9676 - val_loss: 9.8104 - val_mae: 2.1483\n",
      "Epoch 508/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.5010 - mae: 1.0260 - val_loss: 9.4664 - val_mae: 2.1543\n",
      "Epoch 509/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.4926 - mae: 1.0225 - val_loss: 9.0396 - val_mae: 2.1788\n",
      "Epoch 510/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.7661 - mae: 1.0869 - val_loss: 9.7919 - val_mae: 2.2037\n",
      "Epoch 511/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7096 - mae: 0.6627 - val_loss: 9.7845 - val_mae: 2.1722\n",
      "Epoch 512/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.8319 - mae: 1.1260 - val_loss: 9.2376 - val_mae: 2.0885\n",
      "Epoch 513/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.0198 - mae: 1.1661 - val_loss: 10.0044 - val_mae: 2.2089\n",
      "Epoch 514/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.1931 - mae: 0.8612 - val_loss: 9.1516 - val_mae: 2.1493\n",
      "Epoch 515/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.7007 - mae: 0.6592 - val_loss: 9.3004 - val_mae: 2.1420\n",
      "Epoch 516/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0004 - mae: 0.7486 - val_loss: 10.1691 - val_mae: 2.2168\n",
      "Epoch 517/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.3923 - mae: 1.3279 - val_loss: 9.5288 - val_mae: 2.1768\n",
      "Epoch 518/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4077 - mae: 0.9076 - val_loss: 9.5704 - val_mae: 2.1614\n",
      "Epoch 519/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.5436 - mae: 0.5711 - val_loss: 9.6867 - val_mae: 2.1382\n",
      "Epoch 520/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 2.6788 - mae: 1.3997 - val_loss: 10.1645 - val_mae: 2.2347\n",
      "Epoch 521/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.0554 - mae: 0.7906 - val_loss: 10.0326 - val_mae: 2.2699\n",
      "Epoch 522/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.5575 - mae: 0.9840 - val_loss: 9.5928 - val_mae: 2.1916\n",
      "Epoch 523/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.5876 - mae: 1.4172 - val_loss: 9.9716 - val_mae: 2.2406\n",
      "Epoch 524/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.5262 - mae: 0.5756 - val_loss: 9.5936 - val_mae: 2.2143\n",
      "Epoch 525/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 3.2942 - mae: 1.5754 - val_loss: 9.6535 - val_mae: 2.2212\n",
      "Epoch 526/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.9286 - mae: 0.7726 - val_loss: 9.6650 - val_mae: 2.2159\n",
      "Epoch 527/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.0226 - mae: 0.7621 - val_loss: 10.0720 - val_mae: 2.2686\n",
      "Epoch 528/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.4448 - mae: 1.0088 - val_loss: 10.3802 - val_mae: 2.2569\n",
      "Epoch 529/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.7280 - mae: 1.4748 - val_loss: 9.1561 - val_mae: 2.1707\n",
      "Epoch 530/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.5152 - mae: 0.9798 - val_loss: 10.3123 - val_mae: 2.2261\n",
      "Epoch 531/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.1458 - mae: 1.2427 - val_loss: 10.8679 - val_mae: 2.2666\n",
      "Epoch 532/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.7462 - mae: 0.7050 - val_loss: 10.8369 - val_mae: 2.2962\n",
      "Epoch 533/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.9506 - mae: 0.7326 - val_loss: 10.7417 - val_mae: 2.3105\n",
      "Epoch 534/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.4165 - mae: 0.8934 - val_loss: 10.7488 - val_mae: 2.3182\n",
      "Epoch 535/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.1054 - mae: 0.8762 - val_loss: 10.7137 - val_mae: 2.2554\n",
      "Epoch 536/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.9586 - mae: 0.7657 - val_loss: 10.3855 - val_mae: 2.2304\n",
      "Epoch 537/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.8549 - mae: 0.7658 - val_loss: 10.6220 - val_mae: 2.2223\n",
      "Epoch 538/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.4094 - mae: 0.9922 - val_loss: 11.2439 - val_mae: 2.2806\n",
      "Epoch 539/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.5841 - mae: 1.0138 - val_loss: 10.5823 - val_mae: 2.2160\n",
      "Epoch 540/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.1254 - mae: 1.2652 - val_loss: 10.8437 - val_mae: 2.2413\n",
      "Epoch 541/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.6875 - mae: 1.4073 - val_loss: 11.1531 - val_mae: 2.2416\n",
      "Epoch 542/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.2753 - mae: 0.9239 - val_loss: 10.5224 - val_mae: 2.1938\n",
      "Epoch 543/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.9037 - mae: 0.7651 - val_loss: 9.3054 - val_mae: 2.1974\n",
      "Epoch 544/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.1047 - mae: 0.8668 - val_loss: 9.9956 - val_mae: 2.2375\n",
      "Epoch 545/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.7513 - mae: 0.6776 - val_loss: 11.0006 - val_mae: 2.2921\n",
      "Epoch 546/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2.2203 - mae: 1.1936 - val_loss: 9.9923 - val_mae: 2.2203\n",
      "Epoch 547/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.0338 - mae: 0.8197 - val_loss: 9.4111 - val_mae: 2.1591\n",
      "Epoch 548/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.5102 - mae: 1.0260 - val_loss: 9.6174 - val_mae: 2.1936\n",
      "Epoch 549/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.8836 - mae: 0.7609 - val_loss: 9.5579 - val_mae: 2.1775\n",
      "Epoch 550/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2.3098 - mae: 1.2651 - val_loss: 9.8623 - val_mae: 2.1897\n",
      "Epoch 551/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.2357 - mae: 0.9605 - val_loss: 10.6369 - val_mae: 2.2894\n",
      "Epoch 552/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.4429 - mae: 0.9910 - val_loss: 9.7902 - val_mae: 2.2357\n",
      "Epoch 553/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.6654 - mae: 0.6638 - val_loss: 8.4823 - val_mae: 2.1219\n",
      "Epoch 554/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.6102 - mae: 1.0375 - val_loss: 9.2150 - val_mae: 2.1366\n",
      "Epoch 555/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.7837 - mae: 0.7285 - val_loss: 9.5046 - val_mae: 2.1706\n",
      "Epoch 556/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.0894 - mae: 0.8480 - val_loss: 9.0691 - val_mae: 2.1675\n",
      "Epoch 557/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7137 - mae: 0.6694 - val_loss: 9.2154 - val_mae: 2.1939\n",
      "Epoch 558/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.7081 - mae: 1.0160 - val_loss: 9.0529 - val_mae: 2.1527\n",
      "Epoch 559/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.8316 - mae: 0.7314 - val_loss: 9.0448 - val_mae: 2.1643\n",
      "Epoch 560/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.9816 - mae: 1.3815 - val_loss: 10.1481 - val_mae: 2.2324\n",
      "Epoch 561/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.9770 - mae: 0.7979 - val_loss: 9.7343 - val_mae: 2.2221\n",
      "Epoch 562/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7991 - mae: 0.7076 - val_loss: 10.2198 - val_mae: 2.2577\n",
      "Epoch 563/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.6458 - mae: 1.2990 - val_loss: 10.5413 - val_mae: 2.2749\n",
      "Epoch 564/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.5077 - mae: 1.6011 - val_loss: 10.6969 - val_mae: 2.2435\n",
      "Epoch 565/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 2.9090 - mae: 1.3671 - val_loss: 10.2633 - val_mae: 2.2121\n",
      "Epoch 566/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7779 - mae: 0.7216 - val_loss: 10.2224 - val_mae: 2.1942\n",
      "Epoch 567/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.1958 - mae: 0.8709 - val_loss: 9.6989 - val_mae: 2.1606\n",
      "Epoch 568/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.0071 - mae: 0.7837 - val_loss: 10.1645 - val_mae: 2.1684\n",
      "Epoch 569/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.3728 - mae: 0.9484 - val_loss: 9.9736 - val_mae: 2.1696\n",
      "Epoch 570/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.2877 - mae: 0.8914 - val_loss: 8.9030 - val_mae: 2.0933\n",
      "Epoch 571/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.1121 - mae: 0.8349 - val_loss: 11.4922 - val_mae: 2.2958\n",
      "Epoch 572/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.2746 - mae: 0.9025 - val_loss: 9.7408 - val_mae: 2.1487\n",
      "Epoch 573/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.2446 - mae: 0.8975 - val_loss: 9.5989 - val_mae: 2.1446\n",
      "Epoch 574/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.8351 - mae: 0.6992 - val_loss: 9.9815 - val_mae: 2.1910\n",
      "Epoch 575/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.8429 - mae: 0.7346 - val_loss: 9.0884 - val_mae: 2.1347\n",
      "Epoch 576/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.6079 - mae: 0.6055 - val_loss: 10.2003 - val_mae: 2.1658\n",
      "Epoch 577/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.9875 - mae: 0.8077 - val_loss: 9.5459 - val_mae: 2.1855\n",
      "Epoch 578/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.8341 - mae: 0.7336 - val_loss: 9.0637 - val_mae: 2.1608\n",
      "Epoch 579/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2460 - mae: 0.9554 - val_loss: 9.9631 - val_mae: 2.1560\n",
      "Epoch 580/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.6811 - mae: 1.0893 - val_loss: 9.3098 - val_mae: 2.1577\n",
      "Epoch 581/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.0565 - mae: 0.8465 - val_loss: 9.4537 - val_mae: 2.1761\n",
      "Epoch 582/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.7021 - mae: 0.6780 - val_loss: 9.7993 - val_mae: 2.2074\n",
      "Epoch 583/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.2311 - mae: 0.8640 - val_loss: 9.3967 - val_mae: 2.2644\n",
      "Epoch 584/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.1722 - mae: 0.8986 - val_loss: 9.2090 - val_mae: 2.1946\n",
      "Epoch 585/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.5487 - mae: 1.0683 - val_loss: 9.7961 - val_mae: 2.1930\n",
      "Epoch 586/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.7619 - mae: 1.1010 - val_loss: 9.1506 - val_mae: 2.1375\n",
      "Epoch 587/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.3848 - mae: 1.2850 - val_loss: 10.0799 - val_mae: 2.1641\n",
      "Epoch 588/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2325 - mae: 0.9070 - val_loss: 10.1662 - val_mae: 2.1743\n",
      "Epoch 589/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.7599 - mae: 0.6694 - val_loss: 9.0316 - val_mae: 2.2007\n",
      "Epoch 590/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.3105 - mae: 0.8887 - val_loss: 10.2641 - val_mae: 2.2305\n",
      "Epoch 591/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.4973 - mae: 1.4110 - val_loss: 10.8046 - val_mae: 2.2152\n",
      "Epoch 592/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.9952 - mae: 0.7885 - val_loss: 9.7596 - val_mae: 2.2068\n",
      "Epoch 593/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.5938 - mae: 0.6073 - val_loss: 10.0565 - val_mae: 2.2335\n",
      "Epoch 594/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 5.7493 - mae: 1.9292 - val_loss: 9.5290 - val_mae: 2.1108\n",
      "Epoch 595/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.1085 - mae: 0.7619 - val_loss: 9.0194 - val_mae: 2.0964\n",
      "Epoch 596/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.8781 - mae: 0.7700 - val_loss: 9.5243 - val_mae: 2.1917\n",
      "Epoch 597/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.8894 - mae: 0.7101 - val_loss: 10.1894 - val_mae: 2.2421\n",
      "Epoch 598/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.8298 - mae: 1.1211 - val_loss: 9.0643 - val_mae: 2.1332\n",
      "Epoch 599/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.1829 - mae: 1.2542 - val_loss: 9.9654 - val_mae: 2.1910\n",
      "Epoch 600/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 2.4034 - mae: 1.2962 - val_loss: 10.9382 - val_mae: 2.3006\n",
      "Epoch 601/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.7253 - mae: 1.1532 - val_loss: 9.8710 - val_mae: 2.1903\n",
      "Epoch 602/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.6387 - mae: 0.6197 - val_loss: 9.4790 - val_mae: 2.1717\n",
      "Epoch 603/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.4695 - mae: 1.2070 - val_loss: 10.6043 - val_mae: 2.2219\n",
      "Epoch 604/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.9043 - mae: 0.6947 - val_loss: 10.6553 - val_mae: 2.1879\n",
      "Epoch 605/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.6962 - mae: 1.1525 - val_loss: 10.1053 - val_mae: 2.1699\n",
      "Epoch 606/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.5018 - mae: 0.5207 - val_loss: 10.2836 - val_mae: 2.2096\n",
      "Epoch 607/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4766 - mae: 1.0331 - val_loss: 10.2750 - val_mae: 2.1808\n",
      "Epoch 608/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.8971 - mae: 0.7528 - val_loss: 9.7048 - val_mae: 2.1481\n",
      "Epoch 609/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.7973 - mae: 0.6580 - val_loss: 10.9526 - val_mae: 2.2196\n",
      "Epoch 610/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.0202 - mae: 1.2046 - val_loss: 10.2667 - val_mae: 2.2162\n",
      "Epoch 611/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.6322 - mae: 0.6417 - val_loss: 10.1798 - val_mae: 2.1826\n",
      "Epoch 612/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7572 - mae: 0.7258 - val_loss: 11.5185 - val_mae: 2.2667\n",
      "Epoch 613/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.7621 - mae: 1.4919 - val_loss: 11.5614 - val_mae: 2.2826\n",
      "Epoch 614/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4451 - mae: 0.9488 - val_loss: 10.2865 - val_mae: 2.2288\n",
      "Epoch 615/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.9373 - mae: 0.8068 - val_loss: 10.9309 - val_mae: 2.2464\n",
      "Epoch 616/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.0552 - mae: 0.8559 - val_loss: 9.8699 - val_mae: 2.1854\n",
      "Epoch 617/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.0029 - mae: 0.8251 - val_loss: 9.5090 - val_mae: 2.1669\n",
      "Epoch 618/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.7731 - mae: 1.1485 - val_loss: 10.6412 - val_mae: 2.2485\n",
      "Epoch 619/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.8718 - mae: 1.4223 - val_loss: 10.1644 - val_mae: 2.2216\n",
      "Epoch 620/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.9968 - mae: 1.4520 - val_loss: 10.0339 - val_mae: 2.1843\n",
      "Epoch 621/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.1904 - mae: 1.2957 - val_loss: 10.5362 - val_mae: 2.2216\n",
      "Epoch 622/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.2186 - mae: 0.8525 - val_loss: 10.0632 - val_mae: 2.1976\n",
      "Epoch 623/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.5737 - mae: 1.3727 - val_loss: 10.0542 - val_mae: 2.2164\n",
      "Epoch 624/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.5965 - mae: 0.5782 - val_loss: 10.5960 - val_mae: 2.2724\n",
      "Epoch 625/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2850 - mae: 0.9701 - val_loss: 9.0227 - val_mae: 2.1398\n",
      "Epoch 626/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2322 - mae: 0.9209 - val_loss: 10.1371 - val_mae: 2.1776\n",
      "Epoch 627/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.4776 - mae: 1.0028 - val_loss: 10.6884 - val_mae: 2.2617\n",
      "Epoch 628/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.3803 - mae: 1.6766 - val_loss: 10.0971 - val_mae: 2.2069\n",
      "Epoch 629/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.8518 - mae: 0.7512 - val_loss: 10.0036 - val_mae: 2.1806\n",
      "Epoch 630/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.1015 - mae: 0.8167 - val_loss: 10.4986 - val_mae: 2.2486\n",
      "Epoch 631/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 1.2727 - mae: 0.9005 - val_loss: 10.0321 - val_mae: 2.2005\n",
      "Epoch 632/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.4659 - mae: 1.0094 - val_loss: 9.9129 - val_mae: 2.1801\n",
      "Epoch 633/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.9117 - mae: 1.0713 - val_loss: 9.9465 - val_mae: 2.1652\n",
      "Epoch 634/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.1945 - mae: 0.8841 - val_loss: 10.4817 - val_mae: 2.2263\n",
      "Epoch 635/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.6530 - mae: 0.6603 - val_loss: 9.3013 - val_mae: 2.1183\n",
      "Epoch 636/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.0451 - mae: 0.7863 - val_loss: 9.2736 - val_mae: 2.1268\n",
      "Epoch 637/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.6949 - mae: 0.6484 - val_loss: 9.2526 - val_mae: 2.1184\n",
      "Epoch 638/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.6927 - mae: 1.6673 - val_loss: 9.5615 - val_mae: 2.1434\n",
      "Epoch 639/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 6.1848 - mae: 2.0855 - val_loss: 11.9867 - val_mae: 2.3079\n",
      "Epoch 640/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.4990 - mae: 1.0098 - val_loss: 9.9457 - val_mae: 2.1400\n",
      "Epoch 641/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.9222 - mae: 1.0218 - val_loss: 9.6487 - val_mae: 2.1439\n",
      "Epoch 642/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.0943 - mae: 1.2347 - val_loss: 11.1158 - val_mae: 2.2667\n",
      "Epoch 643/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.1203 - mae: 0.8222 - val_loss: 9.4691 - val_mae: 2.0913\n",
      "Epoch 644/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.7440 - mae: 1.7154 - val_loss: 10.5010 - val_mae: 2.1601\n",
      "Epoch 645/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.1671 - mae: 1.2896 - val_loss: 9.8602 - val_mae: 2.1439\n",
      "Epoch 646/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.7673 - mae: 1.1463 - val_loss: 9.7918 - val_mae: 2.1644\n",
      "Epoch 647/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.0848 - mae: 1.2320 - val_loss: 9.2177 - val_mae: 2.1230\n",
      "Epoch 648/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.5590 - mae: 1.0571 - val_loss: 10.3101 - val_mae: 2.2269\n",
      "Epoch 649/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.5914 - mae: 0.5949 - val_loss: 10.4432 - val_mae: 2.2805\n",
      "Epoch 650/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 3.3263 - mae: 1.4202 - val_loss: 10.5896 - val_mae: 2.2588\n",
      "Epoch 651/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.9297 - mae: 0.7814 - val_loss: 10.3295 - val_mae: 2.2070\n",
      "Epoch 652/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.8060 - mae: 0.7053 - val_loss: 9.5597 - val_mae: 2.1440\n",
      "Epoch 653/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2312 - mae: 0.7806 - val_loss: 9.8545 - val_mae: 2.1813\n",
      "Epoch 654/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.4796 - mae: 1.2742 - val_loss: 9.0910 - val_mae: 2.1539\n",
      "Epoch 655/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0279 - mae: 0.8129 - val_loss: 8.6977 - val_mae: 2.1123\n",
      "Epoch 656/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.0376 - mae: 0.8032 - val_loss: 9.8467 - val_mae: 2.2051\n",
      "Epoch 657/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.5075 - mae: 0.5305 - val_loss: 9.4800 - val_mae: 2.1736\n",
      "Epoch 658/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.8705 - mae: 0.7285 - val_loss: 9.0128 - val_mae: 2.1055\n",
      "Epoch 659/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.1682 - mae: 1.0551 - val_loss: 9.3562 - val_mae: 2.1314\n",
      "Epoch 660/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.9790 - mae: 1.2151 - val_loss: 9.3105 - val_mae: 2.1352\n",
      "Epoch 661/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.6971 - mae: 0.6814 - val_loss: 9.0937 - val_mae: 2.0924\n",
      "Epoch 662/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1377 - mae: 0.8453 - val_loss: 8.6922 - val_mae: 2.0382\n",
      "Epoch 663/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.5966 - mae: 1.0677 - val_loss: 9.1542 - val_mae: 2.0882\n",
      "Epoch 664/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.2239 - mae: 1.3037 - val_loss: 8.6328 - val_mae: 2.0488\n",
      "Epoch 665/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.3676 - mae: 0.4559 - val_loss: 8.7698 - val_mae: 2.0835\n",
      "Epoch 666/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.5534 - mae: 0.9837 - val_loss: 9.1109 - val_mae: 2.1178\n",
      "Epoch 667/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.7859 - mae: 0.6932 - val_loss: 8.8054 - val_mae: 2.0665\n",
      "Epoch 668/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.3267 - mae: 0.8598 - val_loss: 9.0093 - val_mae: 2.1145\n",
      "Epoch 669/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.0244 - mae: 1.2217 - val_loss: 9.3488 - val_mae: 2.1087\n",
      "Epoch 670/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.5466 - mae: 0.5913 - val_loss: 9.7920 - val_mae: 2.1766\n",
      "Epoch 671/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 2.2805 - mae: 1.2801 - val_loss: 9.6138 - val_mae: 2.1629\n",
      "Epoch 672/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.8750 - mae: 0.7251 - val_loss: 9.7090 - val_mae: 2.1528\n",
      "Epoch 673/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.8751 - mae: 0.7836 - val_loss: 9.9497 - val_mae: 2.1655\n",
      "Epoch 674/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9713 - mae: 0.8168 - val_loss: 9.8994 - val_mae: 2.1361\n",
      "Epoch 675/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.9488 - mae: 1.4729 - val_loss: 9.6017 - val_mae: 2.0915\n",
      "Epoch 676/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.6074 - mae: 0.9367 - val_loss: 9.1691 - val_mae: 2.1352\n",
      "Epoch 677/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.9718 - mae: 0.7945 - val_loss: 9.6653 - val_mae: 2.1653\n",
      "Epoch 678/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4065 - mae: 0.8696 - val_loss: 10.0516 - val_mae: 2.1719\n",
      "Epoch 679/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 2.2215 - mae: 1.2520 - val_loss: 8.9200 - val_mae: 2.1087\n",
      "Epoch 680/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2969 - mae: 0.9379 - val_loss: 9.1482 - val_mae: 2.1182\n",
      "Epoch 681/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.7195 - mae: 1.1232 - val_loss: 9.7826 - val_mae: 2.1885\n",
      "Epoch 682/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.6783 - mae: 0.6782 - val_loss: 9.6961 - val_mae: 2.1772\n",
      "Epoch 683/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7696 - mae: 0.6797 - val_loss: 9.3914 - val_mae: 2.1322\n",
      "Epoch 684/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.5408 - mae: 0.5810 - val_loss: 9.2778 - val_mae: 2.1083\n",
      "Epoch 685/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.0059 - mae: 0.7973 - val_loss: 8.9664 - val_mae: 2.0986\n",
      "Epoch 686/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.0036 - mae: 1.1146 - val_loss: 9.1384 - val_mae: 2.0989\n",
      "Epoch 687/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 1.5420 - mae: 1.0058 - val_loss: 10.2439 - val_mae: 2.2175\n",
      "Epoch 688/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.8369 - mae: 1.1028 - val_loss: 10.0821 - val_mae: 2.1974\n",
      "Epoch 689/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.1693 - mae: 0.8645 - val_loss: 10.0161 - val_mae: 2.1933\n",
      "Epoch 690/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.6170 - mae: 0.6253 - val_loss: 9.8862 - val_mae: 2.1825\n",
      "Epoch 691/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2582 - mae: 0.9549 - val_loss: 10.0291 - val_mae: 2.2074\n",
      "Epoch 692/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.1834 - mae: 0.9306 - val_loss: 9.9220 - val_mae: 2.1850\n",
      "Epoch 693/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.5842 - mae: 0.5974 - val_loss: 9.9112 - val_mae: 2.1963\n",
      "Epoch 694/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.2308 - mae: 0.9718 - val_loss: 9.4378 - val_mae: 2.1811\n",
      "Epoch 695/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.3838 - mae: 0.5015 - val_loss: 10.0735 - val_mae: 2.2146\n",
      "Epoch 696/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.7968 - mae: 1.4078 - val_loss: 9.8333 - val_mae: 2.2218\n",
      "Epoch 697/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.1742 - mae: 0.9039 - val_loss: 9.9414 - val_mae: 2.2208\n",
      "Epoch 698/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.2229 - mae: 1.3046 - val_loss: 9.9352 - val_mae: 2.2265\n",
      "Epoch 699/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.6386 - mae: 1.3573 - val_loss: 10.4217 - val_mae: 2.2575\n",
      "Epoch 700/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.6581 - mae: 1.1267 - val_loss: 10.3016 - val_mae: 2.2474\n",
      "Epoch 701/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9773 - mae: 0.7653 - val_loss: 10.4673 - val_mae: 2.2659\n",
      "Epoch 702/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.2447 - mae: 1.2945 - val_loss: 10.9985 - val_mae: 2.2879\n",
      "Epoch 703/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.9868 - mae: 0.8334 - val_loss: 10.4068 - val_mae: 2.2211\n",
      "Epoch 704/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.7908 - mae: 1.4602 - val_loss: 10.5757 - val_mae: 2.2549\n",
      "Epoch 705/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.2463 - mae: 0.9161 - val_loss: 10.6242 - val_mae: 2.2911\n",
      "Epoch 706/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.0340 - mae: 0.8316 - val_loss: 10.3915 - val_mae: 2.2351\n",
      "Epoch 707/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.5637 - mae: 0.5876 - val_loss: 10.0643 - val_mae: 2.1773\n",
      "Epoch 708/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.9391 - mae: 0.8253 - val_loss: 9.1320 - val_mae: 2.1164\n",
      "Epoch 709/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.1359 - mae: 0.8833 - val_loss: 8.9670 - val_mae: 2.0836\n",
      "Epoch 710/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0581 - mae: 0.8436 - val_loss: 10.0403 - val_mae: 2.1633\n",
      "Epoch 711/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.8473 - mae: 0.7343 - val_loss: 8.8582 - val_mae: 2.0575\n",
      "Epoch 712/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 1.2182 - mae: 0.8924 - val_loss: 9.4618 - val_mae: 2.1232\n",
      "Epoch 713/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.1669 - mae: 0.8332 - val_loss: 9.9145 - val_mae: 2.1815\n",
      "Epoch 714/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.1196 - mae: 0.8616 - val_loss: 9.6579 - val_mae: 2.1976\n",
      "Epoch 715/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.6654 - mae: 0.6433 - val_loss: 10.2050 - val_mae: 2.2351\n",
      "Epoch 716/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.5971 - mae: 1.3798 - val_loss: 10.0197 - val_mae: 2.2054\n",
      "Epoch 717/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.2234 - mae: 0.9109 - val_loss: 9.9671 - val_mae: 2.2298\n",
      "Epoch 718/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.1427 - mae: 0.8145 - val_loss: 10.4443 - val_mae: 2.2526\n",
      "Epoch 719/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 3.2761 - mae: 1.4382 - val_loss: 10.5264 - val_mae: 2.2335\n",
      "Epoch 720/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.6851 - mae: 0.6852 - val_loss: 10.6540 - val_mae: 2.2523\n",
      "Epoch 721/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.8794 - mae: 1.2408 - val_loss: 10.6135 - val_mae: 2.2592\n",
      "Epoch 722/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.1512 - mae: 0.9100 - val_loss: 10.2386 - val_mae: 2.2297\n",
      "Epoch 723/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.7070 - mae: 1.0871 - val_loss: 10.3379 - val_mae: 2.2122\n",
      "Epoch 724/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.8553 - mae: 0.7287 - val_loss: 10.5552 - val_mae: 2.2183\n",
      "Epoch 725/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.9820 - mae: 1.2006 - val_loss: 10.8577 - val_mae: 2.2369\n",
      "Epoch 726/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 1.3650 - mae: 0.9381 - val_loss: 11.1170 - val_mae: 2.2521\n",
      "Epoch 727/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2943 - mae: 1.0163 - val_loss: 10.2142 - val_mae: 2.1408\n",
      "Epoch 728/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.3184 - mae: 0.9898 - val_loss: 9.7544 - val_mae: 2.1244\n",
      "Epoch 729/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.7340 - mae: 0.7023 - val_loss: 9.6467 - val_mae: 2.1363\n",
      "Epoch 730/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 2.3784 - mae: 1.3486 - val_loss: 9.0787 - val_mae: 2.0989\n",
      "Epoch 731/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.7860 - mae: 1.1280 - val_loss: 9.7566 - val_mae: 2.1541\n",
      "Epoch 732/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.8111 - mae: 0.7132 - val_loss: 9.5584 - val_mae: 2.1515\n",
      "Epoch 733/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.4806 - mae: 1.0074 - val_loss: 9.6352 - val_mae: 2.1661\n",
      "Epoch 734/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.5413 - mae: 1.3700 - val_loss: 9.5460 - val_mae: 2.1298\n",
      "Epoch 735/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.8624 - mae: 1.1403 - val_loss: 8.9690 - val_mae: 2.0684\n",
      "Epoch 736/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.7056 - mae: 0.6696 - val_loss: 10.8946 - val_mae: 2.2865\n",
      "Epoch 737/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.1064 - mae: 1.1867 - val_loss: 9.0053 - val_mae: 2.1164\n",
      "Epoch 738/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 1.2044 - mae: 0.8499 - val_loss: 10.0055 - val_mae: 2.1093\n",
      "Epoch 739/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.5375 - mae: 1.0482 - val_loss: 10.8908 - val_mae: 2.1711\n",
      "Epoch 740/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.5723 - mae: 1.0487 - val_loss: 10.0391 - val_mae: 2.1391\n",
      "Epoch 741/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.1418 - mae: 0.8644 - val_loss: 10.2658 - val_mae: 2.1498\n",
      "Epoch 742/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 2.4579 - mae: 1.3670 - val_loss: 10.9021 - val_mae: 2.2527\n",
      "Epoch 743/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.6440 - mae: 0.6250 - val_loss: 9.5534 - val_mae: 2.1236\n",
      "Epoch 744/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.5952 - mae: 0.5971 - val_loss: 10.2718 - val_mae: 2.1373\n",
      "Epoch 745/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.8505 - mae: 1.1390 - val_loss: 11.2325 - val_mae: 2.2266\n",
      "Epoch 746/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.6761 - mae: 0.6317 - val_loss: 9.7082 - val_mae: 2.1017\n",
      "Epoch 747/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.6818 - mae: 0.6563 - val_loss: 9.3430 - val_mae: 2.0957\n",
      "Epoch 748/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.8491 - mae: 1.1472 - val_loss: 9.8594 - val_mae: 2.1615\n",
      "Epoch 749/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 2.1532 - mae: 1.3109 - val_loss: 10.0356 - val_mae: 2.1868\n",
      "Epoch 750/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.8182 - mae: 0.7203 - val_loss: 9.4051 - val_mae: 2.1271\n",
      "Epoch 751/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4086 - mae: 0.9968 - val_loss: 9.8336 - val_mae: 2.1196\n",
      "Epoch 752/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.2417 - mae: 0.9169 - val_loss: 9.5924 - val_mae: 2.1385\n",
      "Epoch 753/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.8190 - mae: 1.4351 - val_loss: 9.3105 - val_mae: 2.1402\n",
      "Epoch 754/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.8866 - mae: 0.7028 - val_loss: 9.3466 - val_mae: 2.1011\n",
      "Epoch 755/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8401 - mae: 0.7404 - val_loss: 9.2831 - val_mae: 2.0746\n",
      "Epoch 756/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.1866 - mae: 0.7590 - val_loss: 9.9530 - val_mae: 2.1541\n",
      "Epoch 757/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 2.0157 - mae: 1.1901 - val_loss: 9.6005 - val_mae: 2.1983\n",
      "Epoch 758/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.2117 - mae: 1.1581 - val_loss: 9.0231 - val_mae: 2.1392\n",
      "Epoch 759/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.1383 - mae: 0.9214 - val_loss: 10.3098 - val_mae: 2.2207\n",
      "Epoch 760/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.3832 - mae: 0.9831 - val_loss: 10.0372 - val_mae: 2.1897\n",
      "Epoch 761/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.4791 - mae: 0.9416 - val_loss: 9.7286 - val_mae: 2.1618\n",
      "Epoch 762/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.9505 - mae: 0.7890 - val_loss: 10.3410 - val_mae: 2.2688\n",
      "Epoch 763/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 1.4144 - mae: 0.9618 - val_loss: 8.8684 - val_mae: 2.0556\n",
      "Epoch 764/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.5792 - mae: 0.9429 - val_loss: 8.9788 - val_mae: 2.0386\n",
      "Epoch 765/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.3268 - mae: 0.9450 - val_loss: 10.1899 - val_mae: 2.1615\n",
      "Epoch 766/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.5906 - mae: 0.5963 - val_loss: 9.0235 - val_mae: 2.0404\n",
      "Epoch 767/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.7495 - mae: 0.6791 - val_loss: 9.0914 - val_mae: 2.0435\n",
      "Epoch 768/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.4419 - mae: 0.5090 - val_loss: 9.6920 - val_mae: 2.1226\n",
      "Epoch 769/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.5234 - mae: 1.1081 - val_loss: 9.3624 - val_mae: 2.1293\n",
      "Epoch 770/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.7364 - mae: 0.6673 - val_loss: 9.1924 - val_mae: 2.0934\n",
      "Epoch 771/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.5413 - mae: 0.5406 - val_loss: 9.6851 - val_mae: 2.1492\n",
      "Epoch 772/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.7733 - mae: 1.1317 - val_loss: 9.8755 - val_mae: 2.1725\n",
      "Epoch 773/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.4501 - mae: 0.5276 - val_loss: 8.9212 - val_mae: 2.0944\n",
      "Epoch 774/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 1.7483 - mae: 1.1473 - val_loss: 9.2946 - val_mae: 2.1200\n",
      "Epoch 775/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 1.1194 - mae: 0.8746 - val_loss: 9.7362 - val_mae: 2.1782\n",
      "Epoch 776/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.5864 - mae: 0.6163 - val_loss: 8.8035 - val_mae: 2.1435\n",
      "Epoch 777/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.9324 - mae: 0.7841 - val_loss: 9.2849 - val_mae: 2.1411\n",
      "Epoch 778/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 1.5970 - mae: 0.9539 - val_loss: 9.8596 - val_mae: 2.1516\n",
      "Epoch 779/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.2566 - mae: 0.8584 - val_loss: 9.5272 - val_mae: 2.1994\n",
      "Epoch 780/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.6709 - mae: 0.6336 - val_loss: 9.7496 - val_mae: 2.2087\n",
      "Epoch 781/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.6780 - mae: 1.4098 - val_loss: 9.5473 - val_mae: 2.1835\n",
      "Epoch 782/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 1.4348 - mae: 0.9014 - val_loss: 9.7890 - val_mae: 2.1885\n",
      "Epoch 783/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9114 - mae: 0.7847 - val_loss: 10.0460 - val_mae: 2.2221\n",
      "Epoch 784/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.6782 - mae: 0.6433 - val_loss: 9.2443 - val_mae: 2.1531\n",
      "Epoch 785/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.1220 - mae: 0.8208 - val_loss: 9.6112 - val_mae: 2.1912\n",
      "Epoch 786/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.6673 - mae: 0.6509 - val_loss: 9.6888 - val_mae: 2.1944\n",
      "Epoch 787/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.0674 - mae: 1.1996 - val_loss: 9.2913 - val_mae: 2.1747\n",
      "Epoch 788/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 2.4289 - mae: 1.3883 - val_loss: 9.9461 - val_mae: 2.1858\n",
      "Epoch 789/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.5928 - mae: 1.0619 - val_loss: 9.0866 - val_mae: 2.1098\n",
      "Epoch 790/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.3190 - mae: 0.9965 - val_loss: 9.1226 - val_mae: 2.1153\n",
      "Epoch 791/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.8948 - mae: 1.1634 - val_loss: 9.9929 - val_mae: 2.2471\n",
      "Epoch 792/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.5635 - mae: 1.0778 - val_loss: 9.7489 - val_mae: 2.2080\n",
      "Epoch 793/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.6324 - mae: 0.5781 - val_loss: 9.5453 - val_mae: 2.1738\n",
      "Epoch 794/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0584 - mae: 0.8744 - val_loss: 9.4881 - val_mae: 2.1506\n",
      "Epoch 795/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.0221 - mae: 0.8859 - val_loss: 9.1945 - val_mae: 2.1723\n",
      "Epoch 796/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.7448 - mae: 0.6892 - val_loss: 9.2642 - val_mae: 2.1596\n",
      "Epoch 797/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 3.3162 - mae: 1.6037 - val_loss: 9.1090 - val_mae: 2.1143\n",
      "Epoch 798/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.5215 - mae: 0.5895 - val_loss: 9.3494 - val_mae: 2.1452\n",
      "Epoch 799/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 2.9149 - mae: 1.4084 - val_loss: 8.8414 - val_mae: 2.1341\n",
      "Epoch 800/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.1214 - mae: 1.3328 - val_loss: 9.0606 - val_mae: 2.1298\n",
      "Epoch 801/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.6729 - mae: 1.0070 - val_loss: 9.2310 - val_mae: 2.1643\n",
      "Epoch 802/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.3179 - mae: 1.4002 - val_loss: 9.6473 - val_mae: 2.1710\n",
      "Epoch 803/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.2542 - mae: 0.9598 - val_loss: 9.6116 - val_mae: 2.1268\n",
      "Epoch 804/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.0866 - mae: 1.2235 - val_loss: 9.6349 - val_mae: 2.1649\n",
      "Epoch 805/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.8797 - mae: 1.1970 - val_loss: 9.1075 - val_mae: 2.1087\n",
      "Epoch 806/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.5289 - mae: 0.5841 - val_loss: 9.1734 - val_mae: 2.1158\n",
      "Epoch 807/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.1719 - mae: 1.2125 - val_loss: 10.1035 - val_mae: 2.1993\n",
      "Epoch 808/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 1.2334 - mae: 0.8822 - val_loss: 10.5265 - val_mae: 2.2135\n",
      "Epoch 809/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.1702 - mae: 0.8481 - val_loss: 10.6302 - val_mae: 2.2354\n",
      "Epoch 810/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.5266 - mae: 1.0631 - val_loss: 10.4340 - val_mae: 2.2566\n",
      "Epoch 811/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.4880 - mae: 0.5249 - val_loss: 9.8168 - val_mae: 2.2405\n",
      "Epoch 812/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.6054 - mae: 1.0408 - val_loss: 10.1081 - val_mae: 2.2282\n",
      "Epoch 813/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.8819 - mae: 0.7825 - val_loss: 10.6395 - val_mae: 2.2850\n",
      "Epoch 814/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8784 - mae: 0.7769 - val_loss: 10.8349 - val_mae: 2.2964\n",
      "Epoch 815/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 1.7133 - mae: 1.1352 - val_loss: 10.5321 - val_mae: 2.2583\n",
      "Epoch 816/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.7650 - mae: 1.0484 - val_loss: 10.4801 - val_mae: 2.2674\n",
      "Epoch 817/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.0342 - mae: 0.8484 - val_loss: 9.7167 - val_mae: 2.2312\n",
      "Epoch 818/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.1900 - mae: 0.8708 - val_loss: 9.9076 - val_mae: 2.2127\n",
      "Epoch 819/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.6636 - mae: 0.6584 - val_loss: 9.8646 - val_mae: 2.1608\n",
      "Epoch 820/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.9042 - mae: 0.7864 - val_loss: 9.5709 - val_mae: 2.1407\n",
      "Epoch 821/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.3269 - mae: 1.5249 - val_loss: 8.7649 - val_mae: 2.0967\n",
      "Epoch 822/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8074 - mae: 0.6929 - val_loss: 9.1684 - val_mae: 2.1253\n",
      "Epoch 823/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.4457 - mae: 0.4988 - val_loss: 9.9984 - val_mae: 2.1711\n",
      "Epoch 824/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.5530 - mae: 0.6074 - val_loss: 9.3824 - val_mae: 2.1246\n",
      "Epoch 825/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.6657 - mae: 0.6495 - val_loss: 9.2705 - val_mae: 2.1030\n",
      "Epoch 826/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 1.1411 - mae: 0.8766 - val_loss: 9.4440 - val_mae: 2.1299\n",
      "Epoch 827/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.9947 - mae: 0.7556 - val_loss: 9.5786 - val_mae: 2.1593\n",
      "Epoch 828/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.2083 - mae: 0.8903 - val_loss: 9.3286 - val_mae: 2.1526\n",
      "Epoch 829/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.3205 - mae: 0.9903 - val_loss: 9.6306 - val_mae: 2.1852\n",
      "Epoch 830/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.1267 - mae: 0.8764 - val_loss: 9.1607 - val_mae: 2.1106\n",
      "Epoch 831/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.2154 - mae: 0.9352 - val_loss: 9.6465 - val_mae: 2.1400\n",
      "Epoch 832/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 1.0722 - mae: 0.9045 - val_loss: 9.8845 - val_mae: 2.1908\n",
      "Epoch 833/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.6927 - mae: 0.6616 - val_loss: 9.4834 - val_mae: 2.1796\n",
      "Epoch 834/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 2.1037 - mae: 1.2224 - val_loss: 9.7855 - val_mae: 2.2137\n",
      "Epoch 835/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.8672 - mae: 0.7181 - val_loss: 10.3175 - val_mae: 2.2594\n",
      "Epoch 836/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.5146 - mae: 0.5505 - val_loss: 9.7139 - val_mae: 2.1917\n",
      "Epoch 837/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.2943 - mae: 0.8676 - val_loss: 9.3484 - val_mae: 2.1537\n",
      "Epoch 838/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 1.3313 - mae: 0.9115 - val_loss: 9.5391 - val_mae: 2.1783\n",
      "Epoch 839/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.7971 - mae: 1.1657 - val_loss: 9.7545 - val_mae: 2.1991\n",
      "Epoch 840/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.4925 - mae: 0.5309 - val_loss: 10.1351 - val_mae: 2.2409\n",
      "Epoch 841/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.5574 - mae: 1.0102 - val_loss: 9.3370 - val_mae: 2.1555\n",
      "Epoch 842/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.3144 - mae: 0.9388 - val_loss: 10.5227 - val_mae: 2.2380\n",
      "Epoch 843/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.4657 - mae: 0.5417 - val_loss: 10.9960 - val_mae: 2.2377\n",
      "Epoch 844/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.3707 - mae: 0.4794 - val_loss: 9.9803 - val_mae: 2.1791\n",
      "Epoch 845/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.3721 - mae: 0.4685 - val_loss: 10.2518 - val_mae: 2.2029\n",
      "Epoch 846/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.6844 - mae: 0.6403 - val_loss: 9.7973 - val_mae: 2.1741\n",
      "Epoch 847/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.6368 - mae: 0.6268 - val_loss: 9.8976 - val_mae: 2.1804\n",
      "Epoch 848/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.7586 - mae: 0.6623 - val_loss: 9.9847 - val_mae: 2.2136\n",
      "Epoch 849/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.5769 - mae: 0.5873 - val_loss: 10.2011 - val_mae: 2.1965\n",
      "Epoch 850/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.4393 - mae: 0.5375 - val_loss: 9.8317 - val_mae: 2.1821\n",
      "Epoch 851/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.1481 - mae: 0.8758 - val_loss: 9.1527 - val_mae: 2.1334\n",
      "Epoch 852/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.0423 - mae: 0.7460 - val_loss: 9.6456 - val_mae: 2.1557\n",
      "Epoch 853/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.4707 - mae: 1.0290 - val_loss: 10.1171 - val_mae: 2.2090\n",
      "Epoch 854/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7403 - mae: 0.6619 - val_loss: 9.2889 - val_mae: 2.1438\n",
      "Epoch 855/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.3983 - mae: 0.9560 - val_loss: 9.5973 - val_mae: 2.1468\n",
      "Epoch 856/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.8712 - mae: 0.7843 - val_loss: 9.9030 - val_mae: 2.1623\n",
      "Epoch 857/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.1715 - mae: 0.9057 - val_loss: 9.0571 - val_mae: 2.0902\n",
      "Epoch 858/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2.4844 - mae: 1.4739 - val_loss: 9.2490 - val_mae: 2.0814\n",
      "Epoch 859/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.7491 - mae: 0.7292 - val_loss: 9.6440 - val_mae: 2.1206\n",
      "Epoch 860/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.4144 - mae: 0.9616 - val_loss: 9.3156 - val_mae: 2.0986\n",
      "Epoch 861/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9038 - mae: 0.7787 - val_loss: 9.2299 - val_mae: 2.0835\n",
      "Epoch 862/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.4563 - mae: 0.5385 - val_loss: 9.7629 - val_mae: 2.0974\n",
      "Epoch 863/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.1174 - mae: 0.8702 - val_loss: 9.1937 - val_mae: 2.0528\n",
      "Epoch 864/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.5730 - mae: 0.6019 - val_loss: 8.8983 - val_mae: 2.0271\n",
      "Epoch 865/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.5515 - mae: 1.0123 - val_loss: 8.7924 - val_mae: 2.0507\n",
      "Epoch 866/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2631 - mae: 0.9854 - val_loss: 8.8008 - val_mae: 2.0701\n",
      "Epoch 867/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.7067 - mae: 1.0838 - val_loss: 8.8769 - val_mae: 2.0798\n",
      "Epoch 868/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.0710 - mae: 0.7945 - val_loss: 8.7422 - val_mae: 2.0674\n",
      "Epoch 869/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.7702 - mae: 0.7290 - val_loss: 8.8718 - val_mae: 2.0988\n",
      "Epoch 870/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.3356 - mae: 0.9795 - val_loss: 9.9125 - val_mae: 2.1208\n",
      "Epoch 871/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7058 - mae: 0.6654 - val_loss: 9.3646 - val_mae: 2.0901\n",
      "Epoch 872/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 1.5061 - mae: 1.0444 - val_loss: 9.4528 - val_mae: 2.0998\n",
      "Epoch 873/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.8425 - mae: 1.0989 - val_loss: 9.7855 - val_mae: 2.1386\n",
      "Epoch 874/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.5089 - mae: 1.0485 - val_loss: 9.1660 - val_mae: 2.1756\n",
      "Epoch 875/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.9743 - mae: 0.8158 - val_loss: 9.8291 - val_mae: 2.1652\n",
      "Epoch 876/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.6291 - mae: 1.1257 - val_loss: 10.0404 - val_mae: 2.1532\n",
      "Epoch 877/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.0922 - mae: 1.1987 - val_loss: 9.7799 - val_mae: 2.1614\n",
      "Epoch 878/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.8992 - mae: 0.7346 - val_loss: 9.6374 - val_mae: 2.1504\n",
      "Epoch 879/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.6395 - mae: 1.0370 - val_loss: 10.0766 - val_mae: 2.1635\n",
      "Epoch 880/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.5550 - mae: 0.9786 - val_loss: 10.1576 - val_mae: 2.1349\n",
      "Epoch 881/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 1.5838 - mae: 1.0997 - val_loss: 9.5732 - val_mae: 2.1369\n",
      "Epoch 882/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.1219 - mae: 0.8788 - val_loss: 10.2072 - val_mae: 2.1717\n",
      "Epoch 883/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.6009 - mae: 1.3563 - val_loss: 9.7720 - val_mae: 2.1211\n",
      "Epoch 884/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.2610 - mae: 0.8360 - val_loss: 9.4811 - val_mae: 2.1278\n",
      "Epoch 885/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.8760 - mae: 0.8036 - val_loss: 9.3144 - val_mae: 2.1320\n",
      "Epoch 886/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.5885 - mae: 0.6036 - val_loss: 9.7954 - val_mae: 2.1394\n",
      "Epoch 887/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 1.0783 - mae: 0.8590 - val_loss: 10.2792 - val_mae: 2.1985\n",
      "Epoch 888/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.9764 - mae: 1.1785 - val_loss: 9.5844 - val_mae: 2.1286\n",
      "Epoch 889/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.5813 - mae: 0.6087 - val_loss: 9.9275 - val_mae: 2.1619\n",
      "Epoch 890/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.5376 - mae: 0.5468 - val_loss: 10.3604 - val_mae: 2.1811\n",
      "Epoch 891/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.2098 - mae: 0.9419 - val_loss: 9.7088 - val_mae: 2.1442\n",
      "Epoch 892/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.7482 - mae: 0.6901 - val_loss: 10.0172 - val_mae: 2.1438\n",
      "Epoch 893/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.3991 - mae: 0.9746 - val_loss: 9.3012 - val_mae: 2.0970\n",
      "Epoch 894/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.5939 - mae: 0.5916 - val_loss: 9.5696 - val_mae: 2.1356\n",
      "Epoch 895/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.1088 - mae: 0.8360 - val_loss: 9.7874 - val_mae: 2.1546\n",
      "Epoch 896/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.8729 - mae: 0.7484 - val_loss: 8.9103 - val_mae: 2.0839\n",
      "Epoch 897/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.5559 - mae: 0.5391 - val_loss: 9.0599 - val_mae: 2.0824\n",
      "Epoch 898/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.4628 - mae: 1.0445 - val_loss: 9.7278 - val_mae: 2.1603\n",
      "Epoch 899/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.5712 - mae: 0.9325 - val_loss: 9.3717 - val_mae: 2.1292\n",
      "Epoch 900/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.6768 - mae: 0.6757 - val_loss: 9.4142 - val_mae: 2.1069\n",
      "Epoch 901/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7928 - mae: 0.7074 - val_loss: 9.8046 - val_mae: 2.1107\n",
      "Epoch 902/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.0612 - mae: 0.8503 - val_loss: 9.7481 - val_mae: 2.1016\n",
      "Epoch 903/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 3.4520 - mae: 1.7113 - val_loss: 9.0483 - val_mae: 2.0278\n",
      "Epoch 904/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.1409 - mae: 0.8569 - val_loss: 9.3721 - val_mae: 2.0696\n",
      "Epoch 905/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.6091 - mae: 1.1123 - val_loss: 9.0206 - val_mae: 2.0604\n",
      "Epoch 906/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.6306 - mae: 0.9287 - val_loss: 9.0941 - val_mae: 2.0383\n",
      "Epoch 907/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.8816 - mae: 0.6905 - val_loss: 9.3430 - val_mae: 2.0769\n",
      "Epoch 908/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 2.7905 - mae: 1.4650 - val_loss: 9.2654 - val_mae: 2.0757\n",
      "Epoch 909/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.5014 - mae: 0.5456 - val_loss: 9.3613 - val_mae: 2.1190\n",
      "Epoch 910/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8176 - mae: 0.7300 - val_loss: 9.7319 - val_mae: 2.1620\n",
      "Epoch 911/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.7179 - mae: 0.6936 - val_loss: 9.0138 - val_mae: 2.1285\n",
      "Epoch 912/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4433 - mae: 0.9941 - val_loss: 8.5633 - val_mae: 2.0712\n",
      "Epoch 913/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 1.0834 - mae: 0.8082 - val_loss: 9.1033 - val_mae: 2.0938\n",
      "Epoch 914/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.6224 - mae: 0.6288 - val_loss: 9.3477 - val_mae: 2.1097\n",
      "Epoch 915/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 1.1841 - mae: 0.9422 - val_loss: 9.9733 - val_mae: 2.2027\n",
      "Epoch 916/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 1.5705 - mae: 0.9972 - val_loss: 9.7080 - val_mae: 2.1664\n",
      "Epoch 917/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.9058 - mae: 0.7748 - val_loss: 9.9189 - val_mae: 2.1126\n",
      "Epoch 918/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.6260 - mae: 0.6272 - val_loss: 10.4070 - val_mae: 2.1348\n",
      "Epoch 919/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.5403 - mae: 1.0666 - val_loss: 9.6184 - val_mae: 2.1008\n",
      "Epoch 920/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.6499 - mae: 0.6443 - val_loss: 9.4514 - val_mae: 2.0609\n",
      "Epoch 921/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.5673 - mae: 1.0969 - val_loss: 10.9935 - val_mae: 2.2206\n",
      "Epoch 922/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.7446 - mae: 0.6667 - val_loss: 10.2627 - val_mae: 2.1436\n",
      "Epoch 923/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 1.8360 - mae: 0.9281 - val_loss: 10.2800 - val_mae: 2.1233\n",
      "Epoch 924/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.6894 - mae: 1.0716 - val_loss: 10.6504 - val_mae: 2.1964\n",
      "Epoch 925/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.9029 - mae: 0.7455 - val_loss: 9.5003 - val_mae: 2.1345\n",
      "Epoch 926/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.7711 - mae: 0.6873 - val_loss: 9.3847 - val_mae: 2.1243\n",
      "Epoch 927/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.9289 - mae: 0.7998 - val_loss: 9.7022 - val_mae: 2.1495\n",
      "Epoch 928/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.3347 - mae: 0.4548 - val_loss: 9.4166 - val_mae: 2.1133\n",
      "Epoch 929/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 1.3903 - mae: 0.9856 - val_loss: 9.3353 - val_mae: 2.0805\n",
      "Epoch 930/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.5916 - mae: 1.0324 - val_loss: 10.3712 - val_mae: 2.2083\n",
      "Epoch 931/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 1.6629 - mae: 1.0535 - val_loss: 10.4588 - val_mae: 2.2585\n",
      "Epoch 932/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.2099 - mae: 1.3022 - val_loss: 10.0653 - val_mae: 2.2049\n",
      "Epoch 933/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 1.0750 - mae: 0.8431 - val_loss: 9.9451 - val_mae: 2.1973\n",
      "Epoch 934/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.9818 - mae: 0.7833 - val_loss: 9.5457 - val_mae: 2.1682\n",
      "Epoch 935/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.1984 - mae: 0.8597 - val_loss: 9.5432 - val_mae: 2.1162\n",
      "Epoch 936/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 1.1702 - mae: 0.9489 - val_loss: 9.8250 - val_mae: 2.1377\n",
      "Epoch 937/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.0012 - mae: 0.8149 - val_loss: 10.1205 - val_mae: 2.1860\n",
      "Epoch 938/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.1021 - mae: 0.8765 - val_loss: 9.8374 - val_mae: 2.1435\n",
      "Epoch 939/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 6.6105 - mae: 2.1717 - val_loss: 9.2211 - val_mae: 2.0787\n",
      "Epoch 940/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8611 - mae: 0.7654 - val_loss: 8.9402 - val_mae: 2.0897\n",
      "Epoch 941/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 2.2313 - mae: 1.3196 - val_loss: 9.8012 - val_mae: 2.1201\n",
      "Epoch 942/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.3249 - mae: 0.8939 - val_loss: 9.0607 - val_mae: 2.0901\n",
      "Epoch 943/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.7217 - mae: 0.6196 - val_loss: 9.0867 - val_mae: 2.1144\n",
      "Epoch 944/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.3917 - mae: 0.5139 - val_loss: 9.0294 - val_mae: 2.1149\n",
      "Epoch 945/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.6013 - mae: 0.6279 - val_loss: 8.9939 - val_mae: 2.0956\n",
      "Epoch 946/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.6080 - mae: 0.6334 - val_loss: 9.6062 - val_mae: 2.1471\n",
      "Epoch 947/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8143 - mae: 0.7337 - val_loss: 9.3533 - val_mae: 2.1310\n",
      "Epoch 948/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.8448 - mae: 0.7601 - val_loss: 9.4461 - val_mae: 2.1065\n",
      "Epoch 949/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 1.1187 - mae: 0.8462 - val_loss: 9.0277 - val_mae: 2.0923\n",
      "Epoch 950/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 2.6029 - mae: 1.4845 - val_loss: 8.9304 - val_mae: 2.0488\n",
      "Epoch 951/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 2.7294 - mae: 1.5258 - val_loss: 8.8030 - val_mae: 2.0274\n",
      "Epoch 952/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.6784 - mae: 0.6398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - loss: 0.6860 - mae: 0.6410 - val_loss: 8.4268 - val_mae: 2.0203\n",
      "Epoch 953/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7815 - mae: 0.7179 - val_loss: 9.5330 - val_mae: 2.0873\n",
      "Epoch 954/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.6738 - mae: 0.6086 - val_loss: 10.0267 - val_mae: 2.1536\n",
      "Epoch 955/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.2317 - mae: 1.2748 - val_loss: 9.2486 - val_mae: 2.0794\n",
      "Epoch 956/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 2.3018 - mae: 1.3460 - val_loss: 9.1365 - val_mae: 2.0624\n",
      "Epoch 957/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.7562 - mae: 0.6961 - val_loss: 9.3289 - val_mae: 2.0917\n",
      "Epoch 958/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.5675 - mae: 1.3147 - val_loss: 9.5539 - val_mae: 2.1468\n",
      "Epoch 959/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.7161 - mae: 0.6339 - val_loss: 10.7927 - val_mae: 2.2096\n",
      "Epoch 960/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.8023 - mae: 0.7182 - val_loss: 8.8524 - val_mae: 2.0651\n",
      "Epoch 961/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.9712 - mae: 0.7852 - val_loss: 8.6135 - val_mae: 2.0599\n",
      "Epoch 962/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.3302 - mae: 0.4610 - val_loss: 9.1138 - val_mae: 2.1021\n",
      "Epoch 963/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.7963 - mae: 0.7347 - val_loss: 8.9963 - val_mae: 2.1136\n",
      "Epoch 964/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.0614 - mae: 0.8641 - val_loss: 9.8357 - val_mae: 2.2458\n",
      "Epoch 965/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.1358 - mae: 0.8555 - val_loss: 9.1430 - val_mae: 2.1140\n",
      "Epoch 966/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.6822 - mae: 0.6305 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - loss: 0.7312 - mae: 0.6590 - val_loss: 8.3265 - val_mae: 1.9968\n",
      "Epoch 967/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.3435 - mae: 0.9998 - val_loss: 9.0176 - val_mae: 2.0774\n",
      "Epoch 968/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 1.6288 - mae: 0.9876 - val_loss: 8.7603 - val_mae: 2.0510\n",
      "Epoch 969/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.4720 - mae: 0.5367 - val_loss: 8.8639 - val_mae: 2.0761\n",
      "Epoch 970/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.6541 - mae: 0.6676 - val_loss: 9.5035 - val_mae: 2.1544\n",
      "Epoch 971/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.4485 - mae: 0.9763 - val_loss: 9.0839 - val_mae: 2.0826\n",
      "Epoch 972/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.4582 - mae: 0.5310 - val_loss: 10.1339 - val_mae: 2.1576\n",
      "Epoch 973/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 3.5353 - mae: 1.6936 - val_loss: 9.8312 - val_mae: 2.1474\n",
      "Epoch 974/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 4.3615 - mae: 1.7983 - val_loss: 9.3719 - val_mae: 2.1393\n",
      "Epoch 975/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 1.7686 - mae: 1.1785 - val_loss: 9.8411 - val_mae: 2.1998\n",
      "Epoch 976/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.5211 - mae: 1.0212 - val_loss: 9.0007 - val_mae: 2.1507\n",
      "Epoch 977/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.3850 - mae: 0.4791 - val_loss: 9.3362 - val_mae: 2.2020\n",
      "Epoch 978/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.1096 - mae: 0.8475 - val_loss: 9.5147 - val_mae: 2.1292\n",
      "Epoch 979/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.7634 - mae: 0.7478 - val_loss: 9.2135 - val_mae: 2.1212\n",
      "Epoch 980/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.3981 - mae: 0.5021 - val_loss: 9.1324 - val_mae: 2.1193\n",
      "Epoch 981/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.0255 - mae: 0.8718 - val_loss: 8.9740 - val_mae: 2.1062\n",
      "Epoch 982/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.6853 - mae: 1.1119 - val_loss: 8.8795 - val_mae: 2.1021\n",
      "Epoch 983/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.5435 - mae: 0.5822 - val_loss: 8.9196 - val_mae: 2.0988\n",
      "Epoch 984/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.3526 - mae: 0.9748 - val_loss: 9.1413 - val_mae: 2.1339\n",
      "Epoch 985/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.6907 - mae: 0.7016 - val_loss: 9.1446 - val_mae: 2.1423\n",
      "Epoch 986/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.5553 - mae: 0.5983 - val_loss: 8.9407 - val_mae: 2.1152\n",
      "Epoch 987/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 1.3531 - mae: 1.0259 - val_loss: 8.4850 - val_mae: 2.0365\n",
      "Epoch 988/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 2.0424 - mae: 1.2342 - val_loss: 8.9078 - val_mae: 2.0999\n",
      "Epoch 989/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.2089 - mae: 0.8783 - val_loss: 8.4958 - val_mae: 2.0397\n",
      "Epoch 990/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.8793 - mae: 1.1671 - val_loss: 8.9034 - val_mae: 2.1029\n",
      "Epoch 991/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.9372 - mae: 0.8078 - val_loss: 8.9200 - val_mae: 2.1208\n",
      "Epoch 992/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.1134 - mae: 0.8474 - val_loss: 8.8205 - val_mae: 2.0921\n",
      "Epoch 993/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.8374 - mae: 1.2045 - val_loss: 9.2200 - val_mae: 2.0859\n",
      "Epoch 994/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 1.2696 - mae: 1.0046 - val_loss: 9.2577 - val_mae: 2.1042\n",
      "Epoch 995/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 3.9652 - mae: 1.5689 - val_loss: 9.8214 - val_mae: 2.1816\n",
      "Epoch 996/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 1.0881 - mae: 0.8102 - val_loss: 9.9092 - val_mae: 2.1914\n",
      "Epoch 997/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 1.5899 - mae: 1.0335 - val_loss: 9.5471 - val_mae: 2.2143\n",
      "Epoch 998/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 1.6080 - mae: 1.0976 - val_loss: 10.1165 - val_mae: 2.2311\n",
      "Epoch 999/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.3514 - mae: 0.4488 - val_loss: 9.7652 - val_mae: 2.1733\n",
      "Epoch 1000/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 1.1687 - mae: 0.8880 - val_loss: 9.6057 - val_mae: 2.1823\n"
     ]
    }
   ],
   "source": [
    "#Fit and save model\n",
    "history=model.fit(X_train,y_train,\n",
    "                  batch_size=64,\n",
    "                  epochs=1000,\n",
    "                  validation_split=0.2,\n",
    "                  callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622bb00e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
